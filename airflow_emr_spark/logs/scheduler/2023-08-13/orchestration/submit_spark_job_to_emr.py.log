[2023-08-13 10:23:23,438] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:23:23,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:23:23,440] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:23:23,735] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:23:23,958] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,958] {manager.py:508} INFO - Created Permission View: can delete on DAG:submit_pyspark_script_to_emr
[2023-08-13 10:23:23,968] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,968] {manager.py:508} INFO - Created Permission View: can read on DAG:submit_pyspark_script_to_emr
[2023-08-13 10:23:23,976] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,976] {manager.py:508} INFO - Created Permission View: can edit on DAG:submit_pyspark_script_to_emr
[2023-08-13 10:23:23,977] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,977] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:23:23,986] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,986] {dag.py:2398} INFO - Creating ORM DAG for submit_pyspark_script_to_emr
[2023-08-13 10:23:23,998] {logging_mixin.py:115} INFO - [2023-08-13 10:23:23,998] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:23:24,017] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.583 seconds
[2023-08-13 10:23:54,101] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:23:54,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:23:54,106] {logging_mixin.py:115} INFO - [2023-08-13 10:23:54,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:23:54,189] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:23:54,213] {logging_mixin.py:115} INFO - [2023-08-13 10:23:54,213] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:23:54,354] {logging_mixin.py:115} INFO - [2023-08-13 10:23:54,354] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:23:54,367] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.271 seconds
[2023-08-13 10:24:24,441] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:24:24,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:24:24,444] {logging_mixin.py:115} INFO - [2023-08-13 10:24:24,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:24:24,535] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:24:24,563] {logging_mixin.py:115} INFO - [2023-08-13 10:24:24,563] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:24:24,703] {logging_mixin.py:115} INFO - [2023-08-13 10:24:24,703] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:24:24,718] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 10:24:54,802] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:24:54,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:24:54,805] {logging_mixin.py:115} INFO - [2023-08-13 10:24:54,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:24:54,901] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:24:54,928] {logging_mixin.py:115} INFO - [2023-08-13 10:24:54,928] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:24:55,070] {logging_mixin.py:115} INFO - [2023-08-13 10:24:55,070] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:24:55,082] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.286 seconds
[2023-08-13 10:25:25,181] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:25:25,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:25:25,184] {logging_mixin.py:115} INFO - [2023-08-13 10:25:25,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:25:25,281] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:25:25,312] {logging_mixin.py:115} INFO - [2023-08-13 10:25:25,312] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:25:25,453] {logging_mixin.py:115} INFO - [2023-08-13 10:25:25,453] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:25:25,471] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.294 seconds
[2023-08-13 10:25:55,558] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:25:55,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:25:55,561] {logging_mixin.py:115} INFO - [2023-08-13 10:25:55,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:25:55,659] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:25:55,693] {logging_mixin.py:115} INFO - [2023-08-13 10:25:55,693] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:25:55,867] {logging_mixin.py:115} INFO - [2023-08-13 10:25:55,867] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:25:55,882] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 10:26:25,969] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:26:25,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:26:25,971] {logging_mixin.py:115} INFO - [2023-08-13 10:26:25,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:26:26,064] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:26:26,095] {logging_mixin.py:115} INFO - [2023-08-13 10:26:26,095] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:26:26,242] {logging_mixin.py:115} INFO - [2023-08-13 10:26:26,242] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:26:26,263] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.299 seconds
[2023-08-13 10:26:56,355] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:26:56,357] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:26:56,358] {logging_mixin.py:115} INFO - [2023-08-13 10:26:56,358] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:26:56,452] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:26:56,483] {logging_mixin.py:115} INFO - [2023-08-13 10:26:56,483] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:26:56,641] {logging_mixin.py:115} INFO - [2023-08-13 10:26:56,641] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:26:56,656] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.305 seconds
[2023-08-13 10:27:26,735] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:27:26,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:27:26,738] {logging_mixin.py:115} INFO - [2023-08-13 10:27:26,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:27:26,834] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:27:26,861] {logging_mixin.py:115} INFO - [2023-08-13 10:27:26,861] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:27:27,002] {logging_mixin.py:115} INFO - [2023-08-13 10:27:27,002] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:27:27,015] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.286 seconds
[2023-08-13 10:27:57,088] {processor.py:153} INFO - Started process (PID=223) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:27:57,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:27:57,091] {logging_mixin.py:115} INFO - [2023-08-13 10:27:57,091] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:27:57,179] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:27:57,206] {logging_mixin.py:115} INFO - [2023-08-13 10:27:57,206] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:27:57,344] {logging_mixin.py:115} INFO - [2023-08-13 10:27:57,344] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:27:57,356] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.273 seconds
[2023-08-13 10:28:27,488] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:28:27,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:28:27,491] {logging_mixin.py:115} INFO - [2023-08-13 10:28:27,491] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:28:27,583] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:28:27,611] {logging_mixin.py:115} INFO - [2023-08-13 10:28:27,611] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:28:27,751] {logging_mixin.py:115} INFO - [2023-08-13 10:28:27,751] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:28:27,766] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 10:28:57,857] {processor.py:153} INFO - Started process (PID=237) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:28:57,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:28:57,860] {logging_mixin.py:115} INFO - [2023-08-13 10:28:57,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:28:57,958] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:28:57,991] {logging_mixin.py:115} INFO - [2023-08-13 10:28:57,991] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:28:58,140] {logging_mixin.py:115} INFO - [2023-08-13 10:28:58,140] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:28:58,155] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 10:29:28,239] {processor.py:153} INFO - Started process (PID=242) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:29:28,241] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:29:28,242] {logging_mixin.py:115} INFO - [2023-08-13 10:29:28,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:29:28,323] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:29:28,346] {logging_mixin.py:115} INFO - [2023-08-13 10:29:28,346] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:29:28,486] {logging_mixin.py:115} INFO - [2023-08-13 10:29:28,486] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:29:28,501] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.266 seconds
[2023-08-13 10:29:58,595] {processor.py:153} INFO - Started process (PID=247) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:29:58,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:29:58,598] {logging_mixin.py:115} INFO - [2023-08-13 10:29:58,598] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:29:58,708] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:29:58,742] {logging_mixin.py:115} INFO - [2023-08-13 10:29:58,742] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:29:58,905] {logging_mixin.py:115} INFO - [2023-08-13 10:29:58,905] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:29:58,919] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 10:30:29,008] {processor.py:153} INFO - Started process (PID=252) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:30:29,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:30:29,011] {logging_mixin.py:115} INFO - [2023-08-13 10:30:29,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:30:29,103] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:30:29,131] {logging_mixin.py:115} INFO - [2023-08-13 10:30:29,131] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:30:29,276] {logging_mixin.py:115} INFO - [2023-08-13 10:30:29,276] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:30:29,289] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.286 seconds
[2023-08-13 10:30:59,373] {processor.py:153} INFO - Started process (PID=257) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:30:59,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:30:59,376] {logging_mixin.py:115} INFO - [2023-08-13 10:30:59,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:30:59,469] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:30:59,498] {logging_mixin.py:115} INFO - [2023-08-13 10:30:59,498] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:30:59,638] {logging_mixin.py:115} INFO - [2023-08-13 10:30:59,637] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:30:59,651] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 10:31:29,743] {processor.py:153} INFO - Started process (PID=262) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:31:29,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:31:29,746] {logging_mixin.py:115} INFO - [2023-08-13 10:31:29,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:31:29,834] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:31:29,861] {logging_mixin.py:115} INFO - [2023-08-13 10:31:29,861] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:31:30,019] {logging_mixin.py:115} INFO - [2023-08-13 10:31:30,019] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:31:30,037] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.299 seconds
[2023-08-13 10:32:00,125] {processor.py:153} INFO - Started process (PID=267) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:32:00,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:32:00,127] {logging_mixin.py:115} INFO - [2023-08-13 10:32:00,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:32:00,215] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:32:00,244] {logging_mixin.py:115} INFO - [2023-08-13 10:32:00,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:32:00,389] {logging_mixin.py:115} INFO - [2023-08-13 10:32:00,389] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:32:00,402] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 10:32:30,495] {processor.py:153} INFO - Started process (PID=272) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:32:30,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:32:30,498] {logging_mixin.py:115} INFO - [2023-08-13 10:32:30,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:32:30,591] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:32:30,619] {logging_mixin.py:115} INFO - [2023-08-13 10:32:30,619] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:32:30,762] {logging_mixin.py:115} INFO - [2023-08-13 10:32:30,762] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:32:30,778] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.287 seconds
[2023-08-13 10:33:00,852] {processor.py:153} INFO - Started process (PID=277) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:33:00,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:33:00,855] {logging_mixin.py:115} INFO - [2023-08-13 10:33:00,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:33:00,941] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:33:00,968] {logging_mixin.py:115} INFO - [2023-08-13 10:33:00,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:33:01,107] {logging_mixin.py:115} INFO - [2023-08-13 10:33:01,107] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:33:01,121] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.273 seconds
[2023-08-13 10:33:31,204] {processor.py:153} INFO - Started process (PID=282) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:33:31,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:33:31,208] {logging_mixin.py:115} INFO - [2023-08-13 10:33:31,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:33:31,369] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:33:31,410] {logging_mixin.py:115} INFO - [2023-08-13 10:33:31,409] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:33:31,563] {logging_mixin.py:115} INFO - [2023-08-13 10:33:31,563] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:33:31,577] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 10:34:01,657] {processor.py:153} INFO - Started process (PID=287) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:34:01,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:34:01,660] {logging_mixin.py:115} INFO - [2023-08-13 10:34:01,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:34:01,751] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:34:01,779] {logging_mixin.py:115} INFO - [2023-08-13 10:34:01,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:34:01,928] {logging_mixin.py:115} INFO - [2023-08-13 10:34:01,927] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:34:01,943] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.290 seconds
[2023-08-13 10:34:32,031] {processor.py:153} INFO - Started process (PID=292) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:34:32,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:34:32,034] {logging_mixin.py:115} INFO - [2023-08-13 10:34:32,034] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:34:32,120] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:34:32,144] {logging_mixin.py:115} INFO - [2023-08-13 10:34:32,144] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:34:32,281] {logging_mixin.py:115} INFO - [2023-08-13 10:34:32,281] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:34:32,295] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.267 seconds
[2023-08-13 10:35:02,396] {processor.py:153} INFO - Started process (PID=297) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:35:02,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:35:02,399] {logging_mixin.py:115} INFO - [2023-08-13 10:35:02,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:35:02,488] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:35:02,514] {logging_mixin.py:115} INFO - [2023-08-13 10:35:02,514] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:35:02,652] {logging_mixin.py:115} INFO - [2023-08-13 10:35:02,652] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:35:02,665] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.274 seconds
[2023-08-13 10:35:32,750] {processor.py:153} INFO - Started process (PID=302) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:35:32,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:35:32,753] {logging_mixin.py:115} INFO - [2023-08-13 10:35:32,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:35:32,840] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:35:32,863] {logging_mixin.py:115} INFO - [2023-08-13 10:35:32,863] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:35:33,003] {logging_mixin.py:115} INFO - [2023-08-13 10:35:33,003] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:35:33,016] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.271 seconds
[2023-08-13 10:36:03,123] {processor.py:153} INFO - Started process (PID=307) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:36:03,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:36:03,126] {logging_mixin.py:115} INFO - [2023-08-13 10:36:03,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:36:03,189] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:36:03,215] {logging_mixin.py:115} INFO - [2023-08-13 10:36:03,215] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:36:03,353] {logging_mixin.py:115} INFO - [2023-08-13 10:36:03,353] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:36:03,366] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.269 seconds
[2023-08-13 10:36:33,467] {processor.py:153} INFO - Started process (PID=312) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:36:33,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:36:33,470] {logging_mixin.py:115} INFO - [2023-08-13 10:36:33,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:36:33,556] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:36:33,583] {logging_mixin.py:115} INFO - [2023-08-13 10:36:33,583] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:36:33,731] {logging_mixin.py:115} INFO - [2023-08-13 10:36:33,731] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:36:33,747] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.285 seconds
[2023-08-13 10:37:03,844] {processor.py:153} INFO - Started process (PID=317) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:37:03,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:37:03,846] {logging_mixin.py:115} INFO - [2023-08-13 10:37:03,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:37:03,937] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:37:03,965] {logging_mixin.py:115} INFO - [2023-08-13 10:37:03,965] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:37:04,103] {logging_mixin.py:115} INFO - [2023-08-13 10:37:04,103] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:37:04,118] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.279 seconds
[2023-08-13 10:37:34,210] {processor.py:153} INFO - Started process (PID=322) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:37:34,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:37:34,212] {logging_mixin.py:115} INFO - [2023-08-13 10:37:34,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:37:34,298] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:37:34,324] {logging_mixin.py:115} INFO - [2023-08-13 10:37:34,324] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:37:34,467] {logging_mixin.py:115} INFO - [2023-08-13 10:37:34,467] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:37:34,479] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.274 seconds
[2023-08-13 10:38:04,564] {processor.py:153} INFO - Started process (PID=327) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:38:04,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:38:04,568] {logging_mixin.py:115} INFO - [2023-08-13 10:38:04,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:38:04,658] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:38:04,685] {logging_mixin.py:115} INFO - [2023-08-13 10:38:04,685] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:38:04,830] {logging_mixin.py:115} INFO - [2023-08-13 10:38:04,830] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:38:04,846] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.286 seconds
[2023-08-13 10:38:34,971] {processor.py:153} INFO - Started process (PID=332) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:38:34,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:38:34,974] {logging_mixin.py:115} INFO - [2023-08-13 10:38:34,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:38:35,075] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:38:35,113] {logging_mixin.py:115} INFO - [2023-08-13 10:38:35,113] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:38:35,324] {logging_mixin.py:115} INFO - [2023-08-13 10:38:35,324] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:38:35,342] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.375 seconds
[2023-08-13 10:39:05,430] {processor.py:153} INFO - Started process (PID=337) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:39:05,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:39:05,434] {logging_mixin.py:115} INFO - [2023-08-13 10:39:05,434] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:39:05,566] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:39:05,606] {logging_mixin.py:115} INFO - [2023-08-13 10:39:05,606] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:39:05,791] {logging_mixin.py:115} INFO - [2023-08-13 10:39:05,791] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:39:05,808] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.383 seconds
[2023-08-13 10:39:35,902] {processor.py:153} INFO - Started process (PID=342) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:39:35,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:39:35,905] {logging_mixin.py:115} INFO - [2023-08-13 10:39:35,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:39:36,003] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:39:36,031] {logging_mixin.py:115} INFO - [2023-08-13 10:39:36,031] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:39:36,180] {logging_mixin.py:115} INFO - [2023-08-13 10:39:36,180] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:39:36,197] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.300 seconds
[2023-08-13 10:40:06,349] {processor.py:153} INFO - Started process (PID=347) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:40:06,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:40:06,354] {logging_mixin.py:115} INFO - [2023-08-13 10:40:06,354] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:40:06,469] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:40:06,500] {logging_mixin.py:115} INFO - [2023-08-13 10:40:06,500] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:40:06,651] {logging_mixin.py:115} INFO - [2023-08-13 10:40:06,650] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:40:06,667] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 10:40:36,769] {processor.py:153} INFO - Started process (PID=352) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:40:36,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:40:36,774] {logging_mixin.py:115} INFO - [2023-08-13 10:40:36,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:40:36,877] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:40:36,906] {logging_mixin.py:115} INFO - [2023-08-13 10:40:36,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:40:37,078] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.317 seconds
[2023-08-13 10:41:07,178] {processor.py:153} INFO - Started process (PID=362) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:41:07,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:41:07,181] {logging_mixin.py:115} INFO - [2023-08-13 10:41:07,181] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:41:07,274] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:41:07,301] {logging_mixin.py:115} INFO - [2023-08-13 10:41:07,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:41:07,442] {logging_mixin.py:115} INFO - [2023-08-13 10:41:07,442] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:41:07,456] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 10:41:37,538] {processor.py:153} INFO - Started process (PID=373) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:41:37,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:41:37,540] {logging_mixin.py:115} INFO - [2023-08-13 10:41:37,540] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:41:37,645] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:41:37,676] {logging_mixin.py:115} INFO - [2023-08-13 10:41:37,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:41:37,834] {logging_mixin.py:115} INFO - [2023-08-13 10:41:37,834] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:41:37,850] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.317 seconds
[2023-08-13 10:42:07,939] {processor.py:153} INFO - Started process (PID=378) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:42:07,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:42:07,942] {logging_mixin.py:115} INFO - [2023-08-13 10:42:07,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:42:08,021] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:42:08,044] {logging_mixin.py:115} INFO - [2023-08-13 10:42:08,044] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:42:08,174] {logging_mixin.py:115} INFO - [2023-08-13 10:42:08,174] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:42:08,188] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.254 seconds
[2023-08-13 10:42:38,275] {processor.py:153} INFO - Started process (PID=383) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:42:38,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:42:38,278] {logging_mixin.py:115} INFO - [2023-08-13 10:42:38,278] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:42:38,371] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:42:38,396] {logging_mixin.py:115} INFO - [2023-08-13 10:42:38,396] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:42:38,536] {logging_mixin.py:115} INFO - [2023-08-13 10:42:38,536] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:42:38,550] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.280 seconds
[2023-08-13 10:43:08,642] {processor.py:153} INFO - Started process (PID=388) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:43:08,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:43:08,645] {logging_mixin.py:115} INFO - [2023-08-13 10:43:08,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:43:08,732] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:43:08,759] {logging_mixin.py:115} INFO - [2023-08-13 10:43:08,759] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:43:08,896] {logging_mixin.py:115} INFO - [2023-08-13 10:43:08,896] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:43:08,910] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.273 seconds
[2023-08-13 10:43:39,032] {processor.py:153} INFO - Started process (PID=393) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:43:39,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:43:39,035] {logging_mixin.py:115} INFO - [2023-08-13 10:43:39,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:43:39,125] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:43:39,151] {logging_mixin.py:115} INFO - [2023-08-13 10:43:39,151] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:43:39,287] {logging_mixin.py:115} INFO - [2023-08-13 10:43:39,287] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:43:39,300] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.272 seconds
[2023-08-13 10:44:03,783] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:44:03,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:44:03,786] {logging_mixin.py:115} INFO - [2023-08-13 10:44:03,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:44:03,880] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:44:03,905] {logging_mixin.py:115} INFO - [2023-08-13 10:44:03,905] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:44:03,930] {logging_mixin.py:115} INFO - [2023-08-13 10:44:03,930] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:44:04,057] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.278 seconds
[2023-08-13 10:44:34,132] {processor.py:153} INFO - Started process (PID=176) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:44:34,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:44:34,135] {logging_mixin.py:115} INFO - [2023-08-13 10:44:34,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:44:34,228] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:44:34,258] {logging_mixin.py:115} INFO - [2023-08-13 10:44:34,258] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:44:34,411] {logging_mixin.py:115} INFO - [2023-08-13 10:44:34,410] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:44:34,424] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 10:45:04,516] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:45:04,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:45:04,519] {logging_mixin.py:115} INFO - [2023-08-13 10:45:04,519] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:45:04,608] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:45:04,635] {logging_mixin.py:115} INFO - [2023-08-13 10:45:04,635] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:45:04,773] {logging_mixin.py:115} INFO - [2023-08-13 10:45:04,772] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:45:04,786] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.275 seconds
[2023-08-13 10:45:34,856] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:45:34,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:45:34,859] {logging_mixin.py:115} INFO - [2023-08-13 10:45:34,859] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:45:34,961] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:45:34,990] {logging_mixin.py:115} INFO - [2023-08-13 10:45:34,990] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:45:35,143] {logging_mixin.py:115} INFO - [2023-08-13 10:45:35,143] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:45:35,157] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 10:46:05,250] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:46:05,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:46:05,256] {logging_mixin.py:115} INFO - [2023-08-13 10:46:05,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:46:05,376] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:46:05,408] {logging_mixin.py:115} INFO - [2023-08-13 10:46:05,407] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:46:05,574] {logging_mixin.py:115} INFO - [2023-08-13 10:46:05,573] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:46:05,590] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 10:46:35,672] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:46:35,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:46:35,675] {logging_mixin.py:115} INFO - [2023-08-13 10:46:35,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:46:35,777] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:46:35,808] {logging_mixin.py:115} INFO - [2023-08-13 10:46:35,807] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:46:35,956] {logging_mixin.py:115} INFO - [2023-08-13 10:46:35,956] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:46:35,970] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.303 seconds
[2023-08-13 10:47:06,048] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:47:06,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:47:06,050] {logging_mixin.py:115} INFO - [2023-08-13 10:47:06,050] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:47:06,142] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:47:06,171] {logging_mixin.py:115} INFO - [2023-08-13 10:47:06,171] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:47:06,361] {logging_mixin.py:115} INFO - [2023-08-13 10:47:06,361] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:47:06,384] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 10:47:36,472] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:47:36,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:47:36,476] {logging_mixin.py:115} INFO - [2023-08-13 10:47:36,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:47:36,577] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:47:36,609] {logging_mixin.py:115} INFO - [2023-08-13 10:47:36,609] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:47:36,763] {logging_mixin.py:115} INFO - [2023-08-13 10:47:36,763] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:47:36,777] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 10:48:06,857] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:06,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:48:06,860] {logging_mixin.py:115} INFO - [2023-08-13 10:48:06,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:06,954] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:06,982] {logging_mixin.py:115} INFO - [2023-08-13 10:48:06,982] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:48:07,127] {logging_mixin.py:115} INFO - [2023-08-13 10:48:07,127] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:48:07,140] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.288 seconds
[2023-08-13 10:48:10,873] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:10,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:48:10,876] {logging_mixin.py:115} INFO - [2023-08-13 10:48:10,876] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:10,988] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:11,194] {logging_mixin.py:115} INFO - [2023-08-13 10:48:11,194] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:48:11,217] {logging_mixin.py:115} INFO - [2023-08-13 10:48:11,217] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:48:11,236] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.367 seconds
[2023-08-13 10:48:22,672] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:22,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:48:22,677] {logging_mixin.py:115} INFO - [2023-08-13 10:48:22,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:22,768] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:22,780] {logging_mixin.py:115} INFO - [2023-08-13 10:48:22,780] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:48:22,802] {logging_mixin.py:115} INFO - [2023-08-13 10:48:22,802] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:48:22,812] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.145 seconds
[2023-08-13 10:48:52,889] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:52,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:48:52,893] {logging_mixin.py:115} INFO - [2023-08-13 10:48:52,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:52,986] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:48:53,012] {logging_mixin.py:115} INFO - [2023-08-13 10:48:53,012] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:48:53,150] {logging_mixin.py:115} INFO - [2023-08-13 10:48:53,150] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:48:53,164] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.279 seconds
[2023-08-13 10:49:23,251] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:49:23,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:49:23,254] {logging_mixin.py:115} INFO - [2023-08-13 10:49:23,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:49:23,363] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:49:23,391] {logging_mixin.py:115} INFO - [2023-08-13 10:49:23,390] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:49:23,535] {logging_mixin.py:115} INFO - [2023-08-13 10:49:23,535] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:49:23,555] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.308 seconds
[2023-08-13 10:49:53,659] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:49:53,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:49:53,683] {logging_mixin.py:115} INFO - [2023-08-13 10:49:53,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:49:53,779] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:49:53,807] {logging_mixin.py:115} INFO - [2023-08-13 10:49:53,807] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:49:53,950] {logging_mixin.py:115} INFO - [2023-08-13 10:49:53,950] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:49:53,966] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 10:50:24,060] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:50:24,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:50:24,062] {logging_mixin.py:115} INFO - [2023-08-13 10:50:24,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:50:24,135] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:50:24,158] {logging_mixin.py:115} INFO - [2023-08-13 10:50:24,158] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:50:24,285] {logging_mixin.py:115} INFO - [2023-08-13 10:50:24,285] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:50:24,299] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.244 seconds
[2023-08-13 10:50:54,389] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:50:54,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:50:54,392] {logging_mixin.py:115} INFO - [2023-08-13 10:50:54,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:50:54,488] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:50:54,523] {logging_mixin.py:115} INFO - [2023-08-13 10:50:54,523] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:50:54,691] {logging_mixin.py:115} INFO - [2023-08-13 10:50:54,691] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:50:54,710] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 10:51:24,802] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:51:24,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:51:24,805] {logging_mixin.py:115} INFO - [2023-08-13 10:51:24,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:51:24,895] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:51:24,923] {logging_mixin.py:115} INFO - [2023-08-13 10:51:24,922] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:51:25,062] {logging_mixin.py:115} INFO - [2023-08-13 10:51:25,062] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:51:25,075] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.278 seconds
[2023-08-13 10:51:55,167] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:51:55,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:51:55,170] {logging_mixin.py:115} INFO - [2023-08-13 10:51:55,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:51:55,268] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:51:55,302] {logging_mixin.py:115} INFO - [2023-08-13 10:51:55,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:51:55,458] {logging_mixin.py:115} INFO - [2023-08-13 10:51:55,458] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:51:55,472] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.310 seconds
[2023-08-13 10:52:25,558] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:52:25,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:52:25,562] {logging_mixin.py:115} INFO - [2023-08-13 10:52:25,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:52:25,652] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:52:25,680] {logging_mixin.py:115} INFO - [2023-08-13 10:52:25,680] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:52:25,823] {logging_mixin.py:115} INFO - [2023-08-13 10:52:25,823] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:52:25,837] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.284 seconds
[2023-08-13 10:52:55,928] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:52:55,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:52:55,932] {logging_mixin.py:115} INFO - [2023-08-13 10:52:55,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:52:56,053] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:52:56,090] {logging_mixin.py:115} INFO - [2023-08-13 10:52:56,090] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:52:56,263] {logging_mixin.py:115} INFO - [2023-08-13 10:52:56,263] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:52:56,281] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 10:53:26,385] {processor.py:153} INFO - Started process (PID=226) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:53:26,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:53:26,388] {logging_mixin.py:115} INFO - [2023-08-13 10:53:26,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:53:26,479] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:53:26,506] {logging_mixin.py:115} INFO - [2023-08-13 10:53:26,506] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:53:26,651] {logging_mixin.py:115} INFO - [2023-08-13 10:53:26,651] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:53:26,668] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.287 seconds
[2023-08-13 10:53:56,742] {processor.py:153} INFO - Started process (PID=231) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:53:56,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:53:56,744] {logging_mixin.py:115} INFO - [2023-08-13 10:53:56,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:53:56,829] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:53:56,853] {logging_mixin.py:115} INFO - [2023-08-13 10:53:56,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:53:56,981] {logging_mixin.py:115} INFO - [2023-08-13 10:53:56,981] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:53:56,995] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.257 seconds
[2023-08-13 10:54:27,091] {processor.py:153} INFO - Started process (PID=236) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:54:27,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:54:27,094] {logging_mixin.py:115} INFO - [2023-08-13 10:54:27,094] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:54:27,181] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:54:27,206] {logging_mixin.py:115} INFO - [2023-08-13 10:54:27,206] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:54:27,347] {logging_mixin.py:115} INFO - [2023-08-13 10:54:27,347] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:54:27,361] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.275 seconds
[2023-08-13 10:54:57,448] {processor.py:153} INFO - Started process (PID=241) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:54:57,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:54:57,451] {logging_mixin.py:115} INFO - [2023-08-13 10:54:57,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:54:57,566] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:54:57,601] {logging_mixin.py:115} INFO - [2023-08-13 10:54:57,601] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:54:57,767] {logging_mixin.py:115} INFO - [2023-08-13 10:54:57,767] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:54:57,784] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 10:55:27,867] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:55:27,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:55:27,871] {logging_mixin.py:115} INFO - [2023-08-13 10:55:27,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:55:27,960] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:55:27,988] {logging_mixin.py:115} INFO - [2023-08-13 10:55:27,988] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:55:28,125] {logging_mixin.py:115} INFO - [2023-08-13 10:55:28,125] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:55:28,138] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.276 seconds
[2023-08-13 10:55:58,225] {processor.py:153} INFO - Started process (PID=251) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:55:58,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:55:58,227] {logging_mixin.py:115} INFO - [2023-08-13 10:55:58,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:55:58,314] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:55:58,340] {logging_mixin.py:115} INFO - [2023-08-13 10:55:58,340] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:55:58,479] {logging_mixin.py:115} INFO - [2023-08-13 10:55:58,479] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:55:58,492] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.271 seconds
[2023-08-13 10:56:28,574] {processor.py:153} INFO - Started process (PID=256) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:56:28,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:56:28,577] {logging_mixin.py:115} INFO - [2023-08-13 10:56:28,577] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:56:28,664] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:56:28,692] {logging_mixin.py:115} INFO - [2023-08-13 10:56:28,692] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:56:28,832] {logging_mixin.py:115} INFO - [2023-08-13 10:56:28,831] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:56:28,845] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.276 seconds
[2023-08-13 10:56:58,935] {processor.py:153} INFO - Started process (PID=261) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:56:58,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:56:58,937] {logging_mixin.py:115} INFO - [2023-08-13 10:56:58,937] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:56:59,030] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:56:59,062] {logging_mixin.py:115} INFO - [2023-08-13 10:56:59,062] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:56:59,207] {logging_mixin.py:115} INFO - [2023-08-13 10:56:59,206] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:56:59,221] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.291 seconds
[2023-08-13 10:57:29,302] {processor.py:153} INFO - Started process (PID=266) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:57:29,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:57:29,306] {logging_mixin.py:115} INFO - [2023-08-13 10:57:29,306] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:57:29,408] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:57:29,439] {logging_mixin.py:115} INFO - [2023-08-13 10:57:29,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:57:29,586] {logging_mixin.py:115} INFO - [2023-08-13 10:57:29,586] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:57:29,600] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.303 seconds
[2023-08-13 10:57:59,686] {processor.py:153} INFO - Started process (PID=271) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:57:59,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:57:59,689] {logging_mixin.py:115} INFO - [2023-08-13 10:57:59,689] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:57:59,777] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:57:59,805] {logging_mixin.py:115} INFO - [2023-08-13 10:57:59,805] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:57:59,952] {logging_mixin.py:115} INFO - [2023-08-13 10:57:59,952] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:57:59,967] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.286 seconds
[2023-08-13 10:58:27,732] {processor.py:153} INFO - Started process (PID=276) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:58:27,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:58:27,735] {logging_mixin.py:115} INFO - [2023-08-13 10:58:27,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:58:27,871] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:58:28,089] {logging_mixin.py:115} INFO - [2023-08-13 10:58:28,089] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:58:28,111] {logging_mixin.py:115} INFO - [2023-08-13 10:58:28,111] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:58:28,129] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.403 seconds
[2023-08-13 10:58:37,691] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:58:37,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:58:37,694] {logging_mixin.py:115} INFO - [2023-08-13 10:58:37,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:58:37,790] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:58:37,805] {logging_mixin.py:115} INFO - [2023-08-13 10:58:37,805] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:58:37,832] {logging_mixin.py:115} INFO - [2023-08-13 10:58:37,832] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:58:37,846] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.159 seconds
[2023-08-13 10:59:07,930] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:59:07,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:59:07,944] {logging_mixin.py:115} INFO - [2023-08-13 10:59:07,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:59:08,018] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:59:08,042] {logging_mixin.py:115} INFO - [2023-08-13 10:59:08,042] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:59:08,172] {logging_mixin.py:115} INFO - [2023-08-13 10:59:08,172] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:59:08,186] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.261 seconds
[2023-08-13 10:59:38,270] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:59:38,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 10:59:38,273] {logging_mixin.py:115} INFO - [2023-08-13 10:59:38,273] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:59:38,363] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 10:59:38,390] {logging_mixin.py:115} INFO - [2023-08-13 10:59:38,390] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 10:59:38,526] {logging_mixin.py:115} INFO - [2023-08-13 10:59:38,526] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 10:59:38,542] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.277 seconds
[2023-08-13 11:00:08,631] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:08,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:00:08,633] {logging_mixin.py:115} INFO - [2023-08-13 11:00:08,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:08,724] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:08,752] {logging_mixin.py:115} INFO - [2023-08-13 11:00:08,752] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:00:08,890] {logging_mixin.py:115} INFO - [2023-08-13 11:00:08,889] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:00:08,903] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.277 seconds
[2023-08-13 11:00:38,990] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:38,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:00:38,992] {logging_mixin.py:115} INFO - [2023-08-13 11:00:38,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:39,077] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:39,103] {logging_mixin.py:115} INFO - [2023-08-13 11:00:39,103] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:00:39,246] {logging_mixin.py:115} INFO - [2023-08-13 11:00:39,246] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:00:39,260] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.275 seconds
[2023-08-13 11:00:50,023] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:50,024] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:00:50,025] {logging_mixin.py:115} INFO - [2023-08-13 11:00:50,025] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:50,128] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:00:50,156] {logging_mixin.py:115} INFO - [2023-08-13 11:00:50,155] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:00:50,326] {logging_mixin.py:115} INFO - [2023-08-13 11:00:50,326] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:00:50,360] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 11:01:00,952] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:01:00,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:01:00,955] {logging_mixin.py:115} INFO - [2023-08-13 11:01:00,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:01:01,048] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:01:01,074] {logging_mixin.py:115} INFO - [2023-08-13 11:01:01,073] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:01:01,101] {logging_mixin.py:115} INFO - [2023-08-13 11:01:01,101] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:01:01,239] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.290 seconds
[2023-08-13 11:01:31,370] {processor.py:153} INFO - Started process (PID=179) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:01:31,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:01:31,377] {logging_mixin.py:115} INFO - [2023-08-13 11:01:31,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:01:31,481] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:01:31,509] {logging_mixin.py:115} INFO - [2023-08-13 11:01:31,509] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:01:31,659] {logging_mixin.py:115} INFO - [2023-08-13 11:01:31,659] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:01:31,674] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.312 seconds
[2023-08-13 11:02:01,766] {processor.py:153} INFO - Started process (PID=184) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:01,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:02:01,769] {logging_mixin.py:115} INFO - [2023-08-13 11:02:01,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:01,867] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:01,894] {logging_mixin.py:115} INFO - [2023-08-13 11:02:01,894] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:02:02,045] {logging_mixin.py:115} INFO - [2023-08-13 11:02:02,045] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:02:02,062] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.301 seconds
[2023-08-13 11:02:10,771] {processor.py:153} INFO - Started process (PID=189) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:10,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:02:10,774] {logging_mixin.py:115} INFO - [2023-08-13 11:02:10,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:10,950] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:10,979] {logging_mixin.py:115} INFO - [2023-08-13 11:02:10,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:02:11,142] {logging_mixin.py:115} INFO - [2023-08-13 11:02:11,142] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:02:11,160] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.395 seconds
[2023-08-13 11:02:17,124] {processor.py:153} INFO - Started process (PID=194) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:17,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:02:17,127] {logging_mixin.py:115} INFO - [2023-08-13 11:02:17,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:17,250] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:17,283] {logging_mixin.py:115} INFO - [2023-08-13 11:02:17,283] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:02:17,433] {logging_mixin.py:115} INFO - [2023-08-13 11:02:17,433] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:02:17,454] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 11:02:29,287] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:29,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:02:29,290] {logging_mixin.py:115} INFO - [2023-08-13 11:02:29,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:29,378] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:29,405] {logging_mixin.py:115} INFO - [2023-08-13 11:02:29,405] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:02:29,432] {logging_mixin.py:115} INFO - [2023-08-13 11:02:29,432] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:02:29,567] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.283 seconds
[2023-08-13 11:02:59,659] {processor.py:153} INFO - Started process (PID=179) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:59,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:02:59,663] {logging_mixin.py:115} INFO - [2023-08-13 11:02:59,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:59,752] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:02:59,779] {logging_mixin.py:115} INFO - [2023-08-13 11:02:59,779] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:02:59,914] {logging_mixin.py:115} INFO - [2023-08-13 11:02:59,914] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:02:59,929] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.277 seconds
[2023-08-13 11:03:30,015] {processor.py:153} INFO - Started process (PID=184) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:03:30,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:03:30,018] {logging_mixin.py:115} INFO - [2023-08-13 11:03:30,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:03:30,108] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:03:30,133] {logging_mixin.py:115} INFO - [2023-08-13 11:03:30,133] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:03:30,271] {logging_mixin.py:115} INFO - [2023-08-13 11:03:30,271] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:03:30,287] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.276 seconds
[2023-08-13 11:04:00,454] {processor.py:153} INFO - Started process (PID=189) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:04:00,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:04:00,457] {logging_mixin.py:115} INFO - [2023-08-13 11:04:00,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:04:00,549] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:04:00,574] {logging_mixin.py:115} INFO - [2023-08-13 11:04:00,574] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:04:00,718] {logging_mixin.py:115} INFO - [2023-08-13 11:04:00,718] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:04:00,731] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 11:04:30,833] {processor.py:153} INFO - Started process (PID=194) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:04:30,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:04:30,837] {logging_mixin.py:115} INFO - [2023-08-13 11:04:30,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:04:30,939] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:04:30,982] {logging_mixin.py:115} INFO - [2023-08-13 11:04:30,982] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:04:31,128] {logging_mixin.py:115} INFO - [2023-08-13 11:04:31,128] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:04:31,145] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 11:05:01,228] {processor.py:153} INFO - Started process (PID=199) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:05:01,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:05:01,231] {logging_mixin.py:115} INFO - [2023-08-13 11:05:01,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:05:01,329] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:05:01,369] {logging_mixin.py:115} INFO - [2023-08-13 11:05:01,368] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:05:01,519] {logging_mixin.py:115} INFO - [2023-08-13 11:05:01,519] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:05:01,533] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 11:05:31,623] {processor.py:153} INFO - Started process (PID=204) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:05:31,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:05:31,626] {logging_mixin.py:115} INFO - [2023-08-13 11:05:31,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:05:31,714] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:05:31,740] {logging_mixin.py:115} INFO - [2023-08-13 11:05:31,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:05:31,884] {logging_mixin.py:115} INFO - [2023-08-13 11:05:31,884] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:05:31,898] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.280 seconds
[2023-08-13 11:06:01,978] {processor.py:153} INFO - Started process (PID=209) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:06:01,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:06:01,981] {logging_mixin.py:115} INFO - [2023-08-13 11:06:01,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:06:02,049] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:06:02,076] {logging_mixin.py:115} INFO - [2023-08-13 11:06:02,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:06:02,216] {logging_mixin.py:115} INFO - [2023-08-13 11:06:02,216] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:06:02,230] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.278 seconds
[2023-08-13 11:06:32,308] {processor.py:153} INFO - Started process (PID=214) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:06:32,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:06:32,311] {logging_mixin.py:115} INFO - [2023-08-13 11:06:32,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:06:32,395] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:06:32,418] {logging_mixin.py:115} INFO - [2023-08-13 11:06:32,418] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:06:32,548] {logging_mixin.py:115} INFO - [2023-08-13 11:06:32,548] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:06:32,561] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.258 seconds
[2023-08-13 11:07:02,638] {processor.py:153} INFO - Started process (PID=219) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:07:02,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:07:02,641] {logging_mixin.py:115} INFO - [2023-08-13 11:07:02,641] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:07:02,756] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:07:02,796] {logging_mixin.py:115} INFO - [2023-08-13 11:07:02,796] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:07:02,971] {logging_mixin.py:115} INFO - [2023-08-13 11:07:02,970] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:07:02,988] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 11:07:33,093] {processor.py:153} INFO - Started process (PID=224) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:07:33,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:07:33,096] {logging_mixin.py:115} INFO - [2023-08-13 11:07:33,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:07:33,194] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:07:33,224] {logging_mixin.py:115} INFO - [2023-08-13 11:07:33,224] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:07:33,383] {logging_mixin.py:115} INFO - [2023-08-13 11:07:33,382] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:07:33,401] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.313 seconds
[2023-08-13 11:08:03,496] {processor.py:153} INFO - Started process (PID=229) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:03,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:08:03,499] {logging_mixin.py:115} INFO - [2023-08-13 11:08:03,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:03,587] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:03,624] {logging_mixin.py:115} INFO - [2023-08-13 11:08:03,624] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:08:03,760] {logging_mixin.py:115} INFO - [2023-08-13 11:08:03,760] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:08:03,776] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.285 seconds
[2023-08-13 11:08:14,531] {processor.py:153} INFO - Started process (PID=234) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:14,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:08:14,534] {logging_mixin.py:115} INFO - [2023-08-13 11:08:14,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:14,645] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:14,674] {logging_mixin.py:115} INFO - [2023-08-13 11:08:14,674] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:08:14,826] {logging_mixin.py:115} INFO - [2023-08-13 11:08:14,825] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:08:14,848] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 11:08:28,488] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:28,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:08:28,495] {logging_mixin.py:115} INFO - [2023-08-13 11:08:28,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:28,604] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:28,633] {logging_mixin.py:115} INFO - [2023-08-13 11:08:28,633] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:08:28,663] {logging_mixin.py:115} INFO - [2023-08-13 11:08:28,662] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:08:28,801] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.317 seconds
[2023-08-13 11:08:58,890] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:58,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:08:58,892] {logging_mixin.py:115} INFO - [2023-08-13 11:08:58,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:58,973] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:08:58,996] {logging_mixin.py:115} INFO - [2023-08-13 11:08:58,996] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:08:59,124] {logging_mixin.py:115} INFO - [2023-08-13 11:08:59,124] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:08:59,137] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.252 seconds
[2023-08-13 11:09:29,227] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:09:29,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:09:29,230] {logging_mixin.py:115} INFO - [2023-08-13 11:09:29,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:09:29,338] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:09:29,370] {logging_mixin.py:115} INFO - [2023-08-13 11:09:29,370] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:09:29,530] {logging_mixin.py:115} INFO - [2023-08-13 11:09:29,530] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:09:29,547] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 11:09:59,649] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:09:59,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:09:59,652] {logging_mixin.py:115} INFO - [2023-08-13 11:09:59,652] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:09:59,745] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:09:59,773] {logging_mixin.py:115} INFO - [2023-08-13 11:09:59,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:09:59,924] {logging_mixin.py:115} INFO - [2023-08-13 11:09:59,924] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:09:59,938] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.293 seconds
[2023-08-13 11:10:30,024] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:10:30,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:10:30,027] {logging_mixin.py:115} INFO - [2023-08-13 11:10:30,027] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:10:30,102] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:10:30,130] {logging_mixin.py:115} INFO - [2023-08-13 11:10:30,130] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:10:30,270] {logging_mixin.py:115} INFO - [2023-08-13 11:10:30,270] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:10:30,284] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.264 seconds
[2023-08-13 11:11:00,377] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:00,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:11:00,380] {logging_mixin.py:115} INFO - [2023-08-13 11:11:00,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:00,480] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:00,514] {logging_mixin.py:115} INFO - [2023-08-13 11:11:00,514] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 11:11:00,670] {logging_mixin.py:115} INFO - [2023-08-13 11:11:00,670] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 11:11:00,685] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.313 seconds
[2023-08-13 11:11:15,740] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:15,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:11:15,742] {logging_mixin.py:115} INFO - [2023-08-13 11:11:15,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:15,862] {logging_mixin.py:115} INFO - [2023-08-13 11:11:15,860] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:11:15,863] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:15,887] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.152 seconds
[2023-08-13 11:11:45,962] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:45,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:11:45,965] {logging_mixin.py:115} INFO - [2023-08-13 11:11:45,965] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:46,056] {logging_mixin.py:115} INFO - [2023-08-13 11:11:46,054] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:11:46,057] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:11:46,076] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.119 seconds
[2023-08-13 11:12:16,142] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:12:16,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:12:16,144] {logging_mixin.py:115} INFO - [2023-08-13 11:12:16,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:12:16,249] {logging_mixin.py:115} INFO - [2023-08-13 11:12:16,246] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:12:16,250] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:12:16,308] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.171 seconds
[2023-08-13 11:12:46,390] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:12:46,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:12:46,395] {logging_mixin.py:115} INFO - [2023-08-13 11:12:46,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:12:46,493] {logging_mixin.py:115} INFO - [2023-08-13 11:12:46,491] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:12:46,494] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:12:46,522] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.137 seconds
[2023-08-13 11:13:16,579] {processor.py:153} INFO - Started process (PID=226) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:13:16,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:13:16,581] {logging_mixin.py:115} INFO - [2023-08-13 11:13:16,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:13:16,674] {logging_mixin.py:115} INFO - [2023-08-13 11:13:16,672] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:13:16,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:13:16,702] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.127 seconds
[2023-08-13 11:13:41,693] {processor.py:153} INFO - Started process (PID=231) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:13:41,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:13:41,699] {logging_mixin.py:115} INFO - [2023-08-13 11:13:41,698] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:13:41,829] {logging_mixin.py:115} INFO - [2023-08-13 11:13:41,827] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:13:41,830] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:13:41,854] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.172 seconds
[2023-08-13 11:14:11,914] {processor.py:153} INFO - Started process (PID=236) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:14:11,915] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:14:11,918] {logging_mixin.py:115} INFO - [2023-08-13 11:14:11,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:14:12,005] {logging_mixin.py:115} INFO - [2023-08-13 11:14:12,003] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:14:12,006] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:14:12,029] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.119 seconds
[2023-08-13 11:14:42,093] {processor.py:153} INFO - Started process (PID=241) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:14:42,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:14:42,097] {logging_mixin.py:115} INFO - [2023-08-13 11:14:42,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:14:42,187] {logging_mixin.py:115} INFO - [2023-08-13 11:14:42,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:14:42,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:14:42,209] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.121 seconds
[2023-08-13 11:15:12,287] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:15:12,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:15:12,291] {logging_mixin.py:115} INFO - [2023-08-13 11:15:12,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:15:12,406] {logging_mixin.py:115} INFO - [2023-08-13 11:15:12,404] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:15:12,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:15:12,434] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.153 seconds
[2023-08-13 11:15:42,513] {processor.py:153} INFO - Started process (PID=251) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:15:42,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:15:42,516] {logging_mixin.py:115} INFO - [2023-08-13 11:15:42,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:15:42,621] {logging_mixin.py:115} INFO - [2023-08-13 11:15:42,620] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:15:42,622] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:15:42,646] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.138 seconds
[2023-08-13 11:16:12,733] {processor.py:153} INFO - Started process (PID=256) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:16:12,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:16:12,736] {logging_mixin.py:115} INFO - [2023-08-13 11:16:12,736] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:16:12,831] {logging_mixin.py:115} INFO - [2023-08-13 11:16:12,829] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:16:12,831] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:16:12,852] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.126 seconds
[2023-08-13 11:16:42,918] {processor.py:153} INFO - Started process (PID=261) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:16:42,920] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:16:42,922] {logging_mixin.py:115} INFO - [2023-08-13 11:16:42,921] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:16:43,019] {logging_mixin.py:115} INFO - [2023-08-13 11:16:43,018] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    *generate_spark_submit_command('{{ params.spark_submit_cmd }}', eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:16:43,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:16:43,041] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.130 seconds
[2023-08-13 11:17:10,991] {processor.py:153} INFO - Started process (PID=266) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:10,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:17:10,994] {logging_mixin.py:115} INFO - [2023-08-13 11:17:10,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:11,005] {logging_mixin.py:115} INFO - [2023-08-13 11:17:11,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 156
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-08-13 11:17:11,006] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:11,032] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.047 seconds
[2023-08-13 11:17:23,486] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:23,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:17:23,491] {logging_mixin.py:115} INFO - [2023-08-13 11:17:23,491] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:23,500] {logging_mixin.py:115} INFO - [2023-08-13 11:17:23,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 156
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-08-13 11:17:23,501] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:23,525] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.043 seconds
[2023-08-13 11:17:53,574] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:53,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:17:53,577] {logging_mixin.py:115} INFO - [2023-08-13 11:17:53,577] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:53,584] {logging_mixin.py:115} INFO - [2023-08-13 11:17:53,583] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 156
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-08-13 11:17:53,585] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:17:53,611] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.041 seconds
[2023-08-13 11:18:23,657] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:18:23,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:18:23,660] {logging_mixin.py:115} INFO - [2023-08-13 11:18:23,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:18:23,667] {logging_mixin.py:115} INFO - [2023-08-13 11:18:23,666] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 156
    dag=dag,
      ^
SyntaxError: invalid syntax
[2023-08-13 11:18:23,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:18:23,695] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.042 seconds
[2023-08-13 11:18:52,728] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:18:52,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:18:52,731] {logging_mixin.py:115} INFO - [2023-08-13 11:18:52,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:18:52,921] {logging_mixin.py:115} INFO - [2023-08-13 11:18:52,918] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(spark_submit_cmd, eval(spark_conf_map)),
NameError: name 'spark_submit_cmd' is not defined
[2023-08-13 11:18:52,922] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:18:52,951] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.227 seconds
[2023-08-13 11:19:04,958] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:19:04,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:19:04,960] {logging_mixin.py:115} INFO - [2023-08-13 11:19:04,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:19:05,049] {logging_mixin.py:115} INFO - [2023-08-13 11:19:05,047] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(spark_submit_cmd, eval(spark_conf_map)),
NameError: name 'spark_submit_cmd' is not defined
[2023-08-13 11:19:05,058] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:19:05,077] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.123 seconds
[2023-08-13 11:19:35,150] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:19:35,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:19:35,154] {logging_mixin.py:115} INFO - [2023-08-13 11:19:35,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:19:35,278] {logging_mixin.py:115} INFO - [2023-08-13 11:19:35,275] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(spark_submit_cmd, eval(spark_conf_map)),
NameError: name 'spark_submit_cmd' is not defined
[2023-08-13 11:19:35,279] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:19:35,306] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.160 seconds
[2023-08-13 11:20:05,395] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:05,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:20:05,398] {logging_mixin.py:115} INFO - [2023-08-13 11:20:05,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:05,517] {logging_mixin.py:115} INFO - [2023-08-13 11:20:05,514] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(spark_submit_cmd, eval(spark_conf_map)),
NameError: name 'spark_submit_cmd' is not defined
[2023-08-13 11:20:05,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:05,548] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.159 seconds
[2023-08-13 11:20:35,623] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:35,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:20:35,630] {logging_mixin.py:115} INFO - [2023-08-13 11:20:35,629] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:35,756] {logging_mixin.py:115} INFO - [2023-08-13 11:20:35,753] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(spark_submit_cmd, eval(spark_conf_map)),
NameError: name 'spark_submit_cmd' is not defined
[2023-08-13 11:20:35,757] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:35,787] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.171 seconds
[2023-08-13 11:20:55,687] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:55,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:20:55,691] {logging_mixin.py:115} INFO - [2023-08-13 11:20:55,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:55,848] {logging_mixin.py:115} INFO - [2023-08-13 11:20:55,847] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 143, in <module>
    '{{ params.s3_input }}'
TypeError: 'function' object is not iterable
[2023-08-13 11:20:55,849] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:20:55,872] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.190 seconds
[2023-08-13 11:21:07,651] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:21:07,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:21:07,653] {logging_mixin.py:115} INFO - [2023-08-13 11:21:07,653] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:21:07,740] {logging_mixin.py:115} INFO - [2023-08-13 11:21:07,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 143, in <module>
    '{{ params.s3_input }}'
TypeError: 'function' object is not iterable
[2023-08-13 11:21:07,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:21:07,768] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.121 seconds
[2023-08-13 11:21:37,843] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:21:37,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:21:37,846] {logging_mixin.py:115} INFO - [2023-08-13 11:21:37,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:21:37,942] {logging_mixin.py:115} INFO - [2023-08-13 11:21:37,940] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 143, in <module>
    '{{ params.s3_input }}'
TypeError: 'function' object is not iterable
[2023-08-13 11:21:37,943] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:21:37,967] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.130 seconds
[2023-08-13 11:22:08,038] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:22:08,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:22:08,040] {logging_mixin.py:115} INFO - [2023-08-13 11:22:08,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:22:08,154] {logging_mixin.py:115} INFO - [2023-08-13 11:22:08,152] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 143, in <module>
    '{{ params.s3_input }}'
TypeError: 'function' object is not iterable
[2023-08-13 11:22:08,155] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:22:08,187] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.154 seconds
[2023-08-13 11:22:38,270] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:22:38,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:22:38,273] {logging_mixin.py:115} INFO - [2023-08-13 11:22:38,273] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:22:38,365] {logging_mixin.py:115} INFO - [2023-08-13 11:22:38,363] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 143, in <module>
    '{{ params.s3_input }}'
TypeError: 'function' object is not iterable
[2023-08-13 11:22:38,367] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:22:38,389] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.124 seconds
[2023-08-13 11:23:08,463] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:08,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:23:08,466] {logging_mixin.py:115} INFO - [2023-08-13 11:23:08,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:08,567] {logging_mixin.py:115} INFO - [2023-08-13 11:23:08,565] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 143, in <module>
    '{{ params.s3_input }}'
TypeError: 'function' object is not iterable
[2023-08-13 11:23:08,568] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:08,592] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.134 seconds
[2023-08-13 11:23:25,509] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:25,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:23:25,512] {logging_mixin.py:115} INFO - [2023-08-13 11:23:25,512] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:25,629] {logging_mixin.py:115} INFO - [2023-08-13 11:23:25,627] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:23:25,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:25,656] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.152 seconds
[2023-08-13 11:23:51,455] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:51,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:23:51,458] {logging_mixin.py:115} INFO - [2023-08-13 11:23:51,458] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:51,560] {logging_mixin.py:115} INFO - [2023-08-13 11:23:51,558] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:23:51,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:23:51,581] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.130 seconds
[2023-08-13 11:24:21,649] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:24:21,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:24:21,653] {logging_mixin.py:115} INFO - [2023-08-13 11:24:21,653] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:24:21,747] {logging_mixin.py:115} INFO - [2023-08-13 11:24:21,744] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:24:21,748] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:24:21,770] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.126 seconds
[2023-08-13 11:24:51,837] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:24:51,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:24:51,840] {logging_mixin.py:115} INFO - [2023-08-13 11:24:51,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:24:51,933] {logging_mixin.py:115} INFO - [2023-08-13 11:24:51,932] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:24:51,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:24:51,955] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.122 seconds
[2023-08-13 11:25:22,029] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:25:22,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:25:22,033] {logging_mixin.py:115} INFO - [2023-08-13 11:25:22,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:25:22,118] {logging_mixin.py:115} INFO - [2023-08-13 11:25:22,116] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:25:22,118] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:25:22,138] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.114 seconds
[2023-08-13 11:25:52,215] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:25:52,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:25:52,218] {logging_mixin.py:115} INFO - [2023-08-13 11:25:52,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:25:52,301] {logging_mixin.py:115} INFO - [2023-08-13 11:25:52,300] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:25:52,303] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:25:52,323] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.112 seconds
[2023-08-13 11:26:22,394] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:26:22,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:26:22,397] {logging_mixin.py:115} INFO - [2023-08-13 11:26:22,396] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:26:22,481] {logging_mixin.py:115} INFO - [2023-08-13 11:26:22,478] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:26:22,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:26:22,503] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.114 seconds
[2023-08-13 11:26:52,615] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:26:52,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:26:52,621] {logging_mixin.py:115} INFO - [2023-08-13 11:26:52,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:26:52,851] {logging_mixin.py:115} INFO - [2023-08-13 11:26:52,847] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:26:52,853] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:26:52,936] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 11:27:23,038] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:27:23,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:27:23,041] {logging_mixin.py:115} INFO - [2023-08-13 11:27:23,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:27:23,129] {logging_mixin.py:115} INFO - [2023-08-13 11:27:23,127] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:27:23,130] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:27:23,152] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.118 seconds
[2023-08-13 11:27:53,229] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:27:53,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:27:53,232] {logging_mixin.py:115} INFO - [2023-08-13 11:27:53,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:27:53,323] {logging_mixin.py:115} INFO - [2023-08-13 11:27:53,321] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:27:53,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:27:53,352] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.127 seconds
[2023-08-13 11:28:23,432] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:28:23,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:28:23,437] {logging_mixin.py:115} INFO - [2023-08-13 11:28:23,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:28:23,558] {logging_mixin.py:115} INFO - [2023-08-13 11:28:23,556] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:28:23,559] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:28:23,589] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.162 seconds
[2023-08-13 11:28:53,673] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:28:53,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:28:53,677] {logging_mixin.py:115} INFO - [2023-08-13 11:28:53,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:28:53,779] {logging_mixin.py:115} INFO - [2023-08-13 11:28:53,777] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:28:53,780] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:28:53,802] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.135 seconds
[2023-08-13 11:29:23,875] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:29:23,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:29:23,880] {logging_mixin.py:115} INFO - [2023-08-13 11:29:23,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:29:24,002] {logging_mixin.py:115} INFO - [2023-08-13 11:29:23,988] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:29:24,005] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:29:24,034] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.164 seconds
[2023-08-13 11:29:54,117] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:29:54,119] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:29:54,120] {logging_mixin.py:115} INFO - [2023-08-13 11:29:54,120] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:29:54,222] {logging_mixin.py:115} INFO - [2023-08-13 11:29:54,220] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(fetch_cluster_id_and_paramns()[9], eval(fetch_cluster_id_and_paramns()[10])),
TypeError: 'PythonOperator' object is not callable
[2023-08-13 11:29:54,223] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:29:54,247] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.135 seconds
[2023-08-13 11:30:15,166] {processor.py:153} INFO - Started process (PID=235) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:15,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:30:15,169] {logging_mixin.py:115} INFO - [2023-08-13 11:30:15,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:15,269] {logging_mixin.py:115} INFO - [2023-08-13 11:30:15,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:30:15,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:15,294] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.132 seconds
[2023-08-13 11:30:24,738] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:24,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:30:24,741] {logging_mixin.py:115} INFO - [2023-08-13 11:30:24,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:24,827] {logging_mixin.py:115} INFO - [2023-08-13 11:30:24,825] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:30:24,828] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:24,845] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.110 seconds
[2023-08-13 11:30:54,914] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:54,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:30:54,918] {logging_mixin.py:115} INFO - [2023-08-13 11:30:54,917] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:55,017] {logging_mixin.py:115} INFO - [2023-08-13 11:30:55,014] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:30:55,018] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:30:55,042] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.132 seconds
[2023-08-13 11:31:25,123] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:31:25,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:31:25,126] {logging_mixin.py:115} INFO - [2023-08-13 11:31:25,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:31:25,214] {logging_mixin.py:115} INFO - [2023-08-13 11:31:25,212] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:31:25,216] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:31:25,235] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.116 seconds
[2023-08-13 11:31:55,313] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:31:55,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:31:55,317] {logging_mixin.py:115} INFO - [2023-08-13 11:31:55,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:31:55,426] {logging_mixin.py:115} INFO - [2023-08-13 11:31:55,424] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:31:55,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:31:55,471] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.163 seconds
[2023-08-13 11:32:25,543] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:32:25,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:32:25,545] {logging_mixin.py:115} INFO - [2023-08-13 11:32:25,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:32:25,638] {logging_mixin.py:115} INFO - [2023-08-13 11:32:25,636] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:32:25,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:32:25,660] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.122 seconds
[2023-08-13 11:32:55,746] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:32:55,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:32:55,749] {logging_mixin.py:115} INFO - [2023-08-13 11:32:55,749] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:32:55,846] {logging_mixin.py:115} INFO - [2023-08-13 11:32:55,844] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:32:55,847] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:32:55,869] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.127 seconds
[2023-08-13 11:33:25,952] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:33:25,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:33:25,955] {logging_mixin.py:115} INFO - [2023-08-13 11:33:25,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:33:26,039] {logging_mixin.py:115} INFO - [2023-08-13 11:33:26,037] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:33:26,040] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:33:26,059] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.111 seconds
[2023-08-13 11:33:56,130] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:33:56,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:33:56,133] {logging_mixin.py:115} INFO - [2023-08-13 11:33:56,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:33:56,237] {logging_mixin.py:115} INFO - [2023-08-13 11:33:56,235] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:33:56,238] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:33:56,262] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.136 seconds
[2023-08-13 11:34:26,347] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:34:26,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:34:26,352] {logging_mixin.py:115} INFO - [2023-08-13 11:34:26,352] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:34:26,486] {logging_mixin.py:115} INFO - [2023-08-13 11:34:26,484] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:34:26,487] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:34:26,511] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.168 seconds
[2023-08-13 11:34:56,577] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:34:56,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:34:56,580] {logging_mixin.py:115} INFO - [2023-08-13 11:34:56,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:34:56,662] {logging_mixin.py:115} INFO - [2023-08-13 11:34:56,661] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:34:56,663] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:34:56,684] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.112 seconds
[2023-08-13 11:35:26,821] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:35:26,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:35:26,825] {logging_mixin.py:115} INFO - [2023-08-13 11:35:26,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:35:26,950] {logging_mixin.py:115} INFO - [2023-08-13 11:35:26,948] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:35:26,951] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:35:26,980] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.163 seconds
[2023-08-13 11:35:57,072] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:35:57,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:35:57,074] {logging_mixin.py:115} INFO - [2023-08-13 11:35:57,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:35:57,151] {logging_mixin.py:115} INFO - [2023-08-13 11:35:57,149] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:35:57,152] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:35:57,171] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.103 seconds
[2023-08-13 11:36:27,241] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:36:27,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:36:27,244] {logging_mixin.py:115} INFO - [2023-08-13 11:36:27,244] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:36:27,333] {logging_mixin.py:115} INFO - [2023-08-13 11:36:27,332] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 136, in <module>
    *generate_spark_submit_command(eval('{{ params.spark_submit_cmd }}'), eval('{{ params.spark_conf_map }}')),
  File "<string>", line 1, in <module>
NameError: name 'params' is not defined
[2023-08-13 11:36:27,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:36:27,358] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.123 seconds
[2023-08-13 11:36:57,314] {processor.py:153} INFO - Started process (PID=235) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:36:57,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:36:57,317] {logging_mixin.py:115} INFO - [2023-08-13 11:36:57,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:36:57,433] {logging_mixin.py:115} INFO - [2023-08-13 11:36:57,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:36:57,434] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:36:57,459] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.150 seconds
[2023-08-13 11:37:23,882] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:37:23,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:37:23,887] {logging_mixin.py:115} INFO - [2023-08-13 11:37:23,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:37:23,990] {logging_mixin.py:115} INFO - [2023-08-13 11:37:23,988] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:37:23,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:37:24,012] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.136 seconds
[2023-08-13 11:37:54,081] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:37:54,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:37:54,083] {logging_mixin.py:115} INFO - [2023-08-13 11:37:54,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:37:54,161] {logging_mixin.py:115} INFO - [2023-08-13 11:37:54,159] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:37:54,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:37:54,180] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.104 seconds
[2023-08-13 11:38:24,257] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:38:24,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:38:24,260] {logging_mixin.py:115} INFO - [2023-08-13 11:38:24,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:38:24,362] {logging_mixin.py:115} INFO - [2023-08-13 11:38:24,360] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:38:24,363] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:38:24,385] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.134 seconds
[2023-08-13 11:38:54,460] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:38:54,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:38:54,463] {logging_mixin.py:115} INFO - [2023-08-13 11:38:54,463] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:38:54,546] {logging_mixin.py:115} INFO - [2023-08-13 11:38:54,544] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:38:54,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:38:54,567] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.111 seconds
[2023-08-13 11:39:24,641] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:39:24,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:39:24,645] {logging_mixin.py:115} INFO - [2023-08-13 11:39:24,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:39:24,727] {logging_mixin.py:115} INFO - [2023-08-13 11:39:24,725] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:39:24,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:39:24,747] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.110 seconds
[2023-08-13 11:39:54,816] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:39:54,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:39:54,819] {logging_mixin.py:115} INFO - [2023-08-13 11:39:54,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:39:54,909] {logging_mixin.py:115} INFO - [2023-08-13 11:39:54,907] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 137, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:39:54,909] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:39:54,931] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.120 seconds
[2023-08-13 11:40:16,854] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:16,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:40:16,857] {logging_mixin.py:115} INFO - [2023-08-13 11:40:16,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:16,955] {logging_mixin.py:115} INFO - [2023-08-13 11:40:16,954] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    eval("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "<string>", line 1, in <module>
NameError: name 'ti' is not defined
[2023-08-13 11:40:16,957] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:16,979] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.131 seconds
[2023-08-13 11:40:36,024] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:36,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:40:36,027] {logging_mixin.py:115} INFO - [2023-08-13 11:40:36,027] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:36,147] {logging_mixin.py:115} INFO - [2023-08-13 11:40:36,145] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:40:36,148] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:36,172] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.153 seconds
[2023-08-13 11:40:56,161] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:56,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:40:56,164] {logging_mixin.py:115} INFO - [2023-08-13 11:40:56,164] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:56,271] {logging_mixin.py:115} INFO - [2023-08-13 11:40:56,269] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:40:56,272] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:40:56,297] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.140 seconds
[2023-08-13 11:41:23,230] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:41:23,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:41:23,233] {logging_mixin.py:115} INFO - [2023-08-13 11:41:23,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:41:23,348] {logging_mixin.py:115} INFO - [2023-08-13 11:41:23,346] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:41:23,349] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:41:23,376] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.150 seconds
[2023-08-13 11:41:43,749] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:41:43,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:41:43,752] {logging_mixin.py:115} INFO - [2023-08-13 11:41:43,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:41:43,849] {logging_mixin.py:115} INFO - [2023-08-13 11:41:43,847] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:41:43,850] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:41:43,870] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.126 seconds
[2023-08-13 11:42:12,827] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:12,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:42:12,830] {logging_mixin.py:115} INFO - [2023-08-13 11:42:12,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:12,932] {logging_mixin.py:115} INFO - [2023-08-13 11:42:12,930] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:42:12,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:12,955] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.133 seconds
[2023-08-13 11:42:25,595] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:25,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:42:25,597] {logging_mixin.py:115} INFO - [2023-08-13 11:42:25,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:25,694] {logging_mixin.py:115} INFO - [2023-08-13 11:42:25,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:42:25,694] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:25,714] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.122 seconds
[2023-08-13 11:42:55,787] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:55,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:42:55,790] {logging_mixin.py:115} INFO - [2023-08-13 11:42:55,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:55,888] {logging_mixin.py:115} INFO - [2023-08-13 11:42:55,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:42:55,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:42:55,910] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.127 seconds
[2023-08-13 11:43:25,985] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:43:25,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:43:25,988] {logging_mixin.py:115} INFO - [2023-08-13 11:43:25,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:43:26,077] {logging_mixin.py:115} INFO - [2023-08-13 11:43:26,075] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:43:26,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:43:26,100] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.119 seconds
[2023-08-13 11:43:56,175] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:43:56,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:43:56,178] {logging_mixin.py:115} INFO - [2023-08-13 11:43:56,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:43:56,268] {logging_mixin.py:115} INFO - [2023-08-13 11:43:56,266] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:43:56,269] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:43:56,291] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.120 seconds
[2023-08-13 11:44:26,395] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:44:26,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:44:26,399] {logging_mixin.py:115} INFO - [2023-08-13 11:44:26,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:44:26,502] {logging_mixin.py:115} INFO - [2023-08-13 11:44:26,500] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:44:26,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:44:26,529] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.140 seconds
[2023-08-13 11:44:49,441] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:44:49,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:44:49,443] {logging_mixin.py:115} INFO - [2023-08-13 11:44:49,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:44:49,519] {logging_mixin.py:115} INFO - [2023-08-13 11:44:49,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:44:49,520] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:44:49,537] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.100 seconds
[2023-08-13 11:45:19,599] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:45:19,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:45:19,602] {logging_mixin.py:115} INFO - [2023-08-13 11:45:19,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:45:19,684] {logging_mixin.py:115} INFO - [2023-08-13 11:45:19,682] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:45:19,685] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:45:19,704] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.110 seconds
[2023-08-13 11:45:49,778] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:45:49,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:45:49,781] {logging_mixin.py:115} INFO - [2023-08-13 11:45:49,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:45:49,863] {logging_mixin.py:115} INFO - [2023-08-13 11:45:49,861] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:45:49,864] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:45:49,884] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.111 seconds
[2023-08-13 11:46:19,942] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:46:19,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:46:19,951] {logging_mixin.py:115} INFO - [2023-08-13 11:46:19,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:46:20,026] {logging_mixin.py:115} INFO - [2023-08-13 11:46:20,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:46:20,027] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:46:20,046] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.108 seconds
[2023-08-13 11:46:50,127] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:46:50,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:46:50,130] {logging_mixin.py:115} INFO - [2023-08-13 11:46:50,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:46:50,207] {logging_mixin.py:115} INFO - [2023-08-13 11:46:50,205] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:46:50,208] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:46:50,227] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.104 seconds
[2023-08-13 11:47:20,304] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:47:20,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:47:20,308] {logging_mixin.py:115} INFO - [2023-08-13 11:47:20,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:47:20,402] {logging_mixin.py:115} INFO - [2023-08-13 11:47:20,400] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:47:20,403] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:47:20,426] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.128 seconds
[2023-08-13 11:47:50,501] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:47:50,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:47:50,504] {logging_mixin.py:115} INFO - [2023-08-13 11:47:50,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:47:50,594] {logging_mixin.py:115} INFO - [2023-08-13 11:47:50,593] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:47:50,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:47:50,617] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.120 seconds
[2023-08-13 11:48:20,698] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:48:20,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:48:20,701] {logging_mixin.py:115} INFO - [2023-08-13 11:48:20,700] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:48:20,794] {logging_mixin.py:115} INFO - [2023-08-13 11:48:20,793] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:48:20,795] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:48:20,817] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.124 seconds
[2023-08-13 11:48:50,907] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:48:50,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:48:50,909] {logging_mixin.py:115} INFO - [2023-08-13 11:48:50,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:48:50,999] {logging_mixin.py:115} INFO - [2023-08-13 11:48:50,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:48:51,000] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:48:51,022] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.120 seconds
[2023-08-13 11:49:21,094] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:49:21,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:49:21,096] {logging_mixin.py:115} INFO - [2023-08-13 11:49:21,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:49:21,179] {logging_mixin.py:115} INFO - [2023-08-13 11:49:21,177] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:49:21,180] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:49:21,199] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.110 seconds
[2023-08-13 11:49:51,275] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:49:51,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:49:51,277] {logging_mixin.py:115} INFO - [2023-08-13 11:49:51,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:49:51,374] {logging_mixin.py:115} INFO - [2023-08-13 11:49:51,372] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:49:51,375] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:49:51,403] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.133 seconds
[2023-08-13 11:50:21,477] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:50:21,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:50:21,480] {logging_mixin.py:115} INFO - [2023-08-13 11:50:21,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:50:21,574] {logging_mixin.py:115} INFO - [2023-08-13 11:50:21,573] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:50:21,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:50:21,594] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.121 seconds
[2023-08-13 11:50:51,686] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:50:51,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:50:51,689] {logging_mixin.py:115} INFO - [2023-08-13 11:50:51,689] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:50:51,777] {logging_mixin.py:115} INFO - [2023-08-13 11:50:51,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:50:51,778] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:50:51,796] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.114 seconds
[2023-08-13 11:51:21,877] {processor.py:153} INFO - Started process (PID=235) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:51:21,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:51:21,880] {logging_mixin.py:115} INFO - [2023-08-13 11:51:21,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:51:21,964] {logging_mixin.py:115} INFO - [2023-08-13 11:51:21,962] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:51:21,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:51:21,988] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.116 seconds
[2023-08-13 11:51:52,067] {processor.py:153} INFO - Started process (PID=240) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:51:52,069] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:51:52,070] {logging_mixin.py:115} INFO - [2023-08-13 11:51:52,070] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:51:52,161] {logging_mixin.py:115} INFO - [2023-08-13 11:51:52,159] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:51:52,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:51:52,185] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.122 seconds
[2023-08-13 11:52:22,254] {processor.py:153} INFO - Started process (PID=245) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:52:22,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:52:22,257] {logging_mixin.py:115} INFO - [2023-08-13 11:52:22,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:52:22,331] {logging_mixin.py:115} INFO - [2023-08-13 11:52:22,330] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:52:22,332] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:52:22,351] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.100 seconds
[2023-08-13 11:52:52,453] {processor.py:153} INFO - Started process (PID=250) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:52:52,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:52:52,456] {logging_mixin.py:115} INFO - [2023-08-13 11:52:52,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:52:52,564] {logging_mixin.py:115} INFO - [2023-08-13 11:52:52,562] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:52:52,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:52:52,588] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.140 seconds
[2023-08-13 11:53:22,670] {processor.py:153} INFO - Started process (PID=255) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:53:22,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:53:22,672] {logging_mixin.py:115} INFO - [2023-08-13 11:53:22,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:53:22,761] {logging_mixin.py:115} INFO - [2023-08-13 11:53:22,758] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:53:22,763] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:53:22,782] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.117 seconds
[2023-08-13 11:53:52,841] {processor.py:153} INFO - Started process (PID=260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:53:52,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:53:52,843] {logging_mixin.py:115} INFO - [2023-08-13 11:53:52,843] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:53:52,916] {logging_mixin.py:115} INFO - [2023-08-13 11:53:52,914] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:53:52,917] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:53:52,935] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.098 seconds
[2023-08-13 11:54:23,019] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:54:23,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:54:23,021] {logging_mixin.py:115} INFO - [2023-08-13 11:54:23,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:54:23,113] {logging_mixin.py:115} INFO - [2023-08-13 11:54:23,111] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:54:23,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:54:23,136] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.122 seconds
[2023-08-13 11:54:53,250] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:54:53,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:54:53,252] {logging_mixin.py:115} INFO - [2023-08-13 11:54:53,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:54:53,340] {logging_mixin.py:115} INFO - [2023-08-13 11:54:53,338] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:54:53,341] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:54:53,359] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.114 seconds
[2023-08-13 11:55:23,436] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:55:23,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:55:23,439] {logging_mixin.py:115} INFO - [2023-08-13 11:55:23,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:55:23,519] {logging_mixin.py:115} INFO - [2023-08-13 11:55:23,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:55:23,520] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:55:23,538] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.107 seconds
[2023-08-13 11:55:53,616] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:55:53,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:55:53,619] {logging_mixin.py:115} INFO - [2023-08-13 11:55:53,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:55:53,701] {logging_mixin.py:115} INFO - [2023-08-13 11:55:53,699] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:55:53,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:55:53,722] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.110 seconds
[2023-08-13 11:56:23,789] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:56:23,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:56:23,805] {logging_mixin.py:115} INFO - [2023-08-13 11:56:23,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:56:23,900] {logging_mixin.py:115} INFO - [2023-08-13 11:56:23,898] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:56:23,901] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:56:23,923] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.138 seconds
[2023-08-13 11:56:53,998] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:56:54,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:56:54,001] {logging_mixin.py:115} INFO - [2023-08-13 11:56:54,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:56:54,097] {logging_mixin.py:115} INFO - [2023-08-13 11:56:54,095] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:56:54,097] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:56:54,118] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.125 seconds
[2023-08-13 11:57:24,180] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:24,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:57:24,183] {logging_mixin.py:115} INFO - [2023-08-13 11:57:24,182] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:24,284] {logging_mixin.py:115} INFO - [2023-08-13 11:57:24,282] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:57:24,285] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:24,307] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.133 seconds
[2023-08-13 11:57:31,180] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:31,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:57:31,183] {logging_mixin.py:115} INFO - [2023-08-13 11:57:31,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:31,297] {logging_mixin.py:115} INFO - [2023-08-13 11:57:31,295] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:57:31,316] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:31,353] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.177 seconds
[2023-08-13 11:57:42,219] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:42,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:57:42,222] {logging_mixin.py:115} INFO - [2023-08-13 11:57:42,222] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:42,319] {logging_mixin.py:115} INFO - [2023-08-13 11:57:42,317] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:57:42,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:57:42,343] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.127 seconds
[2023-08-13 11:58:12,407] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:58:12,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:58:12,411] {logging_mixin.py:115} INFO - [2023-08-13 11:58:12,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:58:12,530] {logging_mixin.py:115} INFO - [2023-08-13 11:58:12,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:58:12,533] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:58:12,562] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.161 seconds
[2023-08-13 11:58:42,640] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:58:42,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:58:42,644] {logging_mixin.py:115} INFO - [2023-08-13 11:58:42,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:58:42,767] {logging_mixin.py:115} INFO - [2023-08-13 11:58:42,764] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:58:42,768] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:58:42,792] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.160 seconds
[2023-08-13 11:59:12,867] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:59:12,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:59:12,870] {logging_mixin.py:115} INFO - [2023-08-13 11:59:12,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:59:12,967] {logging_mixin.py:115} INFO - [2023-08-13 11:59:12,965] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:59:12,969] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:59:12,994] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.132 seconds
[2023-08-13 11:59:43,064] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:59:43,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 11:59:43,067] {logging_mixin.py:115} INFO - [2023-08-13 11:59:43,067] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:59:43,160] {logging_mixin.py:115} INFO - [2023-08-13 11:59:43,158] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 130, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 80, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 11:59:43,161] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 11:59:43,184] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.124 seconds
[2023-08-13 12:00:10,254] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:10,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:00:10,261] {logging_mixin.py:115} INFO - [2023-08-13 12:00:10,261] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:10,432] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:10,801] {logging_mixin.py:115} INFO - [2023-08-13 12:00:10,801] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:00:10,837] {logging_mixin.py:115} INFO - [2023-08-13 12:00:10,837] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:00:10,862] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.614 seconds
[2023-08-13 12:00:23,751] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:23,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:00:23,753] {logging_mixin.py:115} INFO - [2023-08-13 12:00:23,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:23,850] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:23,867] {logging_mixin.py:115} INFO - [2023-08-13 12:00:23,867] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:00:23,895] {logging_mixin.py:115} INFO - [2023-08-13 12:00:23,895] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:00:23,913] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.165 seconds
[2023-08-13 12:00:53,991] {processor.py:153} INFO - Started process (PID=177) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:53,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:00:53,993] {logging_mixin.py:115} INFO - [2023-08-13 12:00:53,993] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:54,085] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:00:54,112] {logging_mixin.py:115} INFO - [2023-08-13 12:00:54,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:00:54,260] {logging_mixin.py:115} INFO - [2023-08-13 12:00:54,260] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:00:54,275] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.289 seconds
[2023-08-13 12:01:24,363] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:01:24,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:01:24,366] {logging_mixin.py:115} INFO - [2023-08-13 12:01:24,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:01:24,454] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:01:24,480] {logging_mixin.py:115} INFO - [2023-08-13 12:01:24,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:01:24,612] {logging_mixin.py:115} INFO - [2023-08-13 12:01:24,612] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:01:24,626] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.267 seconds
[2023-08-13 12:01:54,722] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:01:54,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:01:54,725] {logging_mixin.py:115} INFO - [2023-08-13 12:01:54,725] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:01:54,805] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:01:54,829] {logging_mixin.py:115} INFO - [2023-08-13 12:01:54,829] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:01:54,966] {logging_mixin.py:115} INFO - [2023-08-13 12:01:54,966] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:01:54,979] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.262 seconds
[2023-08-13 12:02:25,065] {processor.py:153} INFO - Started process (PID=192) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:02:25,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:02:25,068] {logging_mixin.py:115} INFO - [2023-08-13 12:02:25,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:02:25,156] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:02:25,185] {logging_mixin.py:115} INFO - [2023-08-13 12:02:25,185] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:02:25,340] {logging_mixin.py:115} INFO - [2023-08-13 12:02:25,340] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:02:25,357] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 12:02:55,434] {processor.py:153} INFO - Started process (PID=197) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:02:55,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:02:55,437] {logging_mixin.py:115} INFO - [2023-08-13 12:02:55,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:02:55,533] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:02:55,564] {logging_mixin.py:115} INFO - [2023-08-13 12:02:55,563] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:02:55,745] {logging_mixin.py:115} INFO - [2023-08-13 12:02:55,745] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:02:55,768] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 12:03:24,288] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:03:24,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:03:24,291] {logging_mixin.py:115} INFO - [2023-08-13 12:03:24,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:03:24,415] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:03:24,459] {logging_mixin.py:115} INFO - [2023-08-13 12:03:24,459] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:03:24,497] {logging_mixin.py:115} INFO - [2023-08-13 12:03:24,497] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:03:24,805] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.522 seconds
[2023-08-13 12:03:54,891] {processor.py:153} INFO - Started process (PID=177) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:03:54,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:03:54,894] {logging_mixin.py:115} INFO - [2023-08-13 12:03:54,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:03:54,981] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:03:55,005] {logging_mixin.py:115} INFO - [2023-08-13 12:03:55,004] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:03:55,131] {logging_mixin.py:115} INFO - [2023-08-13 12:03:55,131] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:03:55,148] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.261 seconds
[2023-08-13 12:04:25,225] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:04:25,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:04:25,228] {logging_mixin.py:115} INFO - [2023-08-13 12:04:25,228] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:04:25,322] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:04:25,353] {logging_mixin.py:115} INFO - [2023-08-13 12:04:25,353] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:04:25,497] {logging_mixin.py:115} INFO - [2023-08-13 12:04:25,497] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:04:25,516] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 12:04:40,250] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:04:40,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:04:40,253] {logging_mixin.py:115} INFO - [2023-08-13 12:04:40,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:04:40,458] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:04:40,489] {logging_mixin.py:115} INFO - [2023-08-13 12:04:40,488] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:04:40,638] {logging_mixin.py:115} INFO - [2023-08-13 12:04:40,637] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:04:40,660] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.416 seconds
[2023-08-13 12:05:00,170] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:05:00,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:05:00,173] {logging_mixin.py:115} INFO - [2023-08-13 12:05:00,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:05:00,314] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:05:00,368] {logging_mixin.py:115} INFO - [2023-08-13 12:05:00,368] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:05:00,407] {logging_mixin.py:115} INFO - [2023-08-13 12:05:00,407] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:05:00,540] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.376 seconds
[2023-08-13 12:05:30,633] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:05:30,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:05:30,635] {logging_mixin.py:115} INFO - [2023-08-13 12:05:30,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:05:30,728] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:05:30,762] {logging_mixin.py:115} INFO - [2023-08-13 12:05:30,762] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:05:30,909] {logging_mixin.py:115} INFO - [2023-08-13 12:05:30,909] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:05:30,924] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.295 seconds
[2023-08-13 12:06:01,027] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:06:01,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:06:01,032] {logging_mixin.py:115} INFO - [2023-08-13 12:06:01,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:06:01,118] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:06:01,141] {logging_mixin.py:115} INFO - [2023-08-13 12:06:01,141] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:06:01,275] {logging_mixin.py:115} INFO - [2023-08-13 12:06:01,275] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:06:01,290] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.268 seconds
[2023-08-13 12:06:31,387] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:06:31,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:06:31,389] {logging_mixin.py:115} INFO - [2023-08-13 12:06:31,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:06:31,469] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:06:31,494] {logging_mixin.py:115} INFO - [2023-08-13 12:06:31,494] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:06:31,633] {logging_mixin.py:115} INFO - [2023-08-13 12:06:31,633] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:06:31,646] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.264 seconds
[2023-08-13 12:07:01,753] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:07:01,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:07:01,756] {logging_mixin.py:115} INFO - [2023-08-13 12:07:01,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:07:01,853] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:07:01,887] {logging_mixin.py:115} INFO - [2023-08-13 12:07:01,887] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:07:02,034] {logging_mixin.py:115} INFO - [2023-08-13 12:07:02,034] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:07:02,051] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.302 seconds
[2023-08-13 12:07:32,142] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:07:32,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:07:32,144] {logging_mixin.py:115} INFO - [2023-08-13 12:07:32,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:07:32,224] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:07:32,247] {logging_mixin.py:115} INFO - [2023-08-13 12:07:32,247] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:07:32,378] {logging_mixin.py:115} INFO - [2023-08-13 12:07:32,378] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:07:32,394] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.256 seconds
[2023-08-13 12:08:02,481] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:08:02,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:08:02,483] {logging_mixin.py:115} INFO - [2023-08-13 12:08:02,483] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:08:02,569] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:08:02,597] {logging_mixin.py:115} INFO - [2023-08-13 12:08:02,596] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:08:02,733] {logging_mixin.py:115} INFO - [2023-08-13 12:08:02,733] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:08:02,747] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.270 seconds
[2023-08-13 12:08:32,836] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:08:32,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:08:32,839] {logging_mixin.py:115} INFO - [2023-08-13 12:08:32,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:08:32,927] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:08:32,954] {logging_mixin.py:115} INFO - [2023-08-13 12:08:32,954] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:08:33,098] {logging_mixin.py:115} INFO - [2023-08-13 12:08:33,098] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:08:33,111] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.279 seconds
[2023-08-13 12:09:03,198] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:09:03,199] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:09:03,201] {logging_mixin.py:115} INFO - [2023-08-13 12:09:03,200] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:09:03,289] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:09:03,318] {logging_mixin.py:115} INFO - [2023-08-13 12:09:03,318] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:09:03,453] {logging_mixin.py:115} INFO - [2023-08-13 12:09:03,453] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:09:03,466] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.273 seconds
[2023-08-13 12:09:33,538] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:09:33,540] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:09:33,541] {logging_mixin.py:115} INFO - [2023-08-13 12:09:33,541] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:09:33,626] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:09:33,650] {logging_mixin.py:115} INFO - [2023-08-13 12:09:33,650] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:09:33,789] {logging_mixin.py:115} INFO - [2023-08-13 12:09:33,788] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:09:33,804] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.270 seconds
[2023-08-13 12:10:03,879] {processor.py:153} INFO - Started process (PID=226) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:10:03,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:10:03,882] {logging_mixin.py:115} INFO - [2023-08-13 12:10:03,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:10:03,965] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:10:03,989] {logging_mixin.py:115} INFO - [2023-08-13 12:10:03,989] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:10:04,128] {logging_mixin.py:115} INFO - [2023-08-13 12:10:04,128] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:10:04,141] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.267 seconds
[2023-08-13 12:10:34,236] {processor.py:153} INFO - Started process (PID=231) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:10:34,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:10:34,239] {logging_mixin.py:115} INFO - [2023-08-13 12:10:34,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:10:34,323] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:10:34,350] {logging_mixin.py:115} INFO - [2023-08-13 12:10:34,350] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:10:34,477] {logging_mixin.py:115} INFO - [2023-08-13 12:10:34,477] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:10:34,489] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.257 seconds
[2023-08-13 12:11:04,565] {processor.py:153} INFO - Started process (PID=236) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:11:04,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:11:04,567] {logging_mixin.py:115} INFO - [2023-08-13 12:11:04,567] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:11:04,647] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:11:04,670] {logging_mixin.py:115} INFO - [2023-08-13 12:11:04,670] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:11:04,805] {logging_mixin.py:115} INFO - [2023-08-13 12:11:04,805] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:11:04,818] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.257 seconds
[2023-08-13 12:11:34,900] {processor.py:153} INFO - Started process (PID=241) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:11:34,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:11:34,903] {logging_mixin.py:115} INFO - [2023-08-13 12:11:34,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:11:34,981] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:11:35,007] {logging_mixin.py:115} INFO - [2023-08-13 12:11:35,007] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:11:35,140] {logging_mixin.py:115} INFO - [2023-08-13 12:11:35,140] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:11:35,153] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.257 seconds
[2023-08-13 12:12:05,259] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:12:05,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:12:05,262] {logging_mixin.py:115} INFO - [2023-08-13 12:12:05,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:12:05,350] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:12:05,373] {logging_mixin.py:115} INFO - [2023-08-13 12:12:05,373] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:12:05,514] {logging_mixin.py:115} INFO - [2023-08-13 12:12:05,514] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:12:05,528] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.275 seconds
[2023-08-13 12:12:35,628] {processor.py:153} INFO - Started process (PID=251) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:12:35,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:12:35,631] {logging_mixin.py:115} INFO - [2023-08-13 12:12:35,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:12:35,722] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:12:35,750] {logging_mixin.py:115} INFO - [2023-08-13 12:12:35,750] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:12:35,884] {logging_mixin.py:115} INFO - [2023-08-13 12:12:35,884] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:12:35,897] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.273 seconds
[2023-08-13 12:13:05,976] {processor.py:153} INFO - Started process (PID=256) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:05,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:13:05,979] {logging_mixin.py:115} INFO - [2023-08-13 12:13:05,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:06,093] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:06,129] {logging_mixin.py:115} INFO - [2023-08-13 12:13:06,129] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:13:06,289] {logging_mixin.py:115} INFO - [2023-08-13 12:13:06,289] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:13:06,317] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:13:36,401] {processor.py:153} INFO - Started process (PID=261) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:36,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:13:36,405] {logging_mixin.py:115} INFO - [2023-08-13 12:13:36,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:36,498] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:36,524] {logging_mixin.py:115} INFO - [2023-08-13 12:13:36,524] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:13:36,657] {logging_mixin.py:115} INFO - [2023-08-13 12:13:36,657] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:13:36,674] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.278 seconds
[2023-08-13 12:13:49,437] {processor.py:153} INFO - Started process (PID=266) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:49,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:13:49,439] {logging_mixin.py:115} INFO - [2023-08-13 12:13:49,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:49,557] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:13:49,592] {logging_mixin.py:115} INFO - [2023-08-13 12:13:49,592] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:13:49,753] {logging_mixin.py:115} INFO - [2023-08-13 12:13:49,753] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:13:49,771] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 12:14:00,533] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:00,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:14:00,536] {logging_mixin.py:115} INFO - [2023-08-13 12:14:00,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:00,636] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:00,664] {logging_mixin.py:115} INFO - [2023-08-13 12:14:00,664] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:14:00,693] {logging_mixin.py:115} INFO - [2023-08-13 12:14:00,693] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:14:00,830] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.301 seconds
[2023-08-13 12:14:30,910] {processor.py:153} INFO - Started process (PID=177) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:30,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:14:30,913] {logging_mixin.py:115} INFO - [2023-08-13 12:14:30,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:31,004] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:31,031] {logging_mixin.py:115} INFO - [2023-08-13 12:14:31,031] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:14:31,177] {logging_mixin.py:115} INFO - [2023-08-13 12:14:31,177] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:14:31,192] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.287 seconds
[2023-08-13 12:14:52,271] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:52,273] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:14:52,274] {logging_mixin.py:115} INFO - [2023-08-13 12:14:52,274] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:52,385] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:52,416] {logging_mixin.py:115} INFO - [2023-08-13 12:14:52,416] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:14:52,558] {logging_mixin.py:115} INFO - [2023-08-13 12:14:52,558] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:14:52,575] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.308 seconds
[2023-08-13 12:14:58,632] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:58,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:14:58,636] {logging_mixin.py:115} INFO - [2023-08-13 12:14:58,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:58,759] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:14:58,792] {logging_mixin.py:115} INFO - [2023-08-13 12:14:58,792] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:14:58,956] {logging_mixin.py:115} INFO - [2023-08-13 12:14:58,956] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:14:58,976] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 12:15:08,673] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:15:08,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:15:08,675] {logging_mixin.py:115} INFO - [2023-08-13 12:15:08,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:15:08,779] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:15:08,810] {logging_mixin.py:115} INFO - [2023-08-13 12:15:08,810] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:15:08,841] {logging_mixin.py:115} INFO - [2023-08-13 12:15:08,840] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:15:08,977] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.307 seconds
[2023-08-13 12:15:39,070] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:15:39,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:15:39,072] {logging_mixin.py:115} INFO - [2023-08-13 12:15:39,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:15:39,157] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:15:39,181] {logging_mixin.py:115} INFO - [2023-08-13 12:15:39,181] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:15:39,312] {logging_mixin.py:115} INFO - [2023-08-13 12:15:39,312] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:15:39,325] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.260 seconds
[2023-08-13 12:16:09,407] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:09,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:16:09,409] {logging_mixin.py:115} INFO - [2023-08-13 12:16:09,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:09,506] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:09,535] {logging_mixin.py:115} INFO - [2023-08-13 12:16:09,535] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:16:09,682] {logging_mixin.py:115} INFO - [2023-08-13 12:16:09,682] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:16:09,696] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.295 seconds
[2023-08-13 12:16:17,432] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:17,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:16:17,435] {logging_mixin.py:115} INFO - [2023-08-13 12:16:17,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:17,551] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:17,581] {logging_mixin.py:115} INFO - [2023-08-13 12:16:17,581] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:16:17,738] {logging_mixin.py:115} INFO - [2023-08-13 12:16:17,737] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:16:17,755] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.328 seconds
[2023-08-13 12:16:27,760] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:27,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:16:27,762] {logging_mixin.py:115} INFO - [2023-08-13 12:16:27,762] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:27,855] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:27,883] {logging_mixin.py:115} INFO - [2023-08-13 12:16:27,883] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:16:27,907] {logging_mixin.py:115} INFO - [2023-08-13 12:16:27,907] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:16:28,037] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.281 seconds
[2023-08-13 12:16:58,139] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:58,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:16:58,142] {logging_mixin.py:115} INFO - [2023-08-13 12:16:58,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:58,227] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:16:58,250] {logging_mixin.py:115} INFO - [2023-08-13 12:16:58,250] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:16:58,384] {logging_mixin.py:115} INFO - [2023-08-13 12:16:58,384] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:16:58,397] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.263 seconds
[2023-08-13 12:17:28,482] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:17:28,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:17:28,485] {logging_mixin.py:115} INFO - [2023-08-13 12:17:28,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:17:28,588] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:17:28,619] {logging_mixin.py:115} INFO - [2023-08-13 12:17:28,619] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:17:28,773] {logging_mixin.py:115} INFO - [2023-08-13 12:17:28,773] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:17:28,787] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.310 seconds
[2023-08-13 12:17:58,872] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:17:58,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:17:58,875] {logging_mixin.py:115} INFO - [2023-08-13 12:17:58,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:17:58,977] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:17:59,010] {logging_mixin.py:115} INFO - [2023-08-13 12:17:59,010] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:17:59,161] {logging_mixin.py:115} INFO - [2023-08-13 12:17:59,161] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:17:59,175] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.308 seconds
[2023-08-13 12:18:29,233] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:29,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:18:29,236] {logging_mixin.py:115} INFO - [2023-08-13 12:18:29,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:29,331] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:29,364] {logging_mixin.py:115} INFO - [2023-08-13 12:18:29,364] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:18:29,512] {logging_mixin.py:115} INFO - [2023-08-13 12:18:29,512] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:18:29,526] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.298 seconds
[2023-08-13 12:18:30,239] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:30,241] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:18:30,243] {logging_mixin.py:115} INFO - [2023-08-13 12:18:30,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:30,373] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:30,412] {logging_mixin.py:115} INFO - [2023-08-13 12:18:30,412] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:18:30,563] {logging_mixin.py:115} INFO - [2023-08-13 12:18:30,563] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:18:30,582] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:18:40,250] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:40,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:18:40,255] {logging_mixin.py:115} INFO - [2023-08-13 12:18:40,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:40,355] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:40,382] {logging_mixin.py:115} INFO - [2023-08-13 12:18:40,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:18:40,411] {logging_mixin.py:115} INFO - [2023-08-13 12:18:40,411] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:18:40,545] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.299 seconds
[2023-08-13 12:18:46,605] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:46,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:18:46,609] {logging_mixin.py:115} INFO - [2023-08-13 12:18:46,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:46,829] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:18:46,859] {logging_mixin.py:115} INFO - [2023-08-13 12:18:46,859] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:18:47,021] {logging_mixin.py:115} INFO - [2023-08-13 12:18:47,021] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:18:47,089] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.489 seconds
[2023-08-13 12:19:17,203] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:19:17,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:19:17,205] {logging_mixin.py:115} INFO - [2023-08-13 12:19:17,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:19:17,292] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:19:17,321] {logging_mixin.py:115} INFO - [2023-08-13 12:19:17,320] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:19:17,478] {logging_mixin.py:115} INFO - [2023-08-13 12:19:17,478] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:19:17,494] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 12:19:47,577] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:19:47,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:19:47,579] {logging_mixin.py:115} INFO - [2023-08-13 12:19:47,579] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:19:47,675] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:19:47,705] {logging_mixin.py:115} INFO - [2023-08-13 12:19:47,704] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:19:47,853] {logging_mixin.py:115} INFO - [2023-08-13 12:19:47,852] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:19:47,868] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 12:20:17,948] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:17,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:20:17,952] {logging_mixin.py:115} INFO - [2023-08-13 12:20:17,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:18,049] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:18,080] {logging_mixin.py:115} INFO - [2023-08-13 12:20:18,080] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:20:18,225] {logging_mixin.py:115} INFO - [2023-08-13 12:20:18,225] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:20:18,241] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.297 seconds
[2023-08-13 12:20:19,963] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:19,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:20:19,967] {logging_mixin.py:115} INFO - [2023-08-13 12:20:19,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:20,083] {logging_mixin.py:115} INFO - [2023-08-13 12:20:20,081] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 84, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:20:20,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:20,108] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.149 seconds
[2023-08-13 12:20:50,176] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:50,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:20:50,178] {logging_mixin.py:115} INFO - [2023-08-13 12:20:50,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:50,292] {logging_mixin.py:115} INFO - [2023-08-13 12:20:50,290] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 84, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:20:50,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:50,335] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.164 seconds
[2023-08-13 12:20:57,230] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:57,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:20:57,239] {logging_mixin.py:115} INFO - [2023-08-13 12:20:57,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:57,396] {logging_mixin.py:115} INFO - [2023-08-13 12:20:57,394] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:20:57,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:20:57,419] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.195 seconds
[2023-08-13 12:21:08,392] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:08,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:21:08,395] {logging_mixin.py:115} INFO - [2023-08-13 12:21:08,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:08,505] {logging_mixin.py:115} INFO - [2023-08-13 12:21:08,503] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:21:08,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:08,531] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.143 seconds
[2023-08-13 12:21:21,578] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:21,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:21:21,581] {logging_mixin.py:115} INFO - [2023-08-13 12:21:21,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:21,677] {logging_mixin.py:115} INFO - [2023-08-13 12:21:21,676] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:21:21,678] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:21,699] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.124 seconds
[2023-08-13 12:21:29,733] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:29,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:21:29,737] {logging_mixin.py:115} INFO - [2023-08-13 12:21:29,736] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:29,887] {logging_mixin.py:115} INFO - [2023-08-13 12:21:29,885] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:21:29,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:29,911] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.182 seconds
[2023-08-13 12:21:39,911] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:39,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:21:39,913] {logging_mixin.py:115} INFO - [2023-08-13 12:21:39,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:40,005] {logging_mixin.py:115} INFO - [2023-08-13 12:21:40,003] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:21:40,006] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:21:40,025] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.119 seconds
[2023-08-13 12:22:10,101] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:22:10,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:22:10,105] {logging_mixin.py:115} INFO - [2023-08-13 12:22:10,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:22:10,192] {logging_mixin.py:115} INFO - [2023-08-13 12:22:10,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:22:10,193] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:22:10,216] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.130 seconds
[2023-08-13 12:22:40,291] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:22:40,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:22:40,295] {logging_mixin.py:115} INFO - [2023-08-13 12:22:40,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:22:40,388] {logging_mixin.py:115} INFO - [2023-08-13 12:22:40,386] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:22:40,389] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:22:40,410] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.124 seconds
[2023-08-13 12:23:10,508] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:10,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:23:10,511] {logging_mixin.py:115} INFO - [2023-08-13 12:23:10,511] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:10,602] {logging_mixin.py:115} INFO - [2023-08-13 12:23:10,600] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    "{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}"),
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 85, in generate_spark_submit_command
    _conf = [f"{name}={value}" for name, value in spark_conf_map.items()]
AttributeError: 'str' object has no attribute 'items'
[2023-08-13 12:23:10,603] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:10,625] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.122 seconds
[2023-08-13 12:23:28,562] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:28,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:23:28,565] {logging_mixin.py:115} INFO - [2023-08-13 12:23:28,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:28,700] {logging_mixin.py:115} INFO - [2023-08-13 12:23:28,697] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:23:28,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:28,731] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.174 seconds
[2023-08-13 12:23:38,893] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:38,895] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:23:38,896] {logging_mixin.py:115} INFO - [2023-08-13 12:23:38,896] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:38,993] {logging_mixin.py:115} INFO - [2023-08-13 12:23:38,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:23:38,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:23:39,015] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.128 seconds
[2023-08-13 12:24:09,080] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:24:09,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:24:09,083] {logging_mixin.py:115} INFO - [2023-08-13 12:24:09,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:24:09,182] {logging_mixin.py:115} INFO - [2023-08-13 12:24:09,179] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:24:09,183] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:24:09,208] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.132 seconds
[2023-08-13 12:24:39,273] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:24:39,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:24:39,277] {logging_mixin.py:115} INFO - [2023-08-13 12:24:39,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:24:39,399] {logging_mixin.py:115} INFO - [2023-08-13 12:24:39,396] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:24:39,400] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:24:39,428] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.161 seconds
[2023-08-13 12:25:09,500] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:25:09,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:25:09,503] {logging_mixin.py:115} INFO - [2023-08-13 12:25:09,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:25:09,582] {logging_mixin.py:115} INFO - [2023-08-13 12:25:09,579] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:25:09,583] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:25:09,602] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.106 seconds
[2023-08-13 12:25:39,691] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:25:39,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:25:39,694] {logging_mixin.py:115} INFO - [2023-08-13 12:25:39,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:25:39,801] {logging_mixin.py:115} INFO - [2023-08-13 12:25:39,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:25:39,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:25:39,828] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.143 seconds
[2023-08-13 12:26:09,910] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:26:09,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:26:09,912] {logging_mixin.py:115} INFO - [2023-08-13 12:26:09,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:26:10,004] {logging_mixin.py:115} INFO - [2023-08-13 12:26:10,002] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:26:10,005] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:26:10,028] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.123 seconds
[2023-08-13 12:26:40,111] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:26:40,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:26:40,114] {logging_mixin.py:115} INFO - [2023-08-13 12:26:40,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:26:40,247] {logging_mixin.py:115} INFO - [2023-08-13 12:26:40,245] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:26:40,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:26:40,274] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.171 seconds
[2023-08-13 12:27:10,353] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:27:10,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:27:10,356] {logging_mixin.py:115} INFO - [2023-08-13 12:27:10,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:27:10,467] {logging_mixin.py:115} INFO - [2023-08-13 12:27:10,465] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:27:10,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:27:10,492] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.144 seconds
[2023-08-13 12:27:40,580] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:27:40,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:27:40,583] {logging_mixin.py:115} INFO - [2023-08-13 12:27:40,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:27:40,711] {logging_mixin.py:115} INFO - [2023-08-13 12:27:40,707] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:27:40,712] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:27:40,743] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.169 seconds
[2023-08-13 12:28:10,822] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:10,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:28:10,825] {logging_mixin.py:115} INFO - [2023-08-13 12:28:10,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:10,924] {logging_mixin.py:115} INFO - [2023-08-13 12:28:10,922] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 135, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")),
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:28:10,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:10,947] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.130 seconds
[2023-08-13 12:28:35,871] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:35,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:28:35,875] {logging_mixin.py:115} INFO - [2023-08-13 12:28:35,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:35,993] {logging_mixin.py:115} INFO - [2023-08-13 12:28:35,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:28:35,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:36,016] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.150 seconds
[2023-08-13 12:28:45,323] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:45,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:28:45,326] {logging_mixin.py:115} INFO - [2023-08-13 12:28:45,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:45,456] {logging_mixin.py:115} INFO - [2023-08-13 12:28:45,453] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:28:45,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:28:45,521] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.203 seconds
[2023-08-13 12:29:15,629] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:29:15,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:29:15,633] {logging_mixin.py:115} INFO - [2023-08-13 12:29:15,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:29:15,755] {logging_mixin.py:115} INFO - [2023-08-13 12:29:15,752] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:29:15,756] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:29:15,780] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.158 seconds
[2023-08-13 12:29:45,851] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:29:45,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:29:45,854] {logging_mixin.py:115} INFO - [2023-08-13 12:29:45,853] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:29:45,942] {logging_mixin.py:115} INFO - [2023-08-13 12:29:45,940] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:29:45,942] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:29:45,962] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.116 seconds
[2023-08-13 12:30:16,031] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:30:16,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:30:16,034] {logging_mixin.py:115} INFO - [2023-08-13 12:30:16,034] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:30:16,126] {logging_mixin.py:115} INFO - [2023-08-13 12:30:16,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:30:16,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:30:16,149] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.123 seconds
[2023-08-13 12:30:46,217] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:30:46,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:30:46,220] {logging_mixin.py:115} INFO - [2023-08-13 12:30:46,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:30:46,304] {logging_mixin.py:115} INFO - [2023-08-13 12:30:46,302] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:30:46,306] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:30:46,341] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.128 seconds
[2023-08-13 12:31:16,433] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:31:16,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:31:16,436] {logging_mixin.py:115} INFO - [2023-08-13 12:31:16,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:31:16,520] {logging_mixin.py:115} INFO - [2023-08-13 12:31:16,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:31:16,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:31:16,545] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.117 seconds
[2023-08-13 12:31:46,621] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:31:46,622] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:31:46,624] {logging_mixin.py:115} INFO - [2023-08-13 12:31:46,623] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:31:46,705] {logging_mixin.py:115} INFO - [2023-08-13 12:31:46,703] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:31:46,705] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:31:46,724] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.108 seconds
[2023-08-13 12:32:16,804] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:16,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:32:16,807] {logging_mixin.py:115} INFO - [2023-08-13 12:32:16,807] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:16,902] {logging_mixin.py:115} INFO - [2023-08-13 12:32:16,900] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:32:16,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:16,925] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.125 seconds
[2023-08-13 12:32:28,679] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:28,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:32:28,682] {logging_mixin.py:115} INFO - [2023-08-13 12:32:28,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:28,773] {logging_mixin.py:115} INFO - [2023-08-13 12:32:28,771] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:32:28,774] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:28,794] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.118 seconds
[2023-08-13 12:32:58,871] {processor.py:153} INFO - Started process (PID=176) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:58,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:32:58,873] {logging_mixin.py:115} INFO - [2023-08-13 12:32:58,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:58,967] {logging_mixin.py:115} INFO - [2023-08-13 12:32:58,964] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:32:58,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:32:58,990] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.124 seconds
[2023-08-13 12:33:29,070] {processor.py:153} INFO - Started process (PID=181) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:33:29,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:33:29,073] {logging_mixin.py:115} INFO - [2023-08-13 12:33:29,073] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:33:29,165] {logging_mixin.py:115} INFO - [2023-08-13 12:33:29,162] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:33:29,166] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:33:29,187] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.121 seconds
[2023-08-13 12:33:59,263] {processor.py:153} INFO - Started process (PID=186) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:33:59,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:33:59,266] {logging_mixin.py:115} INFO - [2023-08-13 12:33:59,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:33:59,355] {logging_mixin.py:115} INFO - [2023-08-13 12:33:59,353] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:33:59,356] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:33:59,378] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.120 seconds
[2023-08-13 12:34:29,451] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:34:29,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:34:29,454] {logging_mixin.py:115} INFO - [2023-08-13 12:34:29,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:34:29,544] {logging_mixin.py:115} INFO - [2023-08-13 12:34:29,542] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:34:29,545] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:34:29,566] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.119 seconds
[2023-08-13 12:34:59,639] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:34:59,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:34:59,642] {logging_mixin.py:115} INFO - [2023-08-13 12:34:59,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:34:59,738] {logging_mixin.py:115} INFO - [2023-08-13 12:34:59,735] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 134, in <module>
    json.loads("{{ ti.xcom_pull(task_ids='fetch_cluster_id_and_paramns', key='return_value')[10] }}")
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)
[2023-08-13 12:34:59,739] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:34:59,770] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.136 seconds
[2023-08-13 12:35:09,673] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:09,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:35:09,676] {logging_mixin.py:115} INFO - [2023-08-13 12:35:09,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:09,835] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:10,076] {logging_mixin.py:115} INFO - [2023-08-13 12:35:10,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:35:10,097] {logging_mixin.py:115} INFO - [2023-08-13 12:35:10,096] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:35:10,114] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.446 seconds
[2023-08-13 12:35:40,197] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:40,199] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:35:40,200] {logging_mixin.py:115} INFO - [2023-08-13 12:35:40,200] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:40,298] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:40,348] {logging_mixin.py:115} INFO - [2023-08-13 12:35:40,348] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:35:40,504] {logging_mixin.py:115} INFO - [2023-08-13 12:35:40,504] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:35:40,524] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.331 seconds
[2023-08-13 12:35:59,235] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:59,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:35:59,238] {logging_mixin.py:115} INFO - [2023-08-13 12:35:59,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:59,341] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:35:59,384] {logging_mixin.py:115} INFO - [2023-08-13 12:35:59,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:35:59,562] {logging_mixin.py:115} INFO - [2023-08-13 12:35:59,561] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:35:59,583] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 12:36:15,665] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:15,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:15,668] {logging_mixin.py:115} INFO - [2023-08-13 12:36:15,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:15,834] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:15,880] {logging_mixin.py:115} INFO - [2023-08-13 12:36:15,880] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:16,028] {logging_mixin.py:115} INFO - [2023-08-13 12:36:16,028] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:36:16,045] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.386 seconds
[2023-08-13 12:36:25,427] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:25,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:25,430] {logging_mixin.py:115} INFO - [2023-08-13 12:36:25,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:25,525] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:25,566] {logging_mixin.py:115} INFO - [2023-08-13 12:36:25,566] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:25,712] {logging_mixin.py:115} INFO - [2023-08-13 12:36:25,712] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:36:25,724] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.302 seconds
[2023-08-13 12:36:41,629] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:41,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:41,631] {logging_mixin.py:115} INFO - [2023-08-13 12:36:41,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:41,795] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:41,823] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:41,853] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:42,028] {logging_mixin.py:115} INFO - [2023-08-13 12:36:42,028] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:42,063] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.439 seconds
[2023-08-13 12:36:42,840] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:42,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:42,843] {logging_mixin.py:115} INFO - [2023-08-13 12:36:42,843] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:42,949] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:42,969] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:42,997] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:43,165] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:43,209] {logging_mixin.py:115} INFO - [2023-08-13 12:36:43,208] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:43,242] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.406 seconds
[2023-08-13 12:36:43,942] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:43,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:43,947] {logging_mixin.py:115} INFO - [2023-08-13 12:36:43,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:44,065] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:44,085] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:44,109] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:44,275] {logging_mixin.py:115} INFO - [2023-08-13 12:36:44,275] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:44,305] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.372 seconds
[2023-08-13 12:36:45,013] {processor.py:153} INFO - Started process (PID=192) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:45,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:45,016] {logging_mixin.py:115} INFO - [2023-08-13 12:36:45,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:45,110] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:45,128] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:45,151] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:45,322] {logging_mixin.py:115} INFO - [2023-08-13 12:36:45,322] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:45,358] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 12:36:45,574] {processor.py:153} INFO - Started process (PID=197) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:45,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:45,581] {logging_mixin.py:115} INFO - [2023-08-13 12:36:45,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:45,746] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:45,778] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:45,809] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:46,000] {logging_mixin.py:115} INFO - [2023-08-13 12:36:45,999] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:46,037] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.471 seconds
[2023-08-13 12:36:46,592] {processor.py:153} INFO - Started process (PID=202) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:46,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:46,595] {logging_mixin.py:115} INFO - [2023-08-13 12:36:46,595] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:46,728] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:46,773] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:46,817] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:47,036] {logging_mixin.py:115} INFO - [2023-08-13 12:36:47,036] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:47,070] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.484 seconds
[2023-08-13 12:36:47,656] {processor.py:153} INFO - Started process (PID=207) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:47,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:47,659] {logging_mixin.py:115} INFO - [2023-08-13 12:36:47,659] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:47,762] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:47,780] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:47,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:47,971] {logging_mixin.py:115} INFO - [2023-08-13 12:36:47,971] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:48,003] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 12:36:48,754] {processor.py:153} INFO - Started process (PID=212) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:48,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:48,757] {logging_mixin.py:115} INFO - [2023-08-13 12:36:48,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:48,867] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:48,887] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:48,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:49,092] {logging_mixin.py:115} INFO - [2023-08-13 12:36:49,092] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:49,124] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.376 seconds
[2023-08-13 12:36:49,828] {processor.py:153} INFO - Started process (PID=217) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:49,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:49,832] {logging_mixin.py:115} INFO - [2023-08-13 12:36:49,832] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:49,965] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:49,989] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:50,020] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:50,233] {logging_mixin.py:115} INFO - [2023-08-13 12:36:50,233] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:50,268] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.445 seconds
[2023-08-13 12:36:50,643] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:50,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:50,647] {logging_mixin.py:115} INFO - [2023-08-13 12:36:50,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:50,751] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:50,772] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:50,796] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:51,016] {logging_mixin.py:115} INFO - [2023-08-13 12:36:51,016] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:51,059] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.422 seconds
[2023-08-13 12:36:51,807] {processor.py:153} INFO - Started process (PID=227) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:51,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:51,825] {logging_mixin.py:115} INFO - [2023-08-13 12:36:51,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:51,925] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:51,943] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:51,977] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:52,162] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:52,203] {logging_mixin.py:115} INFO - [2023-08-13 12:36:52,203] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:52,237] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.435 seconds
[2023-08-13 12:36:52,940] {processor.py:153} INFO - Started process (PID=236) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:52,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:52,943] {logging_mixin.py:115} INFO - [2023-08-13 12:36:52,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:53,063] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:53,109] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:53,167] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:53,379] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:53,388] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:53,407] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:53,460] {logging_mixin.py:115} INFO - [2023-08-13 12:36:53,460] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:53,502] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.567 seconds
[2023-08-13 12:36:54,012] {processor.py:153} INFO - Started process (PID=241) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:54,014] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:54,015] {logging_mixin.py:115} INFO - [2023-08-13 12:36:54,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:54,152] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:54,177] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:54,214] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:54,419] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:54,456] {logging_mixin.py:115} INFO - [2023-08-13 12:36:54,456] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:54,487] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.481 seconds
[2023-08-13 12:36:55,183] {processor.py:153} INFO - Started process (PID=248) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:55,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:55,186] {logging_mixin.py:115} INFO - [2023-08-13 12:36:55,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:55,310] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:55,341] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:55,378] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:55,706] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:55,717] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:55,729] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:55,766] {logging_mixin.py:115} INFO - [2023-08-13 12:36:55,766] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:55,801] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.623 seconds
[2023-08-13 12:36:56,703] {processor.py:153} INFO - Started process (PID=253) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:56,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:56,707] {logging_mixin.py:115} INFO - [2023-08-13 12:36:56,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:56,857] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:56,876] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:56,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:57,070] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:57,080] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:57,089] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:57,139] {logging_mixin.py:115} INFO - [2023-08-13 12:36:57,139] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:57,198] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.502 seconds
[2023-08-13 12:36:57,841] {processor.py:153} INFO - Started process (PID=260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:57,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:57,845] {logging_mixin.py:115} INFO - [2023-08-13 12:36:57,845] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:57,999] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:58,038] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:58,076] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:58,286] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:58,301] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:58,312] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:58,358] {logging_mixin.py:115} INFO - [2023-08-13 12:36:58,358] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:58,399] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.566 seconds
[2023-08-13 12:36:58,881] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:58,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:58,885] {logging_mixin.py:115} INFO - [2023-08-13 12:36:58,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:59,052] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:59,077] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:36:59,113] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:36:59,261] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:36:59,306] {logging_mixin.py:115} INFO - [2023-08-13 12:36:59,305] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:36:59,343] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.469 seconds
[2023-08-13 12:36:59,933] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:36:59,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:36:59,937] {logging_mixin.py:115} INFO - [2023-08-13 12:36:59,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:00,044] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:00,075] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:00,120] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:00,284] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:00,322] {logging_mixin.py:115} INFO - [2023-08-13 12:37:00,322] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:00,353] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.426 seconds
[2023-08-13 12:37:01,036] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:01,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:01,039] {logging_mixin.py:115} INFO - [2023-08-13 12:37:01,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:01,131] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:01,148] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:01,171] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:01,308] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:01,348] {logging_mixin.py:115} INFO - [2023-08-13 12:37:01,347] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:01,379] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 12:37:01,750] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:01,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:01,753] {logging_mixin.py:115} INFO - [2023-08-13 12:37:01,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:01,849] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:01,866] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:01,889] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:02,009] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:02,044] {logging_mixin.py:115} INFO - [2023-08-13 12:37:02,044] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:02,071] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:37:02,746] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:02,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:02,748] {logging_mixin.py:115} INFO - [2023-08-13 12:37:02,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:02,836] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:02,854] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:02,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:03,007] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:03,043] {logging_mixin.py:115} INFO - [2023-08-13 12:37:03,043] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:03,071] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 12:37:03,792] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:03,793] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:03,794] {logging_mixin.py:115} INFO - [2023-08-13 12:37:03,794] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:03,884] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:03,901] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:03,921] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:04,038] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:04,076] {logging_mixin.py:115} INFO - [2023-08-13 12:37:04,076] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:04,103] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.316 seconds
[2023-08-13 12:37:04,840] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:04,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:04,843] {logging_mixin.py:115} INFO - [2023-08-13 12:37:04,843] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:04,926] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:04,941] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:04,962] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:05,078] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:05,112] {logging_mixin.py:115} INFO - [2023-08-13 12:37:05,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:05,140] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.303 seconds
[2023-08-13 12:37:05,639] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:05,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:05,642] {logging_mixin.py:115} INFO - [2023-08-13 12:37:05,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:05,745] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:05,763] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:05,786] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:05,938] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:05,978] {logging_mixin.py:115} INFO - [2023-08-13 12:37:05,978] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:06,011] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 12:37:06,743] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:06,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:06,745] {logging_mixin.py:115} INFO - [2023-08-13 12:37:06,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:06,842] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:06,864] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:06,888] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:07,020] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:07,028] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:07,036] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:07,068] {logging_mixin.py:115} INFO - [2023-08-13 12:37:07,068] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:07,130] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.392 seconds
[2023-08-13 12:37:07,789] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:07,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:07,792] {logging_mixin.py:115} INFO - [2023-08-13 12:37:07,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:07,889] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:07,909] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:07,933] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:08,075] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:08,130] {logging_mixin.py:115} INFO - [2023-08-13 12:37:08,130] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:08,171] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.387 seconds
[2023-08-13 12:37:08,844] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:08,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:08,849] {logging_mixin.py:115} INFO - [2023-08-13 12:37:08,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:08,979] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:09,009] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:09,036] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:09,167] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:09,204] {logging_mixin.py:115} INFO - [2023-08-13 12:37:09,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:09,232] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.398 seconds
[2023-08-13 12:37:09,889] {processor.py:153} INFO - Started process (PID=320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:09,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:09,892] {logging_mixin.py:115} INFO - [2023-08-13 12:37:09,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:09,991] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:10,009] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:10,038] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:10,183] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:10,232] {logging_mixin.py:115} INFO - [2023-08-13 12:37:10,232] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:10,270] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.388 seconds
[2023-08-13 12:37:10,521] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:10,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:10,524] {logging_mixin.py:115} INFO - [2023-08-13 12:37:10,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:10,618] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:10,637] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:10,662] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:10,800] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:10,859] {logging_mixin.py:115} INFO - [2023-08-13 12:37:10,859] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:10,905] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.388 seconds
[2023-08-13 12:37:11,813] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:11,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:11,816] {logging_mixin.py:115} INFO - [2023-08-13 12:37:11,816] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:11,903] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:11,921] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:11,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:12,062] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:12,070] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:12,077] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:12,108] {logging_mixin.py:115} INFO - [2023-08-13 12:37:12,108] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:12,139] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 12:37:12,863] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:12,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:12,865] {logging_mixin.py:115} INFO - [2023-08-13 12:37:12,865] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:12,947] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:12,963] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:12,986] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:13,113] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:13,157] {logging_mixin.py:115} INFO - [2023-08-13 12:37:13,157] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:13,189] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 12:37:13,916] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:13,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:13,918] {logging_mixin.py:115} INFO - [2023-08-13 12:37:13,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:14,009] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:14,026] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:14,048] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:14,168] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:14,205] {logging_mixin.py:115} INFO - [2023-08-13 12:37:14,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:14,233] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.322 seconds
[2023-08-13 12:37:14,965] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:14,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:14,968] {logging_mixin.py:115} INFO - [2023-08-13 12:37:14,968] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:15,056] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:15,071] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:15,091] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:15,206] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:15,242] {logging_mixin.py:115} INFO - [2023-08-13 12:37:15,242] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:15,268] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.308 seconds
[2023-08-13 12:37:15,698] {processor.py:153} INFO - Started process (PID=350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:15,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:15,700] {logging_mixin.py:115} INFO - [2023-08-13 12:37:15,700] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:15,797] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:15,814] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:15,840] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:15,962] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:15,998] {logging_mixin.py:115} INFO - [2023-08-13 12:37:15,998] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:16,025] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 12:37:16,861] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:16,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:16,863] {logging_mixin.py:115} INFO - [2023-08-13 12:37:16,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:16,955] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:16,972] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:16,996] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:17,116] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:17,124] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:17,132] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:17,166] {logging_mixin.py:115} INFO - [2023-08-13 12:37:17,166] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:17,199] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 12:37:17,903] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:17,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:17,905] {logging_mixin.py:115} INFO - [2023-08-13 12:37:17,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:18,003] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:18,021] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:18,045] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:18,182] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:18,281] {logging_mixin.py:115} INFO - [2023-08-13 12:37:18,281] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:18,324] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.426 seconds
[2023-08-13 12:37:18,952] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:18,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:18,954] {logging_mixin.py:115} INFO - [2023-08-13 12:37:18,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:19,058] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:19,080] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:19,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:19,253] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:19,291] {logging_mixin.py:115} INFO - [2023-08-13 12:37:19,291] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:19,322] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.375 seconds
[2023-08-13 12:37:20,014] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:20,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:20,017] {logging_mixin.py:115} INFO - [2023-08-13 12:37:20,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:20,114] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:20,131] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:20,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:20,275] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:20,326] {logging_mixin.py:115} INFO - [2023-08-13 12:37:20,326] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:20,357] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 12:37:20,854] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:20,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:20,857] {logging_mixin.py:115} INFO - [2023-08-13 12:37:20,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:20,949] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:20,981] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:21,005] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:21,133] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:21,172] {logging_mixin.py:115} INFO - [2023-08-13 12:37:21,171] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:21,212] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 12:37:21,930] {processor.py:153} INFO - Started process (PID=380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:21,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:21,934] {logging_mixin.py:115} INFO - [2023-08-13 12:37:21,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:22,070] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:22,097] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:22,131] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:22,284] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:22,328] {logging_mixin.py:115} INFO - [2023-08-13 12:37:22,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:22,366] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.441 seconds
[2023-08-13 12:37:22,974] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:22,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:22,976] {logging_mixin.py:115} INFO - [2023-08-13 12:37:22,976] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:23,083] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:23,128] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:23,214] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:23,351] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:23,387] {logging_mixin.py:115} INFO - [2023-08-13 12:37:23,387] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:23,417] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.447 seconds
[2023-08-13 12:37:24,024] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:24,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:24,027] {logging_mixin.py:115} INFO - [2023-08-13 12:37:24,027] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:24,125] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:24,143] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:24,168] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:24,292] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:24,328] {logging_mixin.py:115} INFO - [2023-08-13 12:37:24,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:24,354] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 12:37:25,076] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:25,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:25,080] {logging_mixin.py:115} INFO - [2023-08-13 12:37:25,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:25,190] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:25,212] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:25,241] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:25,374] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:25,413] {logging_mixin.py:115} INFO - [2023-08-13 12:37:25,413] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:25,446] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.375 seconds
[2023-08-13 12:37:25,599] {processor.py:153} INFO - Started process (PID=400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:25,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:25,602] {logging_mixin.py:115} INFO - [2023-08-13 12:37:25,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:25,691] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:25,707] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:25,732] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:25,862] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:25,903] {logging_mixin.py:115} INFO - [2023-08-13 12:37:25,903] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:25,935] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 12:37:26,959] {processor.py:153} INFO - Started process (PID=405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:26,960] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:26,961] {logging_mixin.py:115} INFO - [2023-08-13 12:37:26,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:27,052] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:27,088] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:27,123] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:27,258] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:27,266] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:27,274] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:27,278] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:27,285] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:27,315] {logging_mixin.py:115} INFO - [2023-08-13 12:37:27,315] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:27,340] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.386 seconds
[2023-08-13 12:37:28,008] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:28,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:28,010] {logging_mixin.py:115} INFO - [2023-08-13 12:37:28,010] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:28,094] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:28,109] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:28,130] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:28,249] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:28,291] {logging_mixin.py:115} INFO - [2023-08-13 12:37:28,291] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:28,338] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 12:37:29,037] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:29,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:29,040] {logging_mixin.py:115} INFO - [2023-08-13 12:37:29,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:29,125] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:29,140] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:29,160] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:29,278] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:29,313] {logging_mixin.py:115} INFO - [2023-08-13 12:37:29,313] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:29,341] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 12:37:30,087] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:30,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:30,089] {logging_mixin.py:115} INFO - [2023-08-13 12:37:30,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:30,176] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:30,191] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:30,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:30,336] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:30,375] {logging_mixin.py:115} INFO - [2023-08-13 12:37:30,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:30,403] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 12:37:30,939] {processor.py:153} INFO - Started process (PID=425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:30,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:30,941] {logging_mixin.py:115} INFO - [2023-08-13 12:37:30,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:31,023] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:31,054] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:31,083] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:31,210] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:31,248] {logging_mixin.py:115} INFO - [2023-08-13 12:37:31,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:31,276] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 12:37:31,988] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:31,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:31,990] {logging_mixin.py:115} INFO - [2023-08-13 12:37:31,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:32,067] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:32,083] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:32,102] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:32,220] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:32,254] {logging_mixin.py:115} INFO - [2023-08-13 12:37:32,254] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:32,280] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 12:37:33,038] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:33,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:33,041] {logging_mixin.py:115} INFO - [2023-08-13 12:37:33,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:33,125] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:33,140] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:33,161] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:33,278] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:33,313] {logging_mixin.py:115} INFO - [2023-08-13 12:37:33,313] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:33,340] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 12:37:34,087] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:34,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:34,090] {logging_mixin.py:115} INFO - [2023-08-13 12:37:34,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:34,172] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:34,187] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:34,207] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:34,327] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:34,363] {logging_mixin.py:115} INFO - [2023-08-13 12:37:34,363] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:34,390] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.307 seconds
[2023-08-13 12:37:35,133] {processor.py:153} INFO - Started process (PID=445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:35,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:35,135] {logging_mixin.py:115} INFO - [2023-08-13 12:37:35,135] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:35,218] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:35,233] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:35,254] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:35,378] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:35,415] {logging_mixin.py:115} INFO - [2023-08-13 12:37:35,415] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:35,443] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 12:37:35,775] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:35,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:35,777] {logging_mixin.py:115} INFO - [2023-08-13 12:37:35,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:35,865] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:35,882] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:35,903] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:36,014] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:36,050] {logging_mixin.py:115} INFO - [2023-08-13 12:37:36,050] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:36,076] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 12:37:37,030] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:37,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:37,032] {logging_mixin.py:115} INFO - [2023-08-13 12:37:37,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:37,111] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:37,128] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:37,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:37,266] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:37,274] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:37,283] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:37,314] {logging_mixin.py:115} INFO - [2023-08-13 12:37:37,314] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:37,340] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 12:37:38,085] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:38,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:38,088] {logging_mixin.py:115} INFO - [2023-08-13 12:37:38,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:38,200] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:38,227] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:38,259] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:38,391] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:38,434] {logging_mixin.py:115} INFO - [2023-08-13 12:37:38,434] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:38,467] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.386 seconds
[2023-08-13 12:37:39,132] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:39,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:39,134] {logging_mixin.py:115} INFO - [2023-08-13 12:37:39,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:39,227] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:39,244] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:39,269] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:39,403] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:39,440] {logging_mixin.py:115} INFO - [2023-08-13 12:37:39,439] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:39,469] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 12:37:40,181] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:40,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:40,184] {logging_mixin.py:115} INFO - [2023-08-13 12:37:40,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:40,279] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:40,299] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:40,328] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:40,465] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:40,501] {logging_mixin.py:115} INFO - [2023-08-13 12:37:40,501] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:40,534] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 12:37:40,677] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:40,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:40,679] {logging_mixin.py:115} INFO - [2023-08-13 12:37:40,679] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:40,774] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:40,791] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:40,814] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:40,939] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:40,973] {logging_mixin.py:115} INFO - [2023-08-13 12:37:40,973] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:40,999] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 12:37:42,094] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:42,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:42,097] {logging_mixin.py:115} INFO - [2023-08-13 12:37:42,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:42,209] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:42,230] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:42,263] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:42,428] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:42,438] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:42,448] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:42,488] {logging_mixin.py:115} INFO - [2023-08-13 12:37:42,488] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:42,522] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.433 seconds
[2023-08-13 12:37:43,141] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:43,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:43,154] {logging_mixin.py:115} INFO - [2023-08-13 12:37:43,153] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:43,275] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:43,300] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:43,335] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:43,468] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:43,504] {logging_mixin.py:115} INFO - [2023-08-13 12:37:43,504] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:43,536] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.399 seconds
[2023-08-13 12:37:44,184] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:44,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:44,187] {logging_mixin.py:115} INFO - [2023-08-13 12:37:44,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:44,287] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:44,309] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:44,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:44,478] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:44,515] {logging_mixin.py:115} INFO - [2023-08-13 12:37:44,515] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:44,547] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.368 seconds
[2023-08-13 12:37:45,229] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:45,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:45,232] {logging_mixin.py:115} INFO - [2023-08-13 12:37:45,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:45,365] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:45,391] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:45,427] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:45,636] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:45,676] {logging_mixin.py:115} INFO - [2023-08-13 12:37:45,676] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:45,708] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.484 seconds
[2023-08-13 12:37:45,820] {processor.py:153} INFO - Started process (PID=500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:45,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:45,822] {logging_mixin.py:115} INFO - [2023-08-13 12:37:45,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:45,925] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:45,944] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:45,969] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:46,096] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:46,131] {logging_mixin.py:115} INFO - [2023-08-13 12:37:46,131] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:46,158] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 12:37:47,136] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:47,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:47,139] {logging_mixin.py:115} INFO - [2023-08-13 12:37:47,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:47,235] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:47,255] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:47,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:47,419] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:47,426] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:47,434] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:47,466] {logging_mixin.py:115} INFO - [2023-08-13 12:37:47,466] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:47,494] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 12:37:48,187] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:48,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:48,191] {logging_mixin.py:115} INFO - [2023-08-13 12:37:48,190] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:48,290] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:48,308] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:48,333] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:48,462] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:48,501] {logging_mixin.py:115} INFO - [2023-08-13 12:37:48,501] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:48,529] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:37:49,236] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:49,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:49,239] {logging_mixin.py:115} INFO - [2023-08-13 12:37:49,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:49,336] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:49,355] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:49,380] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:49,507] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:49,544] {logging_mixin.py:115} INFO - [2023-08-13 12:37:49,544] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:49,572] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 12:37:50,283] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:50,291] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:50,293] {logging_mixin.py:115} INFO - [2023-08-13 12:37:50,293] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:50,440] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:50,458] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:50,484] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:50,608] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:50,647] {logging_mixin.py:115} INFO - [2023-08-13 12:37:50,647] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:50,683] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.407 seconds
[2023-08-13 12:37:51,136] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:51,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:51,139] {logging_mixin.py:115} INFO - [2023-08-13 12:37:51,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:51,230] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:51,248] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:51,272] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:51,421] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:51,458] {logging_mixin.py:115} INFO - [2023-08-13 12:37:51,458] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:51,488] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 12:37:52,184] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:52,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:52,186] {logging_mixin.py:115} INFO - [2023-08-13 12:37:52,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:52,282] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:52,301] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:52,326] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:52,480] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:52,524] {logging_mixin.py:115} INFO - [2023-08-13 12:37:52,524] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:52,566] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.387 seconds
[2023-08-13 12:37:53,234] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:53,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:53,237] {logging_mixin.py:115} INFO - [2023-08-13 12:37:53,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:53,346] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:53,368] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:53,398] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:53,532] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:53,569] {logging_mixin.py:115} INFO - [2023-08-13 12:37:53,569] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:53,599] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 12:37:54,279] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:54,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:54,281] {logging_mixin.py:115} INFO - [2023-08-13 12:37:54,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:54,373] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:54,391] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:54,417] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:54,544] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:54,580] {logging_mixin.py:115} INFO - [2023-08-13 12:37:54,580] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:54,608] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 12:37:55,349] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:55,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:55,354] {logging_mixin.py:115} INFO - [2023-08-13 12:37:55,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:55,501] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:55,524] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:55,556] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:55,703] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:55,742] {logging_mixin.py:115} INFO - [2023-08-13 12:37:55,742] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:55,771] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.430 seconds
[2023-08-13 12:37:55,882] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:55,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:55,886] {logging_mixin.py:115} INFO - [2023-08-13 12:37:55,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:56,004] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:56,026] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:56,057] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:56,204] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:56,213] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:56,221] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:56,255] {logging_mixin.py:115} INFO - [2023-08-13 12:37:56,255] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:56,293] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.417 seconds
[2023-08-13 12:37:57,252] {processor.py:153} INFO - Started process (PID=555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:57,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:57,255] {logging_mixin.py:115} INFO - [2023-08-13 12:37:57,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:57,361] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:57,380] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:57,405] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:57,529] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:57,538] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:57,546] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:57,579] {logging_mixin.py:115} INFO - [2023-08-13 12:37:57,579] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:57,608] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 12:37:58,330] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:58,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:58,333] {logging_mixin.py:115} INFO - [2023-08-13 12:37:58,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:58,445] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:58,465] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:58,491] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:58,624] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:58,661] {logging_mixin.py:115} INFO - [2023-08-13 12:37:58,661] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:58,690] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.387 seconds
[2023-08-13 12:37:59,363] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:59,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:37:59,366] {logging_mixin.py:115} INFO - [2023-08-13 12:37:59,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:59,478] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:37:59,498] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:37:59,535] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:37:59,715] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:18:53.332896+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:37:59,753] {logging_mixin.py:115} INFO - [2023-08-13 12:37:59,753] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:37:59,771] {logging_mixin.py:115} INFO - [2023-08-13 12:37:59,771] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:37:59,782] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.423 seconds
[2023-08-13 12:38:29,873] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:38:29,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:38:29,876] {logging_mixin.py:115} INFO - [2023-08-13 12:38:29,876] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:38:29,972] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:38:30,017] {logging_mixin.py:115} INFO - [2023-08-13 12:38:30,017] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:38:30,157] {logging_mixin.py:115} INFO - [2023-08-13 12:38:30,157] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:38:30,170] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.302 seconds
[2023-08-13 12:39:00,263] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:39:00,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:39:00,268] {logging_mixin.py:115} INFO - [2023-08-13 12:39:00,268] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:39:00,359] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:39:00,402] {logging_mixin.py:115} INFO - [2023-08-13 12:39:00,402] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:39:00,536] {logging_mixin.py:115} INFO - [2023-08-13 12:39:00,536] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:39:00,548] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.290 seconds
[2023-08-13 12:39:30,640] {processor.py:153} INFO - Started process (PID=580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:39:30,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:39:30,642] {logging_mixin.py:115} INFO - [2023-08-13 12:39:30,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:39:30,744] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:39:30,791] {logging_mixin.py:115} INFO - [2023-08-13 12:39:30,791] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:39:30,927] {logging_mixin.py:115} INFO - [2023-08-13 12:39:30,927] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:39:30,940] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.305 seconds
[2023-08-13 12:40:01,070] {processor.py:153} INFO - Started process (PID=585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:40:01,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:40:01,072] {logging_mixin.py:115} INFO - [2023-08-13 12:40:01,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:40:01,169] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:40:01,235] {logging_mixin.py:115} INFO - [2023-08-13 12:40:01,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:40:01,387] {logging_mixin.py:115} INFO - [2023-08-13 12:40:01,387] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:40:01,408] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 12:40:31,518] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:40:31,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:40:31,521] {logging_mixin.py:115} INFO - [2023-08-13 12:40:31,521] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:40:31,615] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:40:31,658] {logging_mixin.py:115} INFO - [2023-08-13 12:40:31,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:40:31,797] {logging_mixin.py:115} INFO - [2023-08-13 12:40:31,797] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:40:31,813] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.299 seconds
[2023-08-13 12:41:01,898] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:01,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:01,901] {logging_mixin.py:115} INFO - [2023-08-13 12:41:01,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:01,994] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:02,036] {logging_mixin.py:115} INFO - [2023-08-13 12:41:02,036] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:02,183] {logging_mixin.py:115} INFO - [2023-08-13 12:41:02,183] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:41:02,197] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.303 seconds
[2023-08-13 12:41:32,273] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:32,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:32,276] {logging_mixin.py:115} INFO - [2023-08-13 12:41:32,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:32,362] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:32,400] {logging_mixin.py:115} INFO - [2023-08-13 12:41:32,400] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:32,538] {logging_mixin.py:115} INFO - [2023-08-13 12:41:32,537] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:41:32,552] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.283 seconds
[2023-08-13 12:41:53,541] {processor.py:153} INFO - Started process (PID=605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:53,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:53,544] {logging_mixin.py:115} INFO - [2023-08-13 12:41:53,544] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:53,650] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:53,672] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:53,698] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:53,836] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:53,874] {logging_mixin.py:115} INFO - [2023-08-13 12:41:53,874] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:53,907] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 12:41:54,688] {processor.py:153} INFO - Started process (PID=612) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:54,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:54,690] {logging_mixin.py:115} INFO - [2023-08-13 12:41:54,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:54,790] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:54,809] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:54,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:54,970] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:54,978] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:54,986] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:55,018] {logging_mixin.py:115} INFO - [2023-08-13 12:41:55,017] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:55,044] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.361 seconds
[2023-08-13 12:41:55,756] {processor.py:153} INFO - Started process (PID=617) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:55,758] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:55,760] {logging_mixin.py:115} INFO - [2023-08-13 12:41:55,760] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:55,866] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:55,884] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:55,910] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:56,045] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:56,082] {logging_mixin.py:115} INFO - [2023-08-13 12:41:56,082] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:56,122] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.373 seconds
[2023-08-13 12:41:56,910] {processor.py:153} INFO - Started process (PID=626) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:56,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:56,913] {logging_mixin.py:115} INFO - [2023-08-13 12:41:56,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:57,029] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:57,049] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:57,074] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:57,211] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:57,220] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:57,228] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:57,276] {logging_mixin.py:115} INFO - [2023-08-13 12:41:57,276] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:57,306] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.401 seconds
[2023-08-13 12:41:57,972] {processor.py:153} INFO - Started process (PID=631) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:57,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:57,975] {logging_mixin.py:115} INFO - [2023-08-13 12:41:57,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:58,080] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:58,100] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:58,126] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:58,267] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:58,306] {logging_mixin.py:115} INFO - [2023-08-13 12:41:58,306] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:58,322] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 12:41:58,614] {processor.py:153} INFO - Started process (PID=638) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:58,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:58,617] {logging_mixin.py:115} INFO - [2023-08-13 12:41:58,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:58,730] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:58,753] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:58,785] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:58,919] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:58,927] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:58,936] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:58,970] {logging_mixin.py:115} INFO - [2023-08-13 12:41:58,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:41:59,000] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.391 seconds
[2023-08-13 12:41:59,659] {processor.py:153} INFO - Started process (PID=643) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:59,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:41:59,662] {logging_mixin.py:115} INFO - [2023-08-13 12:41:59,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:59,762] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:41:59,781] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:41:59,806] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:41:59,947] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:41:59,982] {logging_mixin.py:115} INFO - [2023-08-13 12:41:59,982] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:00,013] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.359 seconds
[2023-08-13 12:42:00,770] {processor.py:153} INFO - Started process (PID=650) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:00,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:00,773] {logging_mixin.py:115} INFO - [2023-08-13 12:42:00,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:00,870] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:00,890] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:00,913] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:01,031] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:01,038] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:01,046] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:01,078] {logging_mixin.py:115} INFO - [2023-08-13 12:42:01,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:01,104] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 12:42:01,820] {processor.py:153} INFO - Started process (PID=655) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:01,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:01,822] {logging_mixin.py:115} INFO - [2023-08-13 12:42:01,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:01,907] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:01,924] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:01,945] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:02,065] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:02,101] {logging_mixin.py:115} INFO - [2023-08-13 12:42:02,101] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:02,125] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.310 seconds
[2023-08-13 12:42:02,869] {processor.py:153} INFO - Started process (PID=660) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:02,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:02,871] {logging_mixin.py:115} INFO - [2023-08-13 12:42:02,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:02,955] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:02,972] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:02,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:03,109] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:03,144] {logging_mixin.py:115} INFO - [2023-08-13 12:42:03,144] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:03,181] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.316 seconds
[2023-08-13 12:42:03,659] {processor.py:153} INFO - Started process (PID=665) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:03,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:03,662] {logging_mixin.py:115} INFO - [2023-08-13 12:42:03,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:03,745] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:03,761] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:03,782] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:03,900] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:03,936] {logging_mixin.py:115} INFO - [2023-08-13 12:42:03,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:03,965] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.310 seconds
[2023-08-13 12:42:04,720] {processor.py:153} INFO - Started process (PID=670) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:04,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:04,722] {logging_mixin.py:115} INFO - [2023-08-13 12:42:04,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:04,808] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:04,823] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:04,843] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:04,958] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:04,993] {logging_mixin.py:115} INFO - [2023-08-13 12:42:04,993] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:05,020] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.305 seconds
[2023-08-13 12:42:05,775] {processor.py:153} INFO - Started process (PID=675) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:05,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:05,777] {logging_mixin.py:115} INFO - [2023-08-13 12:42:05,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:05,868] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:05,885] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:05,911] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:06,030] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:06,065] {logging_mixin.py:115} INFO - [2023-08-13 12:42:06,065] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:06,095] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:42:06,826] {processor.py:153} INFO - Started process (PID=680) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:06,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:06,829] {logging_mixin.py:115} INFO - [2023-08-13 12:42:06,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:06,913] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:06,930] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:06,953] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:07,070] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:07,105] {logging_mixin.py:115} INFO - [2023-08-13 12:42:07,105] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:07,131] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 12:42:07,988] {processor.py:153} INFO - Started process (PID=685) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:07,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:07,990] {logging_mixin.py:115} INFO - [2023-08-13 12:42:07,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:08,072] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:08,087] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:08,107] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:08,226] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:08,252] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:08,266] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:08,296] {logging_mixin.py:115} INFO - [2023-08-13 12:42:08,296] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:08,328] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 12:42:08,717] {processor.py:153} INFO - Started process (PID=690) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:08,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:08,719] {logging_mixin.py:115} INFO - [2023-08-13 12:42:08,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:08,805] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:08,821] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:08,841] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:08,970] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:09,005] {logging_mixin.py:115} INFO - [2023-08-13 12:42:09,005] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:09,032] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 12:42:09,783] {processor.py:153} INFO - Started process (PID=695) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:09,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:09,786] {logging_mixin.py:115} INFO - [2023-08-13 12:42:09,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:09,884] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:09,905] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:09,932] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:10,066] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:10,121] {logging_mixin.py:115} INFO - [2023-08-13 12:42:10,120] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:10,155] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 12:42:10,831] {processor.py:153} INFO - Started process (PID=700) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:10,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:10,834] {logging_mixin.py:115} INFO - [2023-08-13 12:42:10,834] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:10,933] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:10,952] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:10,977] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:11,105] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:11,155] {logging_mixin.py:115} INFO - [2023-08-13 12:42:11,155] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:11,189] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 12:42:11,253] {processor.py:153} INFO - Started process (PID=705) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:11,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:11,255] {logging_mixin.py:115} INFO - [2023-08-13 12:42:11,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:11,366] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:11,387] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:11,416] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:11,550] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:11,585] {logging_mixin.py:115} INFO - [2023-08-13 12:42:11,585] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:11,619] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 12:42:12,296] {processor.py:153} INFO - Started process (PID=710) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:12,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:12,299] {logging_mixin.py:115} INFO - [2023-08-13 12:42:12,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:12,384] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:12,399] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:12,419] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:12,538] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:12,574] {logging_mixin.py:115} INFO - [2023-08-13 12:42:12,574] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:12,600] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.308 seconds
[2023-08-13 12:42:13,337] {processor.py:153} INFO - Started process (PID=715) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:13,339] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:13,340] {logging_mixin.py:115} INFO - [2023-08-13 12:42:13,340] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:13,436] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:13,455] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:13,483] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:13,607] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:13,642] {logging_mixin.py:115} INFO - [2023-08-13 12:42:13,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:13,669] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 12:42:13,773] {processor.py:153} INFO - Started process (PID=720) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:13,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:13,776] {logging_mixin.py:115} INFO - [2023-08-13 12:42:13,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:13,871] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:13,889] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:13,914] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:14,036] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:14,072] {logging_mixin.py:115} INFO - [2023-08-13 12:42:14,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:14,101] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 12:42:14,822] {processor.py:153} INFO - Started process (PID=725) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:14,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:14,825] {logging_mixin.py:115} INFO - [2023-08-13 12:42:14,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:14,906] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:14,921] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:14,941] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:15,056] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:15,090] {logging_mixin.py:115} INFO - [2023-08-13 12:42:15,090] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:15,115] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.297 seconds
[2023-08-13 12:42:15,866] {processor.py:153} INFO - Started process (PID=730) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:15,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:15,869] {logging_mixin.py:115} INFO - [2023-08-13 12:42:15,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:15,948] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:15,965] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:15,985] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:16,103] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:16,136] {logging_mixin.py:115} INFO - [2023-08-13 12:42:16,136] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:16,161] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.300 seconds
[2023-08-13 12:42:16,925] {processor.py:153} INFO - Started process (PID=735) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:16,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:16,929] {logging_mixin.py:115} INFO - [2023-08-13 12:42:16,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:17,044] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:17,068] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:17,099] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:17,235] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:17,273] {logging_mixin.py:115} INFO - [2023-08-13 12:42:17,273] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:17,306] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.390 seconds
[2023-08-13 12:42:18,038] {processor.py:153} INFO - Started process (PID=740) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:18,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:18,041] {logging_mixin.py:115} INFO - [2023-08-13 12:42:18,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:18,134] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:18,152] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:18,176] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:18,300] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:18,307] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:18,318] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:18,350] {logging_mixin.py:115} INFO - [2023-08-13 12:42:18,350] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:18,377] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 12:42:18,821] {processor.py:153} INFO - Started process (PID=745) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:18,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:18,824] {logging_mixin.py:115} INFO - [2023-08-13 12:42:18,824] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:18,910] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:18,925] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:18,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:19,061] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:19,096] {logging_mixin.py:115} INFO - [2023-08-13 12:42:19,096] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:19,123] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 12:42:19,888] {processor.py:153} INFO - Started process (PID=750) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:19,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:19,890] {logging_mixin.py:115} INFO - [2023-08-13 12:42:19,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:19,971] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:19,987] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:20,007] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:20,138] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:20,188] {logging_mixin.py:115} INFO - [2023-08-13 12:42:20,188] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:20,220] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 12:42:20,932] {processor.py:153} INFO - Started process (PID=755) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:20,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:20,934] {logging_mixin.py:115} INFO - [2023-08-13 12:42:20,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:21,016] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:21,031] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:21,051] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:21,167] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:21,202] {logging_mixin.py:115} INFO - [2023-08-13 12:42:21,202] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:21,228] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.300 seconds
[2023-08-13 12:42:21,981] {processor.py:153} INFO - Started process (PID=760) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:21,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:21,984] {logging_mixin.py:115} INFO - [2023-08-13 12:42:21,984] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:22,064] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:22,082] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:22,102] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:22,219] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:22,261] {logging_mixin.py:115} INFO - [2023-08-13 12:42:22,261] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:22,288] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 12:42:23,034] {processor.py:153} INFO - Started process (PID=765) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:23,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:23,036] {logging_mixin.py:115} INFO - [2023-08-13 12:42:23,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:23,118] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:23,134] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:23,158] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:23,280] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:23,319] {logging_mixin.py:115} INFO - [2023-08-13 12:42:23,318] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:23,348] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 12:42:23,879] {processor.py:153} INFO - Started process (PID=770) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:23,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:23,882] {logging_mixin.py:115} INFO - [2023-08-13 12:42:23,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:23,966] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:23,980] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:24,000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:24,118] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:24,153] {logging_mixin.py:115} INFO - [2023-08-13 12:42:24,153] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:24,181] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 12:42:24,939] {processor.py:153} INFO - Started process (PID=775) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:24,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:24,942] {logging_mixin.py:115} INFO - [2023-08-13 12:42:24,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:25,024] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:25,040] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:25,060] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:25,178] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:25,214] {logging_mixin.py:115} INFO - [2023-08-13 12:42:25,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:25,240] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.305 seconds
[2023-08-13 12:42:25,981] {processor.py:153} INFO - Started process (PID=780) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:25,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:25,984] {logging_mixin.py:115} INFO - [2023-08-13 12:42:25,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:26,067] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:26,085] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:26,106] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:26,224] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:26,259] {logging_mixin.py:115} INFO - [2023-08-13 12:42:26,259] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:26,286] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 12:42:27,041] {processor.py:153} INFO - Started process (PID=785) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:27,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:27,043] {logging_mixin.py:115} INFO - [2023-08-13 12:42:27,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:27,129] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:27,145] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:27,165] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:27,282] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:27,290] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:27,298] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:27,329] {logging_mixin.py:115} INFO - [2023-08-13 12:42:27,329] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:27,355] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 12:42:28,085] {processor.py:153} INFO - Started process (PID=790) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:28,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:28,088] {logging_mixin.py:115} INFO - [2023-08-13 12:42:28,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:28,180] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:28,199] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:28,224] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:28,332] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:28,367] {logging_mixin.py:115} INFO - [2023-08-13 12:42:28,367] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:28,394] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 12:42:28,921] {processor.py:153} INFO - Started process (PID=795) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:28,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:28,923] {logging_mixin.py:115} INFO - [2023-08-13 12:42:28,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:29,006] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:29,022] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:29,042] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:29,160] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:29,196] {logging_mixin.py:115} INFO - [2023-08-13 12:42:29,196] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:29,224] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.308 seconds
[2023-08-13 12:42:29,977] {processor.py:153} INFO - Started process (PID=800) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:29,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:29,979] {logging_mixin.py:115} INFO - [2023-08-13 12:42:29,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:30,062] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:30,077] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:30,096] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:30,214] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:30,249] {logging_mixin.py:115} INFO - [2023-08-13 12:42:30,249] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:30,277] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 12:42:31,032] {processor.py:153} INFO - Started process (PID=805) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:31,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:31,035] {logging_mixin.py:115} INFO - [2023-08-13 12:42:31,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:31,142] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:31,162] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:31,190] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:31,325] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:31,373] {logging_mixin.py:115} INFO - [2023-08-13 12:42:31,373] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:31,419] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.392 seconds
[2023-08-13 12:42:32,089] {processor.py:153} INFO - Started process (PID=810) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:32,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:32,094] {logging_mixin.py:115} INFO - [2023-08-13 12:42:32,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:32,240] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:32,272] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:32,301] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:32,453] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:32,490] {logging_mixin.py:115} INFO - [2023-08-13 12:42:32,490] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:32,518] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.435 seconds
[2023-08-13 12:42:33,133] {processor.py:153} INFO - Started process (PID=815) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:33,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:33,136] {logging_mixin.py:115} INFO - [2023-08-13 12:42:33,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:33,232] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:33,252] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:33,280] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:33,418] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:33,458] {logging_mixin.py:115} INFO - [2023-08-13 12:42:33,458] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:33,490] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.361 seconds
[2023-08-13 12:42:33,998] {processor.py:153} INFO - Started process (PID=820) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:34,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:34,002] {logging_mixin.py:115} INFO - [2023-08-13 12:42:34,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:34,102] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:34,120] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:34,144] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:34,267] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:34,314] {logging_mixin.py:115} INFO - [2023-08-13 12:42:34,314] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:34,340] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:42:35,054] {processor.py:153} INFO - Started process (PID=825) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:35,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:35,056] {logging_mixin.py:115} INFO - [2023-08-13 12:42:35,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:35,154] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:35,173] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:35,200] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:35,329] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:35,367] {logging_mixin.py:115} INFO - [2023-08-13 12:42:35,367] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:35,396] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:42:36,100] {processor.py:153} INFO - Started process (PID=830) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:36,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:36,102] {logging_mixin.py:115} INFO - [2023-08-13 12:42:36,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:36,195] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:36,212] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:36,237] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:36,370] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:36,444] {logging_mixin.py:115} INFO - [2023-08-13 12:42:36,444] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:36,483] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.388 seconds
[2023-08-13 12:42:37,116] {processor.py:153} INFO - Started process (PID=835) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:37,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:37,119] {logging_mixin.py:115} INFO - [2023-08-13 12:42:37,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:37,260] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:37,284] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:37,319] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:37,482] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:37,533] {logging_mixin.py:115} INFO - [2023-08-13 12:42:37,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:37,591] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.481 seconds
[2023-08-13 12:42:38,190] {processor.py:153} INFO - Started process (PID=840) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:38,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:38,194] {logging_mixin.py:115} INFO - [2023-08-13 12:42:38,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:38,311] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:38,332] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:38,358] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:38,496] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:38,537] {logging_mixin.py:115} INFO - [2023-08-13 12:42:38,537] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:38,571] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.387 seconds
[2023-08-13 12:42:39,054] {processor.py:153} INFO - Started process (PID=845) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:39,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:39,057] {logging_mixin.py:115} INFO - [2023-08-13 12:42:39,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:39,168] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:39,187] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:39,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:39,347] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:39,384] {logging_mixin.py:115} INFO - [2023-08-13 12:42:39,384] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:39,415] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.365 seconds
[2023-08-13 12:42:40,136] {processor.py:153} INFO - Started process (PID=850) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:40,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:40,140] {logging_mixin.py:115} INFO - [2023-08-13 12:42:40,140] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:40,282] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:40,321] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:40,408] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:40,668] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:40,759] {logging_mixin.py:115} INFO - [2023-08-13 12:42:40,759] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:40,813] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.682 seconds
[2023-08-13 12:42:41,190] {processor.py:153} INFO - Started process (PID=855) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:41,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:41,193] {logging_mixin.py:115} INFO - [2023-08-13 12:42:41,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:41,299] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:41,319] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:41,355] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:41,510] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:41,549] {logging_mixin.py:115} INFO - [2023-08-13 12:42:41,549] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:41,585] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.401 seconds
[2023-08-13 12:42:42,380] {processor.py:153} INFO - Started process (PID=860) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:42,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:42,383] {logging_mixin.py:115} INFO - [2023-08-13 12:42:42,383] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:42,484] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:42,502] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:42,531] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:42,658] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:42,668] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:42,679] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:42,715] {logging_mixin.py:115} INFO - [2023-08-13 12:42:42,715] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:42,744] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.367 seconds
[2023-08-13 12:42:43,421] {processor.py:153} INFO - Started process (PID=865) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:43,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:43,423] {logging_mixin.py:115} INFO - [2023-08-13 12:42:43,423] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:43,520] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:43,539] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:43,565] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:43,696] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:43,733] {logging_mixin.py:115} INFO - [2023-08-13 12:42:43,733] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:43,764] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 12:42:44,111] {processor.py:153} INFO - Started process (PID=870) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:44,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:44,114] {logging_mixin.py:115} INFO - [2023-08-13 12:42:44,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:44,211] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:44,231] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:44,257] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:44,387] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:44,427] {logging_mixin.py:115} INFO - [2023-08-13 12:42:44,427] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:44,457] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 12:42:45,169] {processor.py:153} INFO - Started process (PID=875) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:45,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:45,172] {logging_mixin.py:115} INFO - [2023-08-13 12:42:45,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:45,264] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:45,282] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:45,307] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:45,439] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:45,491] {logging_mixin.py:115} INFO - [2023-08-13 12:42:45,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:45,524] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.359 seconds
[2023-08-13 12:42:46,219] {processor.py:153} INFO - Started process (PID=880) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:46,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:46,222] {logging_mixin.py:115} INFO - [2023-08-13 12:42:46,222] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:46,322] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:46,344] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:46,384] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:46,697] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:46,760] {logging_mixin.py:115} INFO - [2023-08-13 12:42:46,760] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:46,802] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.588 seconds
[2023-08-13 12:42:47,169] {processor.py:153} INFO - Started process (PID=885) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:47,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:47,172] {logging_mixin.py:115} INFO - [2023-08-13 12:42:47,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:47,276] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:47,294] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:47,319] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:47,445] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:47,482] {logging_mixin.py:115} INFO - [2023-08-13 12:42:47,482] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:47,512] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 12:42:48,216] {processor.py:153} INFO - Started process (PID=890) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:48,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:48,219] {logging_mixin.py:115} INFO - [2023-08-13 12:42:48,219] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:48,304] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:48,322] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:48,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:48,466] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:48,503] {logging_mixin.py:115} INFO - [2023-08-13 12:42:48,503] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:48,532] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 12:42:49,173] {processor.py:153} INFO - Started process (PID=895) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:49,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:49,206] {logging_mixin.py:115} INFO - [2023-08-13 12:42:49,206] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:49,286] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:49,301] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:49,321] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:49,441] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:49,480] {logging_mixin.py:115} INFO - [2023-08-13 12:42:49,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:49,511] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 12:42:50,268] {processor.py:153} INFO - Started process (PID=900) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:50,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:50,271] {logging_mixin.py:115} INFO - [2023-08-13 12:42:50,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:50,397] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:50,419] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:50,454] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:50,593] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:50,646] {logging_mixin.py:115} INFO - [2023-08-13 12:42:50,646] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:50,679] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.415 seconds
[2023-08-13 12:42:51,337] {processor.py:153} INFO - Started process (PID=905) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:51,339] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:51,342] {logging_mixin.py:115} INFO - [2023-08-13 12:42:51,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:51,508] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:51,540] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:51,572] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:51,718] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:51,773] {logging_mixin.py:115} INFO - [2023-08-13 12:42:51,772] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:51,800] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.471 seconds
[2023-08-13 12:42:52,374] {processor.py:153} INFO - Started process (PID=910) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:52,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:52,377] {logging_mixin.py:115} INFO - [2023-08-13 12:42:52,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:52,463] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:52,479] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:52,500] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:52,621] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:52,659] {logging_mixin.py:115} INFO - [2023-08-13 12:42:52,659] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:52,685] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.316 seconds
[2023-08-13 12:42:53,417] {processor.py:153} INFO - Started process (PID=915) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:53,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:53,419] {logging_mixin.py:115} INFO - [2023-08-13 12:42:53,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:53,507] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:53,523] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:53,545] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:53,663] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:53,711] {logging_mixin.py:115} INFO - [2023-08-13 12:42:53,711] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:53,737] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:42:54,263] {processor.py:153} INFO - Started process (PID=920) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:54,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:54,266] {logging_mixin.py:115} INFO - [2023-08-13 12:42:54,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:54,350] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:54,365] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:54,385] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:54,503] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:54,538] {logging_mixin.py:115} INFO - [2023-08-13 12:42:54,538] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:54,565] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 12:42:55,325] {processor.py:153} INFO - Started process (PID=925) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:55,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:55,328] {logging_mixin.py:115} INFO - [2023-08-13 12:42:55,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:55,420] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:55,436] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:55,465] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:55,588] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:55,626] {logging_mixin.py:115} INFO - [2023-08-13 12:42:55,625] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:55,656] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 12:42:56,381] {processor.py:153} INFO - Started process (PID=930) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:56,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:56,384] {logging_mixin.py:115} INFO - [2023-08-13 12:42:56,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:56,482] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:56,499] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:56,526] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:56,649] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:56,691] {logging_mixin.py:115} INFO - [2023-08-13 12:42:56,691] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:56,722] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 12:42:57,219] {processor.py:153} INFO - Started process (PID=935) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:57,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:57,221] {logging_mixin.py:115} INFO - [2023-08-13 12:42:57,221] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:57,305] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:57,320] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:57,342] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:57,463] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:57,497] {logging_mixin.py:115} INFO - [2023-08-13 12:42:57,497] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:57,524] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 12:42:58,266] {processor.py:153} INFO - Started process (PID=940) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:58,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:58,269] {logging_mixin.py:115} INFO - [2023-08-13 12:42:58,269] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:58,341] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:58,360] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:58,386] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:58,511] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:58,547] {logging_mixin.py:115} INFO - [2023-08-13 12:42:58,547] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:58,575] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 12:42:59,290] {processor.py:153} INFO - Started process (PID=945) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:59,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:42:59,293] {logging_mixin.py:115} INFO - [2023-08-13 12:42:59,292] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:59,379] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:42:59,397] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:42:59,421] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:42:59,550] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:42:59,588] {logging_mixin.py:115} INFO - [2023-08-13 12:42:59,587] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:42:59,617] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.331 seconds
[2023-08-13 12:43:00,375] {processor.py:153} INFO - Started process (PID=950) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:00,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:43:00,379] {logging_mixin.py:115} INFO - [2023-08-13 12:43:00,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:00,477] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:00,494] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:43:00,518] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:43:00,648] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:43:00,692] {logging_mixin.py:115} INFO - [2023-08-13 12:43:00,692] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:43:00,728] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.357 seconds
[2023-08-13 12:43:01,438] {processor.py:153} INFO - Started process (PID=955) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:01,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:43:01,441] {logging_mixin.py:115} INFO - [2023-08-13 12:43:01,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:01,539] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:01,560] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:43:01,589] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:43:01,730] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:36:41.386291+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:43:01,787] {logging_mixin.py:115} INFO - [2023-08-13 12:43:01,786] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:43:01,809] {logging_mixin.py:115} INFO - [2023-08-13 12:43:01,809] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:43:01,821] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.388 seconds
[2023-08-13 12:43:31,916] {processor.py:153} INFO - Started process (PID=960) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:31,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:43:31,918] {logging_mixin.py:115} INFO - [2023-08-13 12:43:31,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:32,013] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:43:32,056] {logging_mixin.py:115} INFO - [2023-08-13 12:43:32,056] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:43:32,194] {logging_mixin.py:115} INFO - [2023-08-13 12:43:32,194] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:43:32,207] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.296 seconds
[2023-08-13 12:44:02,306] {processor.py:153} INFO - Started process (PID=965) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:44:02,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:44:02,309] {logging_mixin.py:115} INFO - [2023-08-13 12:44:02,309] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:44:02,411] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:44:02,466] {logging_mixin.py:115} INFO - [2023-08-13 12:44:02,466] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:44:02,623] {logging_mixin.py:115} INFO - [2023-08-13 12:44:02,623] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:44:02,668] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.368 seconds
[2023-08-13 12:44:32,781] {processor.py:153} INFO - Started process (PID=970) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:44:32,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:44:32,784] {logging_mixin.py:115} INFO - [2023-08-13 12:44:32,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:44:32,927] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:44:32,984] {logging_mixin.py:115} INFO - [2023-08-13 12:44:32,983] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:44:33,181] {logging_mixin.py:115} INFO - [2023-08-13 12:44:33,181] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:44:33,208] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.433 seconds
[2023-08-13 12:45:03,333] {processor.py:153} INFO - Started process (PID=975) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:45:03,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:45:03,336] {logging_mixin.py:115} INFO - [2023-08-13 12:45:03,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:45:03,431] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:45:03,483] {logging_mixin.py:115} INFO - [2023-08-13 12:45:03,483] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:45:03,629] {logging_mixin.py:115} INFO - [2023-08-13 12:45:03,629] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:45:03,643] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 12:45:33,743] {processor.py:153} INFO - Started process (PID=980) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:45:33,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:45:33,749] {logging_mixin.py:115} INFO - [2023-08-13 12:45:33,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:45:34,002] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:45:34,089] {logging_mixin.py:115} INFO - [2023-08-13 12:45:34,088] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:45:34,262] {logging_mixin.py:115} INFO - [2023-08-13 12:45:34,261] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:45:34,279] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.543 seconds
[2023-08-13 12:46:04,429] {processor.py:153} INFO - Started process (PID=985) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:46:04,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:46:04,432] {logging_mixin.py:115} INFO - [2023-08-13 12:46:04,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:46:04,523] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:46:04,561] {logging_mixin.py:115} INFO - [2023-08-13 12:46:04,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:46:04,693] {logging_mixin.py:115} INFO - [2023-08-13 12:46:04,693] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:46:04,706] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 12:46:34,808] {processor.py:153} INFO - Started process (PID=990) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:46:34,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:46:34,811] {logging_mixin.py:115} INFO - [2023-08-13 12:46:34,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:46:34,898] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:46:34,936] {logging_mixin.py:115} INFO - [2023-08-13 12:46:34,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:46:35,067] {logging_mixin.py:115} INFO - [2023-08-13 12:46:35,067] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:46:35,080] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.277 seconds
[2023-08-13 12:47:05,159] {processor.py:153} INFO - Started process (PID=995) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:47:05,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:47:05,162] {logging_mixin.py:115} INFO - [2023-08-13 12:47:05,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:47:05,236] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:47:05,274] {logging_mixin.py:115} INFO - [2023-08-13 12:47:05,274] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:47:05,407] {logging_mixin.py:115} INFO - [2023-08-13 12:47:05,407] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:47:05,418] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.263 seconds
[2023-08-13 12:47:35,501] {processor.py:153} INFO - Started process (PID=1000) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:47:35,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:47:35,503] {logging_mixin.py:115} INFO - [2023-08-13 12:47:35,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:47:35,598] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:47:35,670] {logging_mixin.py:115} INFO - [2023-08-13 12:47:35,670] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:47:35,815] {logging_mixin.py:115} INFO - [2023-08-13 12:47:35,815] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:47:35,833] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 12:48:05,926] {processor.py:153} INFO - Started process (PID=1005) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:48:05,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:48:05,929] {logging_mixin.py:115} INFO - [2023-08-13 12:48:05,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:48:06,029] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:48:06,079] {logging_mixin.py:115} INFO - [2023-08-13 12:48:06,079] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:48:06,227] {logging_mixin.py:115} INFO - [2023-08-13 12:48:06,227] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:48:06,240] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 12:48:36,419] {processor.py:153} INFO - Started process (PID=1010) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:48:36,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:48:36,424] {logging_mixin.py:115} INFO - [2023-08-13 12:48:36,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:48:36,555] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:48:36,610] {logging_mixin.py:115} INFO - [2023-08-13 12:48:36,610] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:48:36,780] {logging_mixin.py:115} INFO - [2023-08-13 12:48:36,780] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:48:36,797] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.386 seconds
[2023-08-13 12:49:06,890] {processor.py:153} INFO - Started process (PID=1015) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:06,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:06,893] {logging_mixin.py:115} INFO - [2023-08-13 12:49:06,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:06,986] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:07,034] {logging_mixin.py:115} INFO - [2023-08-13 12:49:07,034] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:07,172] {logging_mixin.py:115} INFO - [2023-08-13 12:49:07,172] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:49:07,186] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.300 seconds
[2023-08-13 12:49:19,926] {processor.py:153} INFO - Started process (PID=1020) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:19,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:19,929] {logging_mixin.py:115} INFO - [2023-08-13 12:49:19,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:20,050] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:20,271] {logging_mixin.py:115} INFO - [2023-08-13 12:49:20,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:20,293] {logging_mixin.py:115} INFO - [2023-08-13 12:49:20,293] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:49:20,322] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.401 seconds
[2023-08-13 12:49:33,362] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:33,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:33,365] {logging_mixin.py:115} INFO - [2023-08-13 12:49:33,365] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:33,546] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:33,565] {logging_mixin.py:115} INFO - [2023-08-13 12:49:33,565] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:33,597] {logging_mixin.py:115} INFO - [2023-08-13 12:49:33,597] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:49:33,615] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.258 seconds
[2023-08-13 12:49:40,478] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:40,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:40,482] {logging_mixin.py:115} INFO - [2023-08-13 12:49:40,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:40,599] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:40,617] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:40,647] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:40,795] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:40,806] {logging_mixin.py:115} INFO - [2023-08-13 12:49:40,806] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:40,862] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.390 seconds
[2023-08-13 12:49:41,647] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:41,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:41,651] {logging_mixin.py:115} INFO - [2023-08-13 12:49:41,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:41,791] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:41,819] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:41,851] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:42,040] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:42,050] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:42,058] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:42,072] {logging_mixin.py:115} INFO - [2023-08-13 12:49:42,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:42,110] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.469 seconds
[2023-08-13 12:49:42,707] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:42,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:42,710] {logging_mixin.py:115} INFO - [2023-08-13 12:49:42,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:42,895] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:42,924] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:42,957] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:43,092] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:43,103] {logging_mixin.py:115} INFO - [2023-08-13 12:49:43,103] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:43,140] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.437 seconds
[2023-08-13 12:49:43,310] {processor.py:153} INFO - Started process (PID=194) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:43,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:43,314] {logging_mixin.py:115} INFO - [2023-08-13 12:49:43,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:43,445] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:43,504] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:43,548] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:43,734] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:43,749] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:43,763] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:43,776] {logging_mixin.py:115} INFO - [2023-08-13 12:49:43,776] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:43,832] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.527 seconds
[2023-08-13 12:49:44,426] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:44,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:44,429] {logging_mixin.py:115} INFO - [2023-08-13 12:49:44,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:44,546] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:44,570] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:44,603] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:44,791] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:44,805] {logging_mixin.py:115} INFO - [2023-08-13 12:49:44,805] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:44,871] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.450 seconds
[2023-08-13 12:49:45,597] {processor.py:153} INFO - Started process (PID=208) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:45,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:45,603] {logging_mixin.py:115} INFO - [2023-08-13 12:49:45,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:45,778] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:45,801] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:45,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:45,986] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:45,995] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:46,004] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:46,012] {logging_mixin.py:115} INFO - [2023-08-13 12:49:46,012] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:46,050] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.469 seconds
[2023-08-13 12:49:46,661] {processor.py:153} INFO - Started process (PID=213) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:46,663] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:49:46,666] {logging_mixin.py:115} INFO - [2023-08-13 12:49:46,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:46,826] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:49:46,850] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:49:46,885] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:49:47,067] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:49:47,078] {logging_mixin.py:115} INFO - [2023-08-13 12:49:47,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:49:47,109] {logging_mixin.py:115} INFO - [2023-08-13 12:49:47,109] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:49:47,136] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.481 seconds
[2023-08-13 12:50:17,244] {processor.py:153} INFO - Started process (PID=218) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:50:17,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:50:17,247] {logging_mixin.py:115} INFO - [2023-08-13 12:50:17,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:50:17,338] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:50:17,376] {logging_mixin.py:115} INFO - [2023-08-13 12:50:17,376] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:50:17,504] {logging_mixin.py:115} INFO - [2023-08-13 12:50:17,504] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:50:17,519] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.279 seconds
[2023-08-13 12:50:47,623] {processor.py:153} INFO - Started process (PID=223) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:50:47,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:50:47,627] {logging_mixin.py:115} INFO - [2023-08-13 12:50:47,627] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:50:47,760] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:50:47,830] {logging_mixin.py:115} INFO - [2023-08-13 12:50:47,830] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:50:48,004] {logging_mixin.py:115} INFO - [2023-08-13 12:50:48,004] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:50:48,021] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.403 seconds
[2023-08-13 12:51:17,110] {processor.py:153} INFO - Started process (PID=228) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:17,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:17,114] {logging_mixin.py:115} INFO - [2023-08-13 12:51:17,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:17,251] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:17,486] {logging_mixin.py:115} INFO - [2023-08-13 12:51:17,486] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:17,511] {logging_mixin.py:115} INFO - [2023-08-13 12:51:17,511] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:51:17,530] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.425 seconds
[2023-08-13 12:51:30,307] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:30,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:30,310] {logging_mixin.py:115} INFO - [2023-08-13 12:51:30,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:30,413] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:30,430] {logging_mixin.py:115} INFO - [2023-08-13 12:51:30,430] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:30,456] {logging_mixin.py:115} INFO - [2023-08-13 12:51:30,455] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:51:30,470] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.167 seconds
[2023-08-13 12:51:32,456] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:32,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:32,459] {logging_mixin.py:115} INFO - [2023-08-13 12:51:32,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:32,553] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:32,571] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:32,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:32,723] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:32,733] {logging_mixin.py:115} INFO - [2023-08-13 12:51:32,733] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:32,762] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 12:51:33,583] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:33,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:33,586] {logging_mixin.py:115} INFO - [2023-08-13 12:51:33,586] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:33,685] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:33,704] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:33,730] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:33,870] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:33,878] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:33,887] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:33,899] {logging_mixin.py:115} INFO - [2023-08-13 12:51:33,899] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:33,931] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 12:51:34,646] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:34,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:34,649] {logging_mixin.py:115} INFO - [2023-08-13 12:51:34,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:34,754] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:34,776] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:34,802] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:34,937] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:34,948] {logging_mixin.py:115} INFO - [2023-08-13 12:51:34,948] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:34,978] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 12:51:35,256] {processor.py:153} INFO - Started process (PID=192) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:35,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:35,259] {logging_mixin.py:115} INFO - [2023-08-13 12:51:35,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:35,368] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:35,390] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:35,419] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:35,570] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:35,584] {logging_mixin.py:115} INFO - [2023-08-13 12:51:35,584] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:35,621] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 12:51:36,345] {processor.py:153} INFO - Started process (PID=197) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:36,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:36,349] {logging_mixin.py:115} INFO - [2023-08-13 12:51:36,349] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:36,460] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:36,480] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:36,525] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:36,716] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:36,727] {logging_mixin.py:115} INFO - [2023-08-13 12:51:36,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:36,758] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.418 seconds
[2023-08-13 12:51:37,427] {processor.py:153} INFO - Started process (PID=202) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:37,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:37,430] {logging_mixin.py:115} INFO - [2023-08-13 12:51:37,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:37,535] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:37,554] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:37,580] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:37,705] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:37,716] {logging_mixin.py:115} INFO - [2023-08-13 12:51:37,715] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:37,758] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 12:51:38,496] {processor.py:153} INFO - Started process (PID=207) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:38,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:38,500] {logging_mixin.py:115} INFO - [2023-08-13 12:51:38,500] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:38,647] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:38,682] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:38,720] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:38,891] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:38,902] {logging_mixin.py:115} INFO - [2023-08-13 12:51:38,902] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:38,934] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.443 seconds
[2023-08-13 12:51:39,567] {processor.py:153} INFO - Started process (PID=212) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:39,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:39,570] {logging_mixin.py:115} INFO - [2023-08-13 12:51:39,570] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:39,694] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:39,716] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:39,747] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:39,894] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:39,906] {logging_mixin.py:115} INFO - [2023-08-13 12:51:39,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:39,940] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 12:51:40,260] {processor.py:153} INFO - Started process (PID=217) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:40,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:40,264] {logging_mixin.py:115} INFO - [2023-08-13 12:51:40,263] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:40,424] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:40,459] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:40,492] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:40,635] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:40,646] {logging_mixin.py:115} INFO - [2023-08-13 12:51:40,646] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:40,681] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.427 seconds
[2023-08-13 12:51:41,372] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:41,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:41,376] {logging_mixin.py:115} INFO - [2023-08-13 12:51:41,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:41,580] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:41,607] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:41,654] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:41,835] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:41:52.760253+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:41,846] {logging_mixin.py:115} INFO - [2023-08-13 12:51:41,846] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:41,880] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.515 seconds
[2023-08-13 12:51:42,472] {processor.py:153} INFO - Started process (PID=227) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:42,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:42,475] {logging_mixin.py:115} INFO - [2023-08-13 12:51:42,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:42,599] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:42,627] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:42,668] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:42,830] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:42,840] {logging_mixin.py:115} INFO - [2023-08-13 12:51:42,840] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:42,870] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.403 seconds
[2023-08-13 12:51:43,539] {processor.py:153} INFO - Started process (PID=232) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:43,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:43,543] {logging_mixin.py:115} INFO - [2023-08-13 12:51:43,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:43,665] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:43,683] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:43,708] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:43,841] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:43,852] {logging_mixin.py:115} INFO - [2023-08-13 12:51:43,852] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:43,888] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 12:51:44,683] {processor.py:153} INFO - Started process (PID=241) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:44,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:44,687] {logging_mixin.py:115} INFO - [2023-08-13 12:51:44,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:44,839] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:44,880] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:44,921] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:45,089] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:45,097] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:45,105] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:45,113] {logging_mixin.py:115} INFO - [2023-08-13 12:51:45,113] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:45,145] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.467 seconds
[2023-08-13 12:51:45,250] {processor.py:153} INFO - Started process (PID=246) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:45,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:45,253] {logging_mixin.py:115} INFO - [2023-08-13 12:51:45,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:45,395] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:45,429] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:45,473] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:45,695] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:45,714] {logging_mixin.py:115} INFO - [2023-08-13 12:51:45,714] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:45,753] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.509 seconds
[2023-08-13 12:51:46,482] {processor.py:153} INFO - Started process (PID=253) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:46,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:46,487] {logging_mixin.py:115} INFO - [2023-08-13 12:51:46,487] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:46,649] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:46,683] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:46,751] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:46,957] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:46,966] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:46,974] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:46,981] {logging_mixin.py:115} INFO - [2023-08-13 12:51:46,981] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:47,008] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.533 seconds
[2023-08-13 12:51:47,546] {processor.py:153} INFO - Started process (PID=258) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:47,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:47,550] {logging_mixin.py:115} INFO - [2023-08-13 12:51:47,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:47,686] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:47,708] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:47,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:47,958] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:47,998] {logging_mixin.py:115} INFO - [2023-08-13 12:51:47,998] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:48,032] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.491 seconds
[2023-08-13 12:51:48,677] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:48,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:48,680] {logging_mixin.py:115} INFO - [2023-08-13 12:51:48,680] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:48,784] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:48,806] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:48,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:48,974] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:48,982] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:48,991] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:49,051] {logging_mixin.py:115} INFO - [2023-08-13 12:51:49,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:49,094] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.422 seconds
[2023-08-13 12:51:49,837] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:49,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:49,840] {logging_mixin.py:115} INFO - [2023-08-13 12:51:49,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:49,948] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:49,971] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:49,999] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:50,198] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:50,245] {logging_mixin.py:115} INFO - [2023-08-13 12:51:50,245] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:50,281] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.448 seconds
[2023-08-13 12:51:50,368] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:50,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:50,373] {logging_mixin.py:115} INFO - [2023-08-13 12:51:50,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:50,523] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:50,543] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:50,595] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:50,780] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:50,818] {logging_mixin.py:115} INFO - [2023-08-13 12:51:50,818] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:50,846] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.485 seconds
[2023-08-13 12:51:51,469] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:51,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:51,476] {logging_mixin.py:115} INFO - [2023-08-13 12:51:51,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:51,645] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:51,664] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:51,687] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:51,807] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:51,842] {logging_mixin.py:115} INFO - [2023-08-13 12:51:51,842] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:51,872] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.409 seconds
[2023-08-13 12:51:52,507] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:52,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:52,510] {logging_mixin.py:115} INFO - [2023-08-13 12:51:52,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:52,599] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:52,616] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:52,640] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:52,777] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:52,815] {logging_mixin.py:115} INFO - [2023-08-13 12:51:52,814] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:52,847] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 12:51:53,569] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:53,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:53,572] {logging_mixin.py:115} INFO - [2023-08-13 12:51:53,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:53,686] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:53,708] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:53,741] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:53,882] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:53,921] {logging_mixin.py:115} INFO - [2023-08-13 12:51:53,921] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:53,952] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.388 seconds
[2023-08-13 12:51:54,616] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:54,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:54,619] {logging_mixin.py:115} INFO - [2023-08-13 12:51:54,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:54,709] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:54,726] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:54,749] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:54,884] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:54,925] {logging_mixin.py:115} INFO - [2023-08-13 12:51:54,925] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:54,956] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 12:51:55,413] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:55,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:55,415] {logging_mixin.py:115} INFO - [2023-08-13 12:51:55,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:55,514] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:55,532] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:55,559] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:55,726] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:55,764] {logging_mixin.py:115} INFO - [2023-08-13 12:51:55,763] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:55,799] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.391 seconds
[2023-08-13 12:51:56,590] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:56,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:56,597] {logging_mixin.py:115} INFO - [2023-08-13 12:51:56,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:56,721] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:56,745] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:56,778] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:56,922] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:56,958] {logging_mixin.py:115} INFO - [2023-08-13 12:51:56,958] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:56,987] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.405 seconds
[2023-08-13 12:51:57,629] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:57,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:57,632] {logging_mixin.py:115} INFO - [2023-08-13 12:51:57,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:57,724] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:57,741] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:57,765] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:57,898] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:57,920] {logging_mixin.py:115} INFO - [2023-08-13 12:51:57,920] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:57,956] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 12:51:58,680] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:58,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:58,686] {logging_mixin.py:115} INFO - [2023-08-13 12:51:58,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:58,806] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:58,827] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:58,859] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:51:59,002] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:51:59,063] {logging_mixin.py:115} INFO - [2023-08-13 12:51:59,063] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:51:59,096] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.426 seconds
[2023-08-13 12:51:59,745] {processor.py:153} INFO - Started process (PID=320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:59,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:51:59,749] {logging_mixin.py:115} INFO - [2023-08-13 12:51:59,749] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:59,878] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:51:59,902] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:51:59,934] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:00,077] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:00,116] {logging_mixin.py:115} INFO - [2023-08-13 12:52:00,116] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:00,143] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.404 seconds
[2023-08-13 12:52:00,301] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:00,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:00,304] {logging_mixin.py:115} INFO - [2023-08-13 12:52:00,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:00,433] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:00,458] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:00,487] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:00,620] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:00,659] {logging_mixin.py:115} INFO - [2023-08-13 12:52:00,659] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:00,688] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.392 seconds
[2023-08-13 12:52:01,532] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:01,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:01,540] {logging_mixin.py:115} INFO - [2023-08-13 12:52:01,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:01,730] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:01,776] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:01,823] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:01,985] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:01,992] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:02,001] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:02,037] {logging_mixin.py:115} INFO - [2023-08-13 12:52:02,037] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:02,071] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.547 seconds
[2023-08-13 12:52:02,584] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:02,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:02,588] {logging_mixin.py:115} INFO - [2023-08-13 12:52:02,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:02,768] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:02,795] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:02,830] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:02,978] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:03,014] {logging_mixin.py:115} INFO - [2023-08-13 12:52:03,014] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:03,045] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.467 seconds
[2023-08-13 12:52:03,627] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:03,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:03,631] {logging_mixin.py:115} INFO - [2023-08-13 12:52:03,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:03,736] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:03,759] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:03,786] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:03,919] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:03,955] {logging_mixin.py:115} INFO - [2023-08-13 12:52:03,955] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:03,984] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 12:52:04,680] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:04,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:04,683] {logging_mixin.py:115} INFO - [2023-08-13 12:52:04,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:04,785] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:04,805] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:04,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:04,971] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:05,007] {logging_mixin.py:115} INFO - [2023-08-13 12:52:05,007] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:05,037] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 12:52:05,468] {processor.py:153} INFO - Started process (PID=350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:05,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:05,471] {logging_mixin.py:115} INFO - [2023-08-13 12:52:05,471] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:05,584] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:05,602] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:05,637] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:05,768] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:05,803] {logging_mixin.py:115} INFO - [2023-08-13 12:52:05,803] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:05,830] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.367 seconds
[2023-08-13 12:52:06,522] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:06,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:06,525] {logging_mixin.py:115} INFO - [2023-08-13 12:52:06,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:06,627] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:06,649] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:06,680] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:06,814] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:06,850] {logging_mixin.py:115} INFO - [2023-08-13 12:52:06,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:06,884] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.366 seconds
[2023-08-13 12:52:07,571] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:07,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:07,574] {logging_mixin.py:115} INFO - [2023-08-13 12:52:07,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:07,684] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:07,705] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:07,730] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:07,875] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:07,910] {logging_mixin.py:115} INFO - [2023-08-13 12:52:07,910] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:07,942] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 12:52:08,672] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:08,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:08,677] {logging_mixin.py:115} INFO - [2023-08-13 12:52:08,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:08,821] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:08,846] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:08,887] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:09,154] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:09,238] {logging_mixin.py:115} INFO - [2023-08-13 12:52:09,238] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:09,276] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.611 seconds
[2023-08-13 12:52:09,729] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:09,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:09,732] {logging_mixin.py:115} INFO - [2023-08-13 12:52:09,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:09,838] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:09,861] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:09,890] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:10,025] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:10,062] {logging_mixin.py:115} INFO - [2023-08-13 12:52:10,062] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:10,093] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.369 seconds
[2023-08-13 12:52:10,469] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:10,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:10,475] {logging_mixin.py:115} INFO - [2023-08-13 12:52:10,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:10,587] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:10,607] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:10,636] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:10,776] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:10,821] {logging_mixin.py:115} INFO - [2023-08-13 12:52:10,821] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:10,873] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.409 seconds
[2023-08-13 12:52:11,552] {processor.py:153} INFO - Started process (PID=380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:11,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:11,556] {logging_mixin.py:115} INFO - [2023-08-13 12:52:11,556] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:11,658] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:11,677] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:11,703] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:11,832] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:11,869] {logging_mixin.py:115} INFO - [2023-08-13 12:52:11,869] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:11,898] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 12:52:12,601] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:12,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:12,604] {logging_mixin.py:115} INFO - [2023-08-13 12:52:12,604] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:12,701] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:12,719] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:12,744] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:12,876] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:12,920] {logging_mixin.py:115} INFO - [2023-08-13 12:52:12,920] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:12,955] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 12:52:13,653] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:13,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:13,656] {logging_mixin.py:115} INFO - [2023-08-13 12:52:13,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:13,746] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:13,763] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:13,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:13,928] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:13,975] {logging_mixin.py:115} INFO - [2023-08-13 12:52:13,975] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:14,015] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.367 seconds
[2023-08-13 12:52:14,700] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:14,702] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:14,703] {logging_mixin.py:115} INFO - [2023-08-13 12:52:14,703] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:14,852] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:14,888] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:14,929] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:15,066] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:15,126] {logging_mixin.py:115} INFO - [2023-08-13 12:52:15,126] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:15,216] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.522 seconds
[2023-08-13 12:52:15,412] {processor.py:153} INFO - Started process (PID=400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:15,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:15,417] {logging_mixin.py:115} INFO - [2023-08-13 12:52:15,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:15,561] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:15,586] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:15,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:15,872] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:15,935] {logging_mixin.py:115} INFO - [2023-08-13 12:52:15,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:15,994] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.588 seconds
[2023-08-13 12:52:16,599] {processor.py:153} INFO - Started process (PID=405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:16,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:16,603] {logging_mixin.py:115} INFO - [2023-08-13 12:52:16,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:16,707] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:16,727] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:16,755] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:16,910] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:16,918] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:16,928] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:16,974] {logging_mixin.py:115} INFO - [2023-08-13 12:52:16,973] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:17,007] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.414 seconds
[2023-08-13 12:52:17,652] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:17,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:17,655] {logging_mixin.py:115} INFO - [2023-08-13 12:52:17,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:17,793] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:17,833] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:17,882] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:18,119] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:18,169] {logging_mixin.py:115} INFO - [2023-08-13 12:52:18,168] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:18,216] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.569 seconds
[2023-08-13 12:52:18,700] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:18,702] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:18,703] {logging_mixin.py:115} INFO - [2023-08-13 12:52:18,703] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:18,805] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:18,826] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:18,854] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:18,990] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:19,030] {logging_mixin.py:115} INFO - [2023-08-13 12:52:19,030] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:19,065] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.369 seconds
[2023-08-13 12:52:19,790] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:19,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:19,796] {logging_mixin.py:115} INFO - [2023-08-13 12:52:19,796] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:19,912] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:19,932] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:19,958] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:20,085] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:20,121] {logging_mixin.py:115} INFO - [2023-08-13 12:52:20,121] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:20,151] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.371 seconds
[2023-08-13 12:52:20,538] {processor.py:153} INFO - Started process (PID=425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:20,540] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:20,541] {logging_mixin.py:115} INFO - [2023-08-13 12:52:20,541] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:20,639] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:20,659] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:20,684] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:20,809] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:20,848] {logging_mixin.py:115} INFO - [2023-08-13 12:52:20,848] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:20,881] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:52:21,649] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:21,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:21,651] {logging_mixin.py:115} INFO - [2023-08-13 12:52:21,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:21,793] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:21,812] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:21,837] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:21,960] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:21,967] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:21,974] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:22,008] {logging_mixin.py:115} INFO - [2023-08-13 12:52:22,008] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:22,035] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.391 seconds
[2023-08-13 12:52:22,694] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:22,696] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:22,697] {logging_mixin.py:115} INFO - [2023-08-13 12:52:22,697] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:22,787] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:22,805] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:22,827] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:22,944] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:22,979] {logging_mixin.py:115} INFO - [2023-08-13 12:52:22,979] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:23,006] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.316 seconds
[2023-08-13 12:52:23,743] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:23,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:23,746] {logging_mixin.py:115} INFO - [2023-08-13 12:52:23,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:23,837] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:23,854] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:23,877] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:23,995] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:24,032] {logging_mixin.py:115} INFO - [2023-08-13 12:52:24,032] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:24,060] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 12:52:24,793] {processor.py:153} INFO - Started process (PID=445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:24,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:24,795] {logging_mixin.py:115} INFO - [2023-08-13 12:52:24,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:24,880] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:24,896] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:24,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:25,037] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:25,072] {logging_mixin.py:115} INFO - [2023-08-13 12:52:25,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:25,099] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 12:52:25,650] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:25,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:25,654] {logging_mixin.py:115} INFO - [2023-08-13 12:52:25,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:25,747] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:25,768] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:25,792] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:25,921] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:25,956] {logging_mixin.py:115} INFO - [2023-08-13 12:52:25,956] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:25,983] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 12:52:26,706] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:26,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:26,709] {logging_mixin.py:115} INFO - [2023-08-13 12:52:26,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:26,802] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:26,820] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:26,845] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:26,981] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:27,015] {logging_mixin.py:115} INFO - [2023-08-13 12:52:27,015] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:27,047] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 12:52:27,751] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:27,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:27,754] {logging_mixin.py:115} INFO - [2023-08-13 12:52:27,754] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:27,859] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:27,877] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:27,902] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:28,012] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:28,048] {logging_mixin.py:115} INFO - [2023-08-13 12:52:28,047] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:28,089] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.364 seconds
[2023-08-13 12:52:28,778] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:28,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:28,781] {logging_mixin.py:115} INFO - [2023-08-13 12:52:28,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:28,876] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:28,901] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:28,944] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:29,077] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:29,115] {logging_mixin.py:115} INFO - [2023-08-13 12:52:29,115] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:29,144] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.371 seconds
[2023-08-13 12:52:29,882] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:29,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:29,887] {logging_mixin.py:115} INFO - [2023-08-13 12:52:29,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:29,991] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:30,011] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:30,035] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:30,159] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:30,195] {logging_mixin.py:115} INFO - [2023-08-13 12:52:30,195] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:30,223] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.357 seconds
[2023-08-13 12:52:30,441] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:30,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:30,444] {logging_mixin.py:115} INFO - [2023-08-13 12:52:30,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:30,602] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:30,621] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:30,649] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:30,784] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:30,824] {logging_mixin.py:115} INFO - [2023-08-13 12:52:30,824] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:30,851] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.414 seconds
[2023-08-13 12:52:31,752] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:31,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:31,755] {logging_mixin.py:115} INFO - [2023-08-13 12:52:31,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:31,862] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:31,881] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:31,917] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:32,045] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:32,053] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:32,061] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:32,065] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:32,072] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:32,104] {logging_mixin.py:115} INFO - [2023-08-13 12:52:32,104] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:32,133] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.385 seconds
[2023-08-13 12:52:32,796] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:32,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:32,799] {logging_mixin.py:115} INFO - [2023-08-13 12:52:32,799] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:32,899] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:32,922] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:32,949] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:33,110] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:33,150] {logging_mixin.py:115} INFO - [2023-08-13 12:52:33,150] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:33,186] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.395 seconds
[2023-08-13 12:52:33,845] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:33,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:33,847] {logging_mixin.py:115} INFO - [2023-08-13 12:52:33,847] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:33,939] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:33,956] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:33,980] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:34,119] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:34,155] {logging_mixin.py:115} INFO - [2023-08-13 12:52:34,155] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:34,196] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 12:52:34,909] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:34,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:34,912] {logging_mixin.py:115} INFO - [2023-08-13 12:52:34,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:35,009] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:35,027] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:35,051] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:35,175] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:35,213] {logging_mixin.py:115} INFO - [2023-08-13 12:52:35,212] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:35,239] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 12:52:35,752] {processor.py:153} INFO - Started process (PID=500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:35,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:35,787] {logging_mixin.py:115} INFO - [2023-08-13 12:52:35,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:35,903] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:35,923] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:35,949] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:36,079] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:36,114] {logging_mixin.py:115} INFO - [2023-08-13 12:52:36,114] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:36,143] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.396 seconds
[2023-08-13 12:52:36,855] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:36,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:36,860] {logging_mixin.py:115} INFO - [2023-08-13 12:52:36,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:36,975] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:36,996] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:37,025] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:37,163] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:37,200] {logging_mixin.py:115} INFO - [2023-08-13 12:52:37,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:37,231] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.383 seconds
[2023-08-13 12:52:37,907] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:37,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:37,911] {logging_mixin.py:115} INFO - [2023-08-13 12:52:37,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:38,010] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:38,074] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:38,103] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:38,227] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:38,264] {logging_mixin.py:115} INFO - [2023-08-13 12:52:38,264] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:38,291] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.389 seconds
[2023-08-13 12:52:38,954] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:38,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:38,957] {logging_mixin.py:115} INFO - [2023-08-13 12:52:38,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:39,063] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:39,083] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:39,110] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:39,235] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:39,271] {logging_mixin.py:115} INFO - [2023-08-13 12:52:39,271] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:39,299] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 12:52:40,006] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:40,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:40,009] {logging_mixin.py:115} INFO - [2023-08-13 12:52:40,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:40,101] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:40,124] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:40,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:40,286] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:40,344] {logging_mixin.py:115} INFO - [2023-08-13 12:52:40,344] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:40,395] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.394 seconds
[2023-08-13 12:52:40,647] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:40,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:40,651] {logging_mixin.py:115} INFO - [2023-08-13 12:52:40,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:40,749] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:40,769] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:40,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:40,919] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:40,954] {logging_mixin.py:115} INFO - [2023-08-13 12:52:40,954] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:40,983] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 12:52:41,930] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:41,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:41,932] {logging_mixin.py:115} INFO - [2023-08-13 12:52:41,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:42,037] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:42,060] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:42,092] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:42,264] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:42,276] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:42,288] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:42,335] {logging_mixin.py:115} INFO - [2023-08-13 12:52:42,335] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:42,370] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.445 seconds
[2023-08-13 12:52:42,976] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:42,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:42,982] {logging_mixin.py:115} INFO - [2023-08-13 12:52:42,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:43,091] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:43,109] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:43,136] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:43,259] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:43,297] {logging_mixin.py:115} INFO - [2023-08-13 12:52:43,297] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:43,327] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.355 seconds
[2023-08-13 12:52:44,027] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:44,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:44,042] {logging_mixin.py:115} INFO - [2023-08-13 12:52:44,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:44,137] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:44,154] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:44,178] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:44,301] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:44,337] {logging_mixin.py:115} INFO - [2023-08-13 12:52:44,337] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:44,366] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 12:52:45,104] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:45,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:45,107] {logging_mixin.py:115} INFO - [2023-08-13 12:52:45,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:45,213] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:45,231] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:45,256] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:45,387] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:45,423] {logging_mixin.py:115} INFO - [2023-08-13 12:52:45,423] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:45,454] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 12:52:45,902] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:45,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:45,906] {logging_mixin.py:115} INFO - [2023-08-13 12:52:45,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:45,999] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:46,017] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:46,041] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:46,168] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:46,175] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:46,184] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:46,215] {logging_mixin.py:115} INFO - [2023-08-13 12:52:46,215] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:46,244] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:52:46,961] {processor.py:153} INFO - Started process (PID=555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:46,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:46,963] {logging_mixin.py:115} INFO - [2023-08-13 12:52:46,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:47,060] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:47,078] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:47,104] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:47,235] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:47,271] {logging_mixin.py:115} INFO - [2023-08-13 12:52:47,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:47,297] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 12:52:48,009] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:48,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:48,011] {logging_mixin.py:115} INFO - [2023-08-13 12:52:48,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:48,093] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:48,109] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:48,130] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:48,257] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:48,300] {logging_mixin.py:115} INFO - [2023-08-13 12:52:48,300] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:48,333] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 12:52:49,054] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:49,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:49,057] {logging_mixin.py:115} INFO - [2023-08-13 12:52:49,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:49,153] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:49,185] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:49,243] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:49,365] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:49,400] {logging_mixin.py:115} INFO - [2023-08-13 12:52:49,400] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:49,429] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.379 seconds
[2023-08-13 12:52:50,103] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:50,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:52:50,106] {logging_mixin.py:115} INFO - [2023-08-13 12:52:50,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:50,198] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:52:50,219] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:52:50,251] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:52:50,424] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:52:50,472] {logging_mixin.py:115} INFO - [2023-08-13 12:52:50,472] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:52:50,497] {logging_mixin.py:115} INFO - [2023-08-13 12:52:50,496] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:52:50,512] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.413 seconds
[2023-08-13 12:53:20,608] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:53:20,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:53:20,611] {logging_mixin.py:115} INFO - [2023-08-13 12:53:20,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:53:20,704] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:53:20,743] {logging_mixin.py:115} INFO - [2023-08-13 12:53:20,743] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:53:20,892] {logging_mixin.py:115} INFO - [2023-08-13 12:53:20,892] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:53:20,908] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.305 seconds
[2023-08-13 12:53:50,989] {processor.py:153} INFO - Started process (PID=580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:53:50,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:53:50,992] {logging_mixin.py:115} INFO - [2023-08-13 12:53:50,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:53:51,068] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:53:51,107] {logging_mixin.py:115} INFO - [2023-08-13 12:53:51,107] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:53:51,239] {logging_mixin.py:115} INFO - [2023-08-13 12:53:51,239] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:53:51,252] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.267 seconds
[2023-08-13 12:54:21,351] {processor.py:153} INFO - Started process (PID=585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:54:21,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:54:21,366] {logging_mixin.py:115} INFO - [2023-08-13 12:54:21,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:54:21,530] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:54:21,588] {logging_mixin.py:115} INFO - [2023-08-13 12:54:21,588] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:54:21,739] {logging_mixin.py:115} INFO - [2023-08-13 12:54:21,739] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:54:21,753] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.410 seconds
[2023-08-13 12:54:51,853] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:54:51,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:54:51,856] {logging_mixin.py:115} INFO - [2023-08-13 12:54:51,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:54:51,954] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:54:52,002] {logging_mixin.py:115} INFO - [2023-08-13 12:54:52,002] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:54:52,140] {logging_mixin.py:115} INFO - [2023-08-13 12:54:52,140] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:54:52,152] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 12:55:22,232] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:55:22,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:55:22,235] {logging_mixin.py:115} INFO - [2023-08-13 12:55:22,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:55:22,353] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:55:22,405] {logging_mixin.py:115} INFO - [2023-08-13 12:55:22,405] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:55:22,560] {logging_mixin.py:115} INFO - [2023-08-13 12:55:22,560] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:55:22,574] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 12:55:52,659] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:55:52,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:55:52,662] {logging_mixin.py:115} INFO - [2023-08-13 12:55:52,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:55:52,759] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:55:52,807] {logging_mixin.py:115} INFO - [2023-08-13 12:55:52,807] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:55:52,962] {logging_mixin.py:115} INFO - [2023-08-13 12:55:52,962] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:55:52,975] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.322 seconds
[2023-08-13 12:56:23,077] {processor.py:153} INFO - Started process (PID=605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:56:23,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:56:23,081] {logging_mixin.py:115} INFO - [2023-08-13 12:56:23,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:56:23,203] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:56:23,263] {logging_mixin.py:115} INFO - [2023-08-13 12:56:23,263] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:56:23,414] {logging_mixin.py:115} INFO - [2023-08-13 12:56:23,414] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:56:23,428] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 12:56:53,124] {processor.py:153} INFO - Started process (PID=610) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:56:53,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:56:53,127] {logging_mixin.py:115} INFO - [2023-08-13 12:56:53,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:56:53,246] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:56:53,452] {logging_mixin.py:115} INFO - [2023-08-13 12:56:53,452] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:56:53,476] {logging_mixin.py:115} INFO - [2023-08-13 12:56:53,476] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:56:53,494] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.374 seconds
[2023-08-13 12:57:10,171] {processor.py:153} INFO - Started process (PID=615) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:10,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:10,192] {logging_mixin.py:115} INFO - [2023-08-13 12:57:10,192] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:10,327] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:10,336] {logging_mixin.py:115} INFO - [2023-08-13 12:57:10,336] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:10,505] {logging_mixin.py:115} INFO - [2023-08-13 12:57:10,505] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:57:10,522] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.355 seconds
[2023-08-13 12:57:20,690] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:20,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:20,693] {logging_mixin.py:115} INFO - [2023-08-13 12:57:20,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:20,803] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:20,809] {logging_mixin.py:115} INFO - [2023-08-13 12:57:20,809] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:20,836] {logging_mixin.py:115} INFO - [2023-08-13 12:57:20,836] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:57:20,971] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.285 seconds
[2023-08-13 12:57:26,829] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:26,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:26,836] {logging_mixin.py:115} INFO - [2023-08-13 12:57:26,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:26,973] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:26,981] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:27,007] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:27,136] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:27,173] {logging_mixin.py:115} INFO - [2023-08-13 12:57:27,173] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:27,206] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.383 seconds
[2023-08-13 12:57:27,977] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:27,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:27,980] {logging_mixin.py:115} INFO - [2023-08-13 12:57:27,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:28,112] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:28,123] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:28,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:28,297] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:28,305] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:28,314] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:28,348] {logging_mixin.py:115} INFO - [2023-08-13 12:57:28,348] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:28,380] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.408 seconds
[2023-08-13 12:57:29,040] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:29,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:29,044] {logging_mixin.py:115} INFO - [2023-08-13 12:57:29,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:29,178] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:29,186] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:29,219] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:29,378] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:29,427] {logging_mixin.py:115} INFO - [2023-08-13 12:57:29,427] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:29,479] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.445 seconds
[2023-08-13 12:57:30,230] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:30,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:30,234] {logging_mixin.py:115} INFO - [2023-08-13 12:57:30,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:30,436] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:30,454] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:30,486] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:30,697] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:30,712] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:30,725] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:30,777] {logging_mixin.py:115} INFO - [2023-08-13 12:57:30,777] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:30,838] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.617 seconds
[2023-08-13 12:57:31,823] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:31,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:31,829] {logging_mixin.py:115} INFO - [2023-08-13 12:57:31,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:31,988] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:32,001] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:32,033] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:32,212] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:32,221] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:32,229] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:32,262] {logging_mixin.py:115} INFO - [2023-08-13 12:57:32,262] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:32,291] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.473 seconds
[2023-08-13 12:57:32,876] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:32,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:32,880] {logging_mixin.py:115} INFO - [2023-08-13 12:57:32,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:33,013] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:33,023] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:33,056] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:33,253] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:33,313] {logging_mixin.py:115} INFO - [2023-08-13 12:57:33,313] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:33,361] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.492 seconds
[2023-08-13 12:57:33,936] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:33,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:33,939] {logging_mixin.py:115} INFO - [2023-08-13 12:57:33,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:34,085] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:34,093] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:34,121] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:34,260] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:34,301] {logging_mixin.py:115} INFO - [2023-08-13 12:57:34,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:34,332] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.402 seconds
[2023-08-13 12:57:35,027] {processor.py:153} INFO - Started process (PID=216) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:35,028] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:35,030] {logging_mixin.py:115} INFO - [2023-08-13 12:57:35,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:35,239] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:35,249] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:35,282] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:35,515] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:35,554] {logging_mixin.py:115} INFO - [2023-08-13 12:57:35,554] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:35,586] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.565 seconds
[2023-08-13 12:57:35,663] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:35,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:35,666] {logging_mixin.py:115} INFO - [2023-08-13 12:57:35,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:35,787] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:35,795] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:35,826] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:35,978] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:49:39.412404+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:36,019] {logging_mixin.py:115} INFO - [2023-08-13 12:57:36,019] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:36,056] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.397 seconds
[2023-08-13 12:57:36,910] {processor.py:153} INFO - Started process (PID=226) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:36,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:36,914] {logging_mixin.py:115} INFO - [2023-08-13 12:57:36,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:37,061] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:37,069] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:37,098] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:37,233] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:37,240] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:37,250] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:37,286] {logging_mixin.py:115} INFO - [2023-08-13 12:57:37,286] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:37,318] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.415 seconds
[2023-08-13 12:57:38,055] {processor.py:153} INFO - Started process (PID=233) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:38,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:38,060] {logging_mixin.py:115} INFO - [2023-08-13 12:57:38,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:38,203] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:38,211] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:38,241] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:38,398] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:38,408] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:38,421] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:38,475] {logging_mixin.py:115} INFO - [2023-08-13 12:57:38,475] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:38,514] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.464 seconds
[2023-08-13 12:57:39,105] {processor.py:153} INFO - Started process (PID=238) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:39,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:39,108] {logging_mixin.py:115} INFO - [2023-08-13 12:57:39,108] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:39,280] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:39,291] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:39,342] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:39,561] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:39,601] {logging_mixin.py:115} INFO - [2023-08-13 12:57:39,601] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:39,642] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.543 seconds
[2023-08-13 12:57:40,226] {processor.py:153} INFO - Started process (PID=245) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:40,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:40,230] {logging_mixin.py:115} INFO - [2023-08-13 12:57:40,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:40,412] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:40,424] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:40,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:40,653] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:40,663] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:40,675] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:40,719] {logging_mixin.py:115} INFO - [2023-08-13 12:57:40,719] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:40,755] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.535 seconds
[2023-08-13 12:57:40,834] {processor.py:153} INFO - Started process (PID=250) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:40,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:40,837] {logging_mixin.py:115} INFO - [2023-08-13 12:57:40,837] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:41,021] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:41,032] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:41,071] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:41,222] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:41,261] {logging_mixin.py:115} INFO - [2023-08-13 12:57:41,261] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:41,294] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.465 seconds
[2023-08-13 12:57:42,012] {processor.py:153} INFO - Started process (PID=255) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:42,014] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:42,016] {logging_mixin.py:115} INFO - [2023-08-13 12:57:42,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:42,160] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:42,169] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:42,196] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:42,323] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:42,330] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:42,340] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:42,374] {logging_mixin.py:115} INFO - [2023-08-13 12:57:42,374] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:42,406] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.399 seconds
[2023-08-13 12:57:43,065] {processor.py:153} INFO - Started process (PID=260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:43,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:43,069] {logging_mixin.py:115} INFO - [2023-08-13 12:57:43,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:43,185] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:43,192] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:43,215] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:43,342] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:43,379] {logging_mixin.py:115} INFO - [2023-08-13 12:57:43,379] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:43,408] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 12:57:44,121] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:44,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:44,124] {logging_mixin.py:115} INFO - [2023-08-13 12:57:44,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:44,276] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:44,286] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:44,327] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:44,514] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:44,560] {logging_mixin.py:115} INFO - [2023-08-13 12:57:44,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:44,598] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.482 seconds
[2023-08-13 12:57:45,166] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:45,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:45,169] {logging_mixin.py:115} INFO - [2023-08-13 12:57:45,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:45,299] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:45,306] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:45,334] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:45,470] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:45,508] {logging_mixin.py:115} INFO - [2023-08-13 12:57:45,507] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:45,541] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.380 seconds
[2023-08-13 12:57:46,009] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:46,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:46,012] {logging_mixin.py:115} INFO - [2023-08-13 12:57:46,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:46,146] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:46,158] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:46,187] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:46,324] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:46,369] {logging_mixin.py:115} INFO - [2023-08-13 12:57:46,369] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:46,414] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.411 seconds
[2023-08-13 12:57:47,077] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:47,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:47,082] {logging_mixin.py:115} INFO - [2023-08-13 12:57:47,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:47,225] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:47,232] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:47,257] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:47,515] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:47,572] {logging_mixin.py:115} INFO - [2023-08-13 12:57:47,572] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:47,608] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.540 seconds
[2023-08-13 12:57:48,128] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:48,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:48,132] {logging_mixin.py:115} INFO - [2023-08-13 12:57:48,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:48,289] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:48,301] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:48,328] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:48,467] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:48,504] {logging_mixin.py:115} INFO - [2023-08-13 12:57:48,504] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:48,534] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.412 seconds
[2023-08-13 12:57:49,196] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:49,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:49,198] {logging_mixin.py:115} INFO - [2023-08-13 12:57:49,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:49,306] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:49,313] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:49,336] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:49,463] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:49,502] {logging_mixin.py:115} INFO - [2023-08-13 12:57:49,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:49,531] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.340 seconds
[2023-08-13 12:57:50,241] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:50,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:50,243] {logging_mixin.py:115} INFO - [2023-08-13 12:57:50,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:50,370] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:50,381] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:50,420] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:50,569] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:50,604] {logging_mixin.py:115} INFO - [2023-08-13 12:57:50,604] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:50,630] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.394 seconds
[2023-08-13 12:57:50,709] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:50,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:50,712] {logging_mixin.py:115} INFO - [2023-08-13 12:57:50,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:50,824] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:50,831] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:50,855] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:50,986] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:51,021] {logging_mixin.py:115} INFO - [2023-08-13 12:57:51,021] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:51,049] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 12:57:52,235] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:52,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:52,238] {logging_mixin.py:115} INFO - [2023-08-13 12:57:52,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:52,349] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:52,356] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:52,378] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:52,502] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:52,509] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:52,516] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:52,521] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:52,528] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:52,557] {logging_mixin.py:115} INFO - [2023-08-13 12:57:52,557] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:52,581] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.352 seconds
[2023-08-13 12:57:53,281] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:53,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:53,284] {logging_mixin.py:115} INFO - [2023-08-13 12:57:53,283] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:53,394] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:53,401] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:53,426] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:53,550] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:53,587] {logging_mixin.py:115} INFO - [2023-08-13 12:57:53,587] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:53,616] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.340 seconds
[2023-08-13 12:57:54,338] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:54,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:54,341] {logging_mixin.py:115} INFO - [2023-08-13 12:57:54,341] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:54,450] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:54,456] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:54,477] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:54,595] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:54,631] {logging_mixin.py:115} INFO - [2023-08-13 12:57:54,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:54,659] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 12:57:55,385] {processor.py:153} INFO - Started process (PID=320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:55,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:55,388] {logging_mixin.py:115} INFO - [2023-08-13 12:57:55,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:55,502] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:55,509] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:55,533] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:55,662] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:55,698] {logging_mixin.py:115} INFO - [2023-08-13 12:57:55,698] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:55,728] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 12:57:56,117] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:56,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:56,119] {logging_mixin.py:115} INFO - [2023-08-13 12:57:56,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:56,222] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:56,229] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:56,251] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:56,443] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:56,483] {logging_mixin.py:115} INFO - [2023-08-13 12:57:56,483] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:56,510] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.398 seconds
[2023-08-13 12:57:57,174] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:57,175] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:57,176] {logging_mixin.py:115} INFO - [2023-08-13 12:57:57,176] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:57,285] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:57,292] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:57,320] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:57,447] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:57,484] {logging_mixin.py:115} INFO - [2023-08-13 12:57:57,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:57,512] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 12:57:58,201] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:58,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:58,204] {logging_mixin.py:115} INFO - [2023-08-13 12:57:58,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:58,310] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:58,320] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:58,342] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:58,472] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:58,507] {logging_mixin.py:115} INFO - [2023-08-13 12:57:58,507] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:58,533] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 12:57:59,249] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:59,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:57:59,252] {logging_mixin.py:115} INFO - [2023-08-13 12:57:59,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:59,360] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:57:59,367] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:57:59,393] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:57:59,517] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:57:59,553] {logging_mixin.py:115} INFO - [2023-08-13 12:57:59,553] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:57:59,581] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 12:58:00,303] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:00,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:00,305] {logging_mixin.py:115} INFO - [2023-08-13 12:58:00,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:00,423] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:00,431] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:00,457] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:00,584] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:00,622] {logging_mixin.py:115} INFO - [2023-08-13 12:58:00,622] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:00,652] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 12:58:00,906] {processor.py:153} INFO - Started process (PID=350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:00,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:00,908] {logging_mixin.py:115} INFO - [2023-08-13 12:58:00,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:01,014] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:01,021] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:01,044] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:01,165] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:01,201] {logging_mixin.py:115} INFO - [2023-08-13 12:58:01,201] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:01,228] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 12:58:02,215] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:02,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:02,217] {logging_mixin.py:115} INFO - [2023-08-13 12:58:02,217] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:02,323] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:02,329] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:02,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:02,475] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:02,483] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:02,490] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:02,521] {logging_mixin.py:115} INFO - [2023-08-13 12:58:02,520] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:02,546] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 12:58:03,264] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:03,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:03,266] {logging_mixin.py:115} INFO - [2023-08-13 12:58:03,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:03,373] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:03,380] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:03,404] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:03,525] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:03,559] {logging_mixin.py:115} INFO - [2023-08-13 12:58:03,558] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:03,586] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 12:58:04,314] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:04,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:04,316] {logging_mixin.py:115} INFO - [2023-08-13 12:58:04,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:04,423] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:04,430] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:04,452] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:04,574] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:04,608] {logging_mixin.py:115} INFO - [2023-08-13 12:58:04,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:04,634] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:58:05,362] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:05,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:05,364] {logging_mixin.py:115} INFO - [2023-08-13 12:58:05,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:05,469] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:05,475] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:05,495] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:05,616] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:05,649] {logging_mixin.py:115} INFO - [2023-08-13 12:58:05,648] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:05,683] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:58:05,739] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:05,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:05,741] {logging_mixin.py:115} INFO - [2023-08-13 12:58:05,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:05,842] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:05,849] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:05,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:06,005] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:06,037] {logging_mixin.py:115} INFO - [2023-08-13 12:58:06,037] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:06,062] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 12:58:06,210] {processor.py:153} INFO - Started process (PID=380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:06,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:06,213] {logging_mixin.py:115} INFO - [2023-08-13 12:58:06,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:06,323] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:06,333] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:06,361] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:06,499] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:06,537] {logging_mixin.py:115} INFO - [2023-08-13 12:58:06,537] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:06,566] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.361 seconds
[2023-08-13 12:58:07,260] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:07,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:07,262] {logging_mixin.py:115} INFO - [2023-08-13 12:58:07,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:07,357] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:07,364] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:07,387] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:07,509] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:07,543] {logging_mixin.py:115} INFO - [2023-08-13 12:58:07,543] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:07,571] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 12:58:08,306] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:08,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:08,309] {logging_mixin.py:115} INFO - [2023-08-13 12:58:08,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:08,419] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:08,429] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:08,453] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:08,580] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:08,614] {logging_mixin.py:115} INFO - [2023-08-13 12:58:08,614] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:08,643] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 12:58:09,350] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:09,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:09,353] {logging_mixin.py:115} INFO - [2023-08-13 12:58:09,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:09,457] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:09,463] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:09,483] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:09,603] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:09,639] {logging_mixin.py:115} INFO - [2023-08-13 12:58:09,639] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:09,665] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.319 seconds
[2023-08-13 12:58:10,396] {processor.py:153} INFO - Started process (PID=400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:10,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:10,399] {logging_mixin.py:115} INFO - [2023-08-13 12:58:10,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:10,508] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:10,515] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:10,540] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:10,669] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:10,702] {logging_mixin.py:115} INFO - [2023-08-13 12:58:10,702] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:10,732] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 12:58:10,951] {processor.py:153} INFO - Started process (PID=405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:10,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:10,954] {logging_mixin.py:115} INFO - [2023-08-13 12:58:10,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:11,081] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:11,090] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:11,115] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:11,240] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:11,276] {logging_mixin.py:115} INFO - [2023-08-13 12:58:11,276] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:11,336] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.389 seconds
[2023-08-13 12:58:12,335] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:12,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:12,339] {logging_mixin.py:115} INFO - [2023-08-13 12:58:12,338] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:12,450] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:12,457] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:12,480] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:12,601] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:12,607] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:12,615] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:12,645] {logging_mixin.py:115} INFO - [2023-08-13 12:58:12,645] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:12,669] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 12:58:13,386] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:13,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:13,391] {logging_mixin.py:115} INFO - [2023-08-13 12:58:13,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:13,497] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:13,503] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:13,526] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:13,647] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:13,681] {logging_mixin.py:115} INFO - [2023-08-13 12:58:13,680] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:13,707] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:58:14,434] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:14,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:14,436] {logging_mixin.py:115} INFO - [2023-08-13 12:58:14,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:14,540] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:14,547] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:14,571] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:14,693] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:14,727] {logging_mixin.py:115} INFO - [2023-08-13 12:58:14,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:14,755] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 12:58:15,486] {processor.py:153} INFO - Started process (PID=425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:15,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:15,488] {logging_mixin.py:115} INFO - [2023-08-13 12:58:15,488] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:15,594] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:15,600] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:15,624] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:15,746] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:15,781] {logging_mixin.py:115} INFO - [2023-08-13 12:58:15,781] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:15,809] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.328 seconds
[2023-08-13 12:58:16,330] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:16,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:16,332] {logging_mixin.py:115} INFO - [2023-08-13 12:58:16,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:16,466] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:16,477] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:16,508] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:16,670] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:16,710] {logging_mixin.py:115} INFO - [2023-08-13 12:58:16,710] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:16,745] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.420 seconds
[2023-08-13 12:58:17,394] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:17,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:17,397] {logging_mixin.py:115} INFO - [2023-08-13 12:58:17,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:17,518] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:17,525] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:17,551] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:17,681] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:17,718] {logging_mixin.py:115} INFO - [2023-08-13 12:58:17,718] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:17,749] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 12:58:18,457] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:18,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:18,461] {logging_mixin.py:115} INFO - [2023-08-13 12:58:18,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:18,576] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:18,584] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:18,608] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:18,731] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:18,767] {logging_mixin.py:115} INFO - [2023-08-13 12:58:18,767] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:18,796] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 12:58:19,506] {processor.py:153} INFO - Started process (PID=445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:19,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:19,508] {logging_mixin.py:115} INFO - [2023-08-13 12:58:19,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:19,617] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:19,624] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:19,647] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:19,780] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:19,819] {logging_mixin.py:115} INFO - [2023-08-13 12:58:19,819] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:19,850] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 12:58:20,558] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:20,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:20,561] {logging_mixin.py:115} INFO - [2023-08-13 12:58:20,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:20,706] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:20,714] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:20,739] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:20,874] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:20,959] {logging_mixin.py:115} INFO - [2023-08-13 12:58:20,959] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:20,990] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.437 seconds
[2023-08-13 12:58:21,421] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:21,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:21,429] {logging_mixin.py:115} INFO - [2023-08-13 12:58:21,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:21,589] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:21,597] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:21,625] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:21,760] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:21,768] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:21,777] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:21,781] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:21,790] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:21,825] {logging_mixin.py:115} INFO - [2023-08-13 12:58:21,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:21,856] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.444 seconds
[2023-08-13 12:58:22,489] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:22,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:22,492] {logging_mixin.py:115} INFO - [2023-08-13 12:58:22,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:22,611] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:22,620] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:22,646] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:22,779] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:22,832] {logging_mixin.py:115} INFO - [2023-08-13 12:58:22,832] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:22,885] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.402 seconds
[2023-08-13 12:58:23,629] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:23,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:23,639] {logging_mixin.py:115} INFO - [2023-08-13 12:58:23,638] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:23,853] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:23,861] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:23,886] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:24,022] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:24,058] {logging_mixin.py:115} INFO - [2023-08-13 12:58:24,058] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:24,091] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.476 seconds
[2023-08-13 12:58:24,660] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:24,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:24,663] {logging_mixin.py:115} INFO - [2023-08-13 12:58:24,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:24,776] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:24,783] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:24,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:24,931] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:24,967] {logging_mixin.py:115} INFO - [2023-08-13 12:58:24,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:25,014] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.359 seconds
[2023-08-13 12:58:25,717] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:25,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:25,721] {logging_mixin.py:115} INFO - [2023-08-13 12:58:25,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:25,862] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:25,870] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:25,894] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:26,023] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:26,062] {logging_mixin.py:115} INFO - [2023-08-13 12:58:26,062] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:26,090] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.380 seconds
[2023-08-13 12:58:26,504] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:26,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:26,507] {logging_mixin.py:115} INFO - [2023-08-13 12:58:26,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:26,626] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:26,633] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:26,659] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:26,793] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:26,828] {logging_mixin.py:115} INFO - [2023-08-13 12:58:26,828] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:26,860] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 12:58:27,561] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:27,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:27,564] {logging_mixin.py:115} INFO - [2023-08-13 12:58:27,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:27,675] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:27,683] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:27,686] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:27,818] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:27,858] {logging_mixin.py:115} INFO - [2023-08-13 12:58:27,858] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:27,886] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.352 seconds
[2023-08-13 12:58:28,602] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:28,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:28,611] {logging_mixin.py:115} INFO - [2023-08-13 12:58:28,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:28,752] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:28,765] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:28,799] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:28,935] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:28,977] {logging_mixin.py:115} INFO - [2023-08-13 12:58:28,977] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:29,019] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.423 seconds
[2023-08-13 12:58:29,659] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:29,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:29,661] {logging_mixin.py:115} INFO - [2023-08-13 12:58:29,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:29,776] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:29,783] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:29,807] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:29,946] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:29,981] {logging_mixin.py:115} INFO - [2023-08-13 12:58:29,981] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:30,008] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 12:58:30,703] {processor.py:153} INFO - Started process (PID=500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:30,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:30,707] {logging_mixin.py:115} INFO - [2023-08-13 12:58:30,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:30,826] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:30,833] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:30,858] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:30,992] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:31,034] {logging_mixin.py:115} INFO - [2023-08-13 12:58:31,034] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:31,069] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.372 seconds
[2023-08-13 12:58:31,546] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:31,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:31,549] {logging_mixin.py:115} INFO - [2023-08-13 12:58:31,549] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:31,691] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:31,698] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:31,724] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:31,868] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:31,875] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:31,885] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:31,926] {logging_mixin.py:115} INFO - [2023-08-13 12:58:31,925] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:31,957] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.417 seconds
[2023-08-13 12:58:32,631] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:32,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:32,635] {logging_mixin.py:115} INFO - [2023-08-13 12:58:32,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:32,826] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:32,837] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:32,906] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:33,156] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:33,202] {logging_mixin.py:115} INFO - [2023-08-13 12:58:33,202] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:33,236] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.613 seconds
[2023-08-13 12:58:33,685] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:33,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:33,688] {logging_mixin.py:115} INFO - [2023-08-13 12:58:33,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:33,822] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:33,850] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:33,882] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:34,029] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:34,068] {logging_mixin.py:115} INFO - [2023-08-13 12:58:34,068] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:34,105] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.425 seconds
[2023-08-13 12:58:34,741] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:34,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:34,744] {logging_mixin.py:115} INFO - [2023-08-13 12:58:34,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:34,883] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:34,900] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:34,943] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:35,113] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:35,156] {logging_mixin.py:115} INFO - [2023-08-13 12:58:35,156] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:35,192] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.456 seconds
[2023-08-13 12:58:35,799] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:35,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:35,802] {logging_mixin.py:115} INFO - [2023-08-13 12:58:35,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:35,941] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:35,950] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:35,988] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:36,130] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:36,165] {logging_mixin.py:115} INFO - [2023-08-13 12:58:36,165] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:36,192] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.399 seconds
[2023-08-13 12:58:36,698] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:36,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:36,702] {logging_mixin.py:115} INFO - [2023-08-13 12:58:36,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:36,840] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:36,847] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:36,873] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:37,013] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:37,051] {logging_mixin.py:115} INFO - [2023-08-13 12:58:37,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:37,080] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.389 seconds
[2023-08-13 12:58:37,765] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:37,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:37,768] {logging_mixin.py:115} INFO - [2023-08-13 12:58:37,768] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:37,884] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:37,891] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:37,916] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:38,056] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:38,092] {logging_mixin.py:115} INFO - [2023-08-13 12:58:38,092] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:38,122] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 12:58:38,819] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:38,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:38,822] {logging_mixin.py:115} INFO - [2023-08-13 12:58:38,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:38,936] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:38,944] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:38,968] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:39,096] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:39,138] {logging_mixin.py:115} INFO - [2023-08-13 12:58:39,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:39,170] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.355 seconds
[2023-08-13 12:58:39,879] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:39,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:39,882] {logging_mixin.py:115} INFO - [2023-08-13 12:58:39,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:39,996] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:40,006] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:40,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:40,161] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:40,197] {logging_mixin.py:115} INFO - [2023-08-13 12:58:40,197] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:40,225] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 12:58:40,933] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:40,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:58:40,936] {logging_mixin.py:115} INFO - [2023-08-13 12:58:40,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:41,063] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:58:41,070] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:58:41,096] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:58:41,244] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:58:41,282] {logging_mixin.py:115} INFO - [2023-08-13 12:58:41,282] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:58:41,300] {logging_mixin.py:115} INFO - [2023-08-13 12:58:41,300] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:58:41,312] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.384 seconds
[2023-08-13 12:59:11,441] {processor.py:153} INFO - Started process (PID=555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:59:11,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:59:11,444] {logging_mixin.py:115} INFO - [2023-08-13 12:59:11,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:59:11,572] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:59:11,579] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 12:59:11,606] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 12:59:11,753] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 12:59:11,795] {logging_mixin.py:115} INFO - [2023-08-13 12:59:11,794] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:59:11,812] {logging_mixin.py:115} INFO - [2023-08-13 12:59:11,812] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:59:11,831] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.395 seconds
[2023-08-13 12:59:41,961] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:59:41,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 12:59:41,964] {logging_mixin.py:115} INFO - [2023-08-13 12:59:41,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:59:42,072] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 12:59:42,103] {logging_mixin.py:115} INFO - [2023-08-13 12:59:42,103] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 12:59:42,238] {logging_mixin.py:115} INFO - [2023-08-13 12:59:42,238] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 12:59:42,251] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.295 seconds
[2023-08-13 13:00:12,343] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:00:12,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:00:12,346] {logging_mixin.py:115} INFO - [2023-08-13 13:00:12,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:00:12,458] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:00:12,491] {logging_mixin.py:115} INFO - [2023-08-13 13:00:12,490] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:00:12,629] {logging_mixin.py:115} INFO - [2023-08-13 13:00:12,629] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:00:12,642] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 13:00:42,721] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:00:42,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:00:42,724] {logging_mixin.py:115} INFO - [2023-08-13 13:00:42,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:00:42,847] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:00:42,883] {logging_mixin.py:115} INFO - [2023-08-13 13:00:42,883] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:00:43,036] {logging_mixin.py:115} INFO - [2023-08-13 13:00:43,036] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:00:43,050] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:01:13,138] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:01:13,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:01:13,141] {logging_mixin.py:115} INFO - [2023-08-13 13:01:13,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:01:13,260] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:01:13,293] {logging_mixin.py:115} INFO - [2023-08-13 13:01:13,293] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:01:13,436] {logging_mixin.py:115} INFO - [2023-08-13 13:01:13,436] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:01:13,448] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 13:01:43,543] {processor.py:153} INFO - Started process (PID=580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:01:43,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:01:43,546] {logging_mixin.py:115} INFO - [2023-08-13 13:01:43,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:01:43,648] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:01:43,674] {logging_mixin.py:115} INFO - [2023-08-13 13:01:43,674] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:01:43,808] {logging_mixin.py:115} INFO - [2023-08-13 13:01:43,808] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:01:43,820] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 13:02:13,901] {processor.py:153} INFO - Started process (PID=585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:02:13,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:02:13,905] {logging_mixin.py:115} INFO - [2023-08-13 13:02:13,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:02:14,032] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:02:14,071] {logging_mixin.py:115} INFO - [2023-08-13 13:02:14,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:02:14,233] {logging_mixin.py:115} INFO - [2023-08-13 13:02:14,233] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:02:14,249] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 13:02:44,357] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:02:44,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:02:44,360] {logging_mixin.py:115} INFO - [2023-08-13 13:02:44,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:02:44,458] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:02:44,485] {logging_mixin.py:115} INFO - [2023-08-13 13:02:44,485] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:02:44,616] {logging_mixin.py:115} INFO - [2023-08-13 13:02:44,616] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:02:44,628] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.276 seconds
[2023-08-13 13:03:14,708] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:14,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:03:14,712] {logging_mixin.py:115} INFO - [2023-08-13 13:03:14,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:14,853] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:14,894] {logging_mixin.py:115} INFO - [2023-08-13 13:03:14,894] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:03:15,048] {logging_mixin.py:115} INFO - [2023-08-13 13:03:15,048] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:03:15,063] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 13:03:45,161] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:45,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:03:45,164] {logging_mixin.py:115} INFO - [2023-08-13 13:03:45,164] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:45,283] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:45,321] {logging_mixin.py:115} INFO - [2023-08-13 13:03:45,321] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:03:45,470] {logging_mixin.py:115} INFO - [2023-08-13 13:03:45,470] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:03:45,501] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:03:51,172] {processor.py:153} INFO - Started process (PID=605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:51,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:03:51,175] {logging_mixin.py:115} INFO - [2023-08-13 13:03:51,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:51,300] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:03:51,339] {logging_mixin.py:115} INFO - [2023-08-13 13:03:51,339] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:03:51,493] {logging_mixin.py:115} INFO - [2023-08-13 13:03:51,493] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:03:51,514] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:04:03,685] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:03,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:03,687] {logging_mixin.py:115} INFO - [2023-08-13 13:04:03,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:03,801] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:03,838] {logging_mixin.py:115} INFO - [2023-08-13 13:04:03,838] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:03,998] {logging_mixin.py:115} INFO - [2023-08-13 13:04:03,998] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:04:04,018] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 13:04:13,801] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:13,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:13,806] {logging_mixin.py:115} INFO - [2023-08-13 13:04:13,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:13,977] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:13,989] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:14,033] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:14,218] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:14,256] {logging_mixin.py:115} INFO - [2023-08-13 13:04:14,256] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:14,289] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.493 seconds
[2023-08-13 13:04:14,971] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:14,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:14,974] {logging_mixin.py:115} INFO - [2023-08-13 13:04:14,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:15,088] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:15,096] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:15,124] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:15,255] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:15,265] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:15,273] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:15,305] {logging_mixin.py:115} INFO - [2023-08-13 13:04:15,304] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:15,333] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.366 seconds
[2023-08-13 13:04:16,028] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:16,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:16,031] {logging_mixin.py:115} INFO - [2023-08-13 13:04:16,031] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:16,148] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:16,156] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:16,181] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:16,324] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:16,380] {logging_mixin.py:115} INFO - [2023-08-13 13:04:16,380] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:16,420] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.397 seconds
[2023-08-13 13:04:17,180] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:17,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:17,183] {logging_mixin.py:115} INFO - [2023-08-13 13:04:17,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:17,352] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:17,367] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:17,406] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:17,557] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:17,565] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:17,572] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:17,604] {logging_mixin.py:115} INFO - [2023-08-13 13:04:17,604] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:17,631] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.456 seconds
[2023-08-13 13:04:18,241] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:18,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:18,244] {logging_mixin.py:115} INFO - [2023-08-13 13:04:18,244] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:18,398] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:18,406] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:18,441] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:18,605] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:18,649] {logging_mixin.py:115} INFO - [2023-08-13 13:04:18,649] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:18,689] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.453 seconds
[2023-08-13 13:04:18,889] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:18,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:18,892] {logging_mixin.py:115} INFO - [2023-08-13 13:04:18,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:19,002] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:19,009] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:19,031] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:19,166] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:19,173] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:19,182] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:51:31.672680+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:19,215] {logging_mixin.py:115} INFO - [2023-08-13 13:04:19,215] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:19,244] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.361 seconds
[2023-08-13 13:04:19,944] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:19,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:19,946] {logging_mixin.py:115} INFO - [2023-08-13 13:04:19,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:20,064] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:20,073] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:20,104] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:20,250] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:20,290] {logging_mixin.py:115} INFO - [2023-08-13 13:04:20,290] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:20,335] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.395 seconds
[2023-08-13 13:04:21,070] {processor.py:153} INFO - Started process (PID=218) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:21,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:21,076] {logging_mixin.py:115} INFO - [2023-08-13 13:04:21,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:21,246] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:21,266] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:21,293] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:21,456] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:21,465] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:21,475] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:21,510] {logging_mixin.py:115} INFO - [2023-08-13 13:04:21,510] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:21,548] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.489 seconds
[2023-08-13 13:04:22,124] {processor.py:153} INFO - Started process (PID=223) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:22,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:22,127] {logging_mixin.py:115} INFO - [2023-08-13 13:04:22,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:22,306] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:22,320] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:22,356] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:22,504] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:22,548] {logging_mixin.py:115} INFO - [2023-08-13 13:04:22,547] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:22,585] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.467 seconds
[2023-08-13 13:04:23,311] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:23,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:23,315] {logging_mixin.py:115} INFO - [2023-08-13 13:04:23,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:23,472] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:23,481] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:23,511] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:23,670] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:23,682] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:23,696] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:23,736] {logging_mixin.py:115} INFO - [2023-08-13 13:04:23,736] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:23,780] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.477 seconds
[2023-08-13 13:04:23,941] {processor.py:153} INFO - Started process (PID=235) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:23,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:23,943] {logging_mixin.py:115} INFO - [2023-08-13 13:04:23,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:24,052] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:24,060] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:24,083] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:24,208] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:24,215] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:24,223] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:24,257] {logging_mixin.py:115} INFO - [2023-08-13 13:04:24,257] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:24,290] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 13:04:24,995] {processor.py:153} INFO - Started process (PID=240) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:24,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:24,998] {logging_mixin.py:115} INFO - [2023-08-13 13:04:24,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:25,126] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:25,135] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:25,159] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:25,288] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:25,332] {logging_mixin.py:115} INFO - [2023-08-13 13:04:25,332] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:25,368] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 13:04:26,103] {processor.py:153} INFO - Started process (PID=245) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:26,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:26,106] {logging_mixin.py:115} INFO - [2023-08-13 13:04:26,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:26,222] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:26,229] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:26,254] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:26,388] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:26,440] {logging_mixin.py:115} INFO - [2023-08-13 13:04:26,440] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:26,473] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 13:04:27,089] {processor.py:153} INFO - Started process (PID=250) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:27,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:27,092] {logging_mixin.py:115} INFO - [2023-08-13 13:04:27,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:27,220] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:27,227] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:27,258] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:27,428] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:27,453] {logging_mixin.py:115} INFO - [2023-08-13 13:04:27,453] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:27,487] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.424 seconds
[2023-08-13 13:04:28,116] {processor.py:153} INFO - Started process (PID=255) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:28,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:28,118] {logging_mixin.py:115} INFO - [2023-08-13 13:04:28,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:28,234] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:28,241] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:28,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:28,399] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:28,436] {logging_mixin.py:115} INFO - [2023-08-13 13:04:28,436] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:28,467] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.355 seconds
[2023-08-13 13:04:28,997] {processor.py:153} INFO - Started process (PID=260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:28,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:29,000] {logging_mixin.py:115} INFO - [2023-08-13 13:04:29,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:29,153] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:29,161] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:29,189] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:29,323] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:29,357] {logging_mixin.py:115} INFO - [2023-08-13 13:04:29,357] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:29,388] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.397 seconds
[2023-08-13 13:04:30,054] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:30,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:30,057] {logging_mixin.py:115} INFO - [2023-08-13 13:04:30,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:30,168] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:30,175] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:30,200] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:30,329] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:30,365] {logging_mixin.py:115} INFO - [2023-08-13 13:04:30,365] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:30,399] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 13:04:31,113] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:31,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:31,116] {logging_mixin.py:115} INFO - [2023-08-13 13:04:31,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:31,229] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:31,239] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:31,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:31,399] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:31,447] {logging_mixin.py:115} INFO - [2023-08-13 13:04:31,447] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:31,484] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 13:04:32,162] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:32,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:32,165] {logging_mixin.py:115} INFO - [2023-08-13 13:04:32,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:32,294] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:32,301] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:32,329] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:32,478] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:32,524] {logging_mixin.py:115} INFO - [2023-08-13 13:04:32,524] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:32,562] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.404 seconds
[2023-08-13 13:04:33,209] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:33,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:33,212] {logging_mixin.py:115} INFO - [2023-08-13 13:04:33,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:33,329] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:33,336] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:33,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:33,486] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:33,522] {logging_mixin.py:115} INFO - [2023-08-13 13:04:33,522] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:33,551] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:04:33,731] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:33,732] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:33,734] {logging_mixin.py:115} INFO - [2023-08-13 13:04:33,733] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:33,850] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:33,858] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:33,884] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:34,017] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:34,052] {logging_mixin.py:115} INFO - [2023-08-13 13:04:34,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:34,091] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.366 seconds
[2023-08-13 13:04:35,126] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:35,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:35,129] {logging_mixin.py:115} INFO - [2023-08-13 13:04:35,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:35,235] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:35,242] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:35,267] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:35,404] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:35,411] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:35,419] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:35,424] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:35,432] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:35,464] {logging_mixin.py:115} INFO - [2023-08-13 13:04:35,464] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:35,490] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.368 seconds
[2023-08-13 13:04:36,198] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:36,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:36,202] {logging_mixin.py:115} INFO - [2023-08-13 13:04:36,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:36,341] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:36,351] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:36,395] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:36,578] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:36,623] {logging_mixin.py:115} INFO - [2023-08-13 13:04:36,623] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:36,651] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.459 seconds
[2023-08-13 13:04:37,245] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:37,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:37,247] {logging_mixin.py:115} INFO - [2023-08-13 13:04:37,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:37,353] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:37,359] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:37,381] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:37,505] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:37,541] {logging_mixin.py:115} INFO - [2023-08-13 13:04:37,540] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:37,572] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:04:38,398] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:38,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:38,401] {logging_mixin.py:115} INFO - [2023-08-13 13:04:38,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:38,501] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:38,507] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:38,527] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:38,643] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:38,681] {logging_mixin.py:115} INFO - [2023-08-13 13:04:38,681] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:38,705] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 13:04:39,127] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:39,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:39,129] {logging_mixin.py:115} INFO - [2023-08-13 13:04:39,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:39,227] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:39,247] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:39,266] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:39,381] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:39,415] {logging_mixin.py:115} INFO - [2023-08-13 13:04:39,415] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:39,442] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 13:04:40,176] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:40,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:40,178] {logging_mixin.py:115} INFO - [2023-08-13 13:04:40,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:40,268] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:40,274] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:40,295] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:40,422] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:40,460] {logging_mixin.py:115} INFO - [2023-08-13 13:04:40,460] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:40,487] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 13:04:41,224] {processor.py:153} INFO - Started process (PID=320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:41,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:41,227] {logging_mixin.py:115} INFO - [2023-08-13 13:04:41,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:41,330] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:41,339] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:41,367] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:41,498] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:41,534] {logging_mixin.py:115} INFO - [2023-08-13 13:04:41,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:41,558] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 13:04:42,267] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:42,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:42,269] {logging_mixin.py:115} INFO - [2023-08-13 13:04:42,269] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:42,366] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:42,371] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:42,391] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:42,507] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:42,541] {logging_mixin.py:115} INFO - [2023-08-13 13:04:42,541] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:42,566] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.302 seconds
[2023-08-13 13:04:43,308] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:43,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:43,310] {logging_mixin.py:115} INFO - [2023-08-13 13:04:43,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:43,398] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:43,405] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:43,425] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:43,545] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:43,578] {logging_mixin.py:115} INFO - [2023-08-13 13:04:43,578] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:43,608] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 13:04:43,833] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:43,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:43,835] {logging_mixin.py:115} INFO - [2023-08-13 13:04:43,835] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:43,924] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:43,930] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:43,950] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:44,064] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:44,098] {logging_mixin.py:115} INFO - [2023-08-13 13:04:44,097] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:44,125] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.297 seconds
[2023-08-13 13:04:44,185] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:44,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:44,188] {logging_mixin.py:115} INFO - [2023-08-13 13:04:44,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:44,283] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:44,289] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:44,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:44,423] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:44,457] {logging_mixin.py:115} INFO - [2023-08-13 13:04:44,457] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:44,484] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.302 seconds
[2023-08-13 13:04:45,229] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:45,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:45,231] {logging_mixin.py:115} INFO - [2023-08-13 13:04:45,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:45,324] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:45,330] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:45,352] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:45,470] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:45,508] {logging_mixin.py:115} INFO - [2023-08-13 13:04:45,508] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:45,538] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.313 seconds
[2023-08-13 13:04:46,269] {processor.py:153} INFO - Started process (PID=350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:46,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:46,271] {logging_mixin.py:115} INFO - [2023-08-13 13:04:46,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:46,383] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:46,397] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:46,423] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:46,550] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:46,588] {logging_mixin.py:115} INFO - [2023-08-13 13:04:46,587] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:46,613] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 13:04:47,305] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:47,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:47,307] {logging_mixin.py:115} INFO - [2023-08-13 13:04:47,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:47,412] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:47,418] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:47,437] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:47,555] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:47,589] {logging_mixin.py:115} INFO - [2023-08-13 13:04:47,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:47,616] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 13:04:48,351] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:48,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:48,354] {logging_mixin.py:115} INFO - [2023-08-13 13:04:48,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:48,460] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:48,467] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:48,491] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:48,617] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:48,652] {logging_mixin.py:115} INFO - [2023-08-13 13:04:48,652] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:48,679] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:04:48,775] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:48,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:48,777] {logging_mixin.py:115} INFO - [2023-08-13 13:04:48,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:48,889] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:48,896] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:48,921] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:49,049] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:49,084] {logging_mixin.py:115} INFO - [2023-08-13 13:04:49,084] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:49,117] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:04:49,235] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:49,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:49,238] {logging_mixin.py:115} INFO - [2023-08-13 13:04:49,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:49,344] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:49,350] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:49,369] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:49,487] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:49,527] {logging_mixin.py:115} INFO - [2023-08-13 13:04:49,527] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:49,561] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 13:04:50,279] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:50,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:50,281] {logging_mixin.py:115} INFO - [2023-08-13 13:04:50,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:50,401] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:50,411] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:50,439] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:50,569] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:50,608] {logging_mixin.py:115} INFO - [2023-08-13 13:04:50,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:50,634] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.359 seconds
[2023-08-13 13:04:51,316] {processor.py:153} INFO - Started process (PID=380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:51,318] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:51,319] {logging_mixin.py:115} INFO - [2023-08-13 13:04:51,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:51,439] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:51,447] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:51,471] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:51,598] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:51,642] {logging_mixin.py:115} INFO - [2023-08-13 13:04:51,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:51,671] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 13:04:52,362] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:52,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:52,364] {logging_mixin.py:115} INFO - [2023-08-13 13:04:52,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:52,459] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:52,465] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:52,489] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:52,608] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:52,642] {logging_mixin.py:115} INFO - [2023-08-13 13:04:52,642] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:52,669] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 13:04:53,404] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:53,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:53,406] {logging_mixin.py:115} INFO - [2023-08-13 13:04:53,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:53,495] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:53,501] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:53,521] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:53,634] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:53,673] {logging_mixin.py:115} INFO - [2023-08-13 13:04:53,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:53,703] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 13:04:53,877] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:53,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:53,880] {logging_mixin.py:115} INFO - [2023-08-13 13:04:53,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:53,991] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:53,997] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:54,017] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:54,142] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:54,179] {logging_mixin.py:115} INFO - [2023-08-13 13:04:54,179] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:54,207] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:04:54,283] {processor.py:153} INFO - Started process (PID=400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:54,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:54,286] {logging_mixin.py:115} INFO - [2023-08-13 13:04:54,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:54,397] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:54,403] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:54,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:54,549] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:54,589] {logging_mixin.py:115} INFO - [2023-08-13 13:04:54,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:54,615] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:04:55,324] {processor.py:153} INFO - Started process (PID=405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:55,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:55,329] {logging_mixin.py:115} INFO - [2023-08-13 13:04:55,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:55,423] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:55,430] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:55,453] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:55,573] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:55,608] {logging_mixin.py:115} INFO - [2023-08-13 13:04:55,608] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:55,635] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 13:04:56,375] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:56,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:56,378] {logging_mixin.py:115} INFO - [2023-08-13 13:04:56,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:56,497] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:56,503] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:56,527] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:56,647] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:56,687] {logging_mixin.py:115} INFO - [2023-08-13 13:04:56,687] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:56,714] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:04:57,418] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:57,419] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:57,420] {logging_mixin.py:115} INFO - [2023-08-13 13:04:57,420] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:57,503] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:57,509] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:57,530] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:57,665] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:57,700] {logging_mixin.py:115} INFO - [2023-08-13 13:04:57,700] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:57,728] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:04:58,440] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:58,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:58,443] {logging_mixin.py:115} INFO - [2023-08-13 13:04:58,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:58,552] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:58,560] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:58,585] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:58,709] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:58,743] {logging_mixin.py:115} INFO - [2023-08-13 13:04:58,743] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:58,774] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:04:59,312] {processor.py:153} INFO - Started process (PID=425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:59,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:04:59,314] {logging_mixin.py:115} INFO - [2023-08-13 13:04:59,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:59,425] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:04:59,432] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:04:59,456] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:04:59,581] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:04:59,616] {logging_mixin.py:115} INFO - [2023-08-13 13:04:59,616] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:04:59,643] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:05:00,379] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:00,380] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:00,382] {logging_mixin.py:115} INFO - [2023-08-13 13:05:00,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:00,557] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:00,565] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:00,589] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:00,715] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:00,754] {logging_mixin.py:115} INFO - [2023-08-13 13:05:00,754] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:00,782] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.408 seconds
[2023-08-13 13:05:01,431] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:01,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:01,436] {logging_mixin.py:115} INFO - [2023-08-13 13:05:01,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:01,560] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:01,572] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:01,611] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:01,737] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:01,773] {logging_mixin.py:115} INFO - [2023-08-13 13:05:01,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:01,800] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.374 seconds
[2023-08-13 13:05:02,472] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:02,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:02,475] {logging_mixin.py:115} INFO - [2023-08-13 13:05:02,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:02,584] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:02,591] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:02,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:02,739] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:02,774] {logging_mixin.py:115} INFO - [2023-08-13 13:05:02,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:02,800] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:05:03,517] {processor.py:153} INFO - Started process (PID=445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:03,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:03,520] {logging_mixin.py:115} INFO - [2023-08-13 13:05:03,520] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:03,628] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:03,635] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:03,659] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:03,785] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:03,820] {logging_mixin.py:115} INFO - [2023-08-13 13:05:03,820] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:03,847] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:05:03,909] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:03,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:03,912] {logging_mixin.py:115} INFO - [2023-08-13 13:05:03,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:04,027] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:04,034] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:04,058] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:04,184] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:04,192] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:04,200] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:04,231] {logging_mixin.py:115} INFO - [2023-08-13 13:05:04,231] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:04,258] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 13:05:04,369] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:04,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:04,372] {logging_mixin.py:115} INFO - [2023-08-13 13:05:04,372] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:04,484] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:04,491] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:04,515] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:04,637] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:04,672] {logging_mixin.py:115} INFO - [2023-08-13 13:05:04,672] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:04,699] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:05:05,436] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:05,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:05,441] {logging_mixin.py:115} INFO - [2023-08-13 13:05:05,441] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:05,547] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:05,554] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:05,573] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:05,692] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:05,727] {logging_mixin.py:115} INFO - [2023-08-13 13:05:05,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:05,754] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.322 seconds
[2023-08-13 13:05:06,484] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:06,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:06,486] {logging_mixin.py:115} INFO - [2023-08-13 13:05:06,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:06,591] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:06,597] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:06,622] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:06,745] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:06,789] {logging_mixin.py:115} INFO - [2023-08-13 13:05:06,789] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:06,814] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:05:07,528] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:07,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:07,530] {logging_mixin.py:115} INFO - [2023-08-13 13:05:07,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:07,625] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:07,631] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:07,650] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:07,770] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:07,804] {logging_mixin.py:115} INFO - [2023-08-13 13:05:07,804] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:07,830] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.306 seconds
[2023-08-13 13:05:08,580] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:08,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:08,582] {logging_mixin.py:115} INFO - [2023-08-13 13:05:08,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:08,677] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:08,683] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:08,702] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:08,819] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:08,853] {logging_mixin.py:115} INFO - [2023-08-13 13:05:08,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:08,879] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.303 seconds
[2023-08-13 13:05:09,425] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:09,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:09,427] {logging_mixin.py:115} INFO - [2023-08-13 13:05:09,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:09,524] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:09,529] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:09,549] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:09,667] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:09,701] {logging_mixin.py:115} INFO - [2023-08-13 13:05:09,701] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:09,730] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 13:05:10,489] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:10,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:10,492] {logging_mixin.py:115} INFO - [2023-08-13 13:05:10,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:10,594] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:10,603] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:10,624] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:10,747] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:10,787] {logging_mixin.py:115} INFO - [2023-08-13 13:05:10,787] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:10,816] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 13:05:11,534] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:11,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:11,536] {logging_mixin.py:115} INFO - [2023-08-13 13:05:11,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:11,641] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:11,646] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:11,666] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:11,794] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:11,829] {logging_mixin.py:115} INFO - [2023-08-13 13:05:11,829] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:11,858] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:05:12,592] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:12,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:12,595] {logging_mixin.py:115} INFO - [2023-08-13 13:05:12,595] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:12,745] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:12,753] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:12,781] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:12,943] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:12,981] {logging_mixin.py:115} INFO - [2023-08-13 13:05:12,981] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:13,012] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.425 seconds
[2023-08-13 13:05:13,638] {processor.py:153} INFO - Started process (PID=500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:13,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:13,640] {logging_mixin.py:115} INFO - [2023-08-13 13:05:13,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:13,739] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:13,751] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:13,776] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:13,907] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:13,945] {logging_mixin.py:115} INFO - [2023-08-13 13:05:13,945] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:13,971] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:05:14,484] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:14,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:14,487] {logging_mixin.py:115} INFO - [2023-08-13 13:05:14,487] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:14,599] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:14,606] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:14,630] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:14,767] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:14,778] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:14,803] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:14,841] {logging_mixin.py:115} INFO - [2023-08-13 13:05:14,841] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:14,875] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.396 seconds
[2023-08-13 13:05:15,543] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:15,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:15,547] {logging_mixin.py:115} INFO - [2023-08-13 13:05:15,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:15,659] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:15,666] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:15,690] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:15,827] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:15,865] {logging_mixin.py:115} INFO - [2023-08-13 13:05:15,865] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:15,897] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 13:05:16,590] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:16,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:16,593] {logging_mixin.py:115} INFO - [2023-08-13 13:05:16,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:16,714] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:16,722] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:16,753] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:16,893] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:16,929] {logging_mixin.py:115} INFO - [2023-08-13 13:05:16,929] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:16,956] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 13:05:17,640] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:17,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:17,642] {logging_mixin.py:115} INFO - [2023-08-13 13:05:17,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:17,757] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:17,764] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:17,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:17,921] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:17,957] {logging_mixin.py:115} INFO - [2023-08-13 13:05:17,957] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:17,984] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 13:05:18,688] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:18,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:18,690] {logging_mixin.py:115} INFO - [2023-08-13 13:05:18,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:18,792] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:18,798] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:18,832] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:19,016] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:19,059] {logging_mixin.py:115} INFO - [2023-08-13 13:05:19,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:19,107] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.424 seconds
[2023-08-13 13:05:19,539] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:19,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:19,542] {logging_mixin.py:115} INFO - [2023-08-13 13:05:19,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:19,649] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:19,655] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:19,677] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:19,798] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:19,805] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:19,812] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:19,844] {logging_mixin.py:115} INFO - [2023-08-13 13:05:19,844] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:19,872] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 13:05:20,605] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:20,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:20,608] {logging_mixin.py:115} INFO - [2023-08-13 13:05:20,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:20,714] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:20,722] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:20,743] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:20,869] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:20,906] {logging_mixin.py:115} INFO - [2023-08-13 13:05:20,906] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:20,936] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:05:21,658] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:21,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:21,660] {logging_mixin.py:115} INFO - [2023-08-13 13:05:21,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:21,777] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:21,784] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:21,810] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:21,935] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:21,969] {logging_mixin.py:115} INFO - [2023-08-13 13:05:21,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:21,996] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:05:22,698] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:22,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:22,700] {logging_mixin.py:115} INFO - [2023-08-13 13:05:22,700] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:22,814] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:22,821] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:22,847] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:22,974] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:23,010] {logging_mixin.py:115} INFO - [2023-08-13 13:05:23,010] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:23,038] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 13:05:23,743] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:23,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:23,746] {logging_mixin.py:115} INFO - [2023-08-13 13:05:23,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:23,867] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:23,876] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:23,907] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:24,040] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:24,074] {logging_mixin.py:115} INFO - [2023-08-13 13:05:24,074] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:24,092] {logging_mixin.py:115} INFO - [2023-08-13 13:05:24,092] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:05:24,105] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.366 seconds
[2023-08-13 13:05:54,212] {processor.py:153} INFO - Started process (PID=555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:54,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:05:54,215] {logging_mixin.py:115} INFO - [2023-08-13 13:05:54,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:54,325] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:05:54,331] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:05:54,355] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:05:54,484] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T12:57:26.213289+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:05:54,520] {logging_mixin.py:115} INFO - [2023-08-13 13:05:54,520] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:05:54,538] {logging_mixin.py:115} INFO - [2023-08-13 13:05:54,538] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:05:54,552] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 13:06:24,639] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:06:24,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:06:24,642] {logging_mixin.py:115} INFO - [2023-08-13 13:06:24,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:06:24,755] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:06:24,788] {logging_mixin.py:115} INFO - [2023-08-13 13:06:24,788] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:06:24,934] {logging_mixin.py:115} INFO - [2023-08-13 13:06:24,934] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:06:24,948] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 13:06:55,037] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:06:55,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:06:55,040] {logging_mixin.py:115} INFO - [2023-08-13 13:06:55,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:06:55,150] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:06:55,184] {logging_mixin.py:115} INFO - [2023-08-13 13:06:55,184] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:06:55,331] {logging_mixin.py:115} INFO - [2023-08-13 13:06:55,331] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:06:55,345] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.312 seconds
[2023-08-13 13:07:25,431] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:07:25,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:07:25,436] {logging_mixin.py:115} INFO - [2023-08-13 13:07:25,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:07:25,583] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:07:25,629] {logging_mixin.py:115} INFO - [2023-08-13 13:07:25,629] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:07:25,800] {logging_mixin.py:115} INFO - [2023-08-13 13:07:25,800] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:07:25,820] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.394 seconds
[2023-08-13 13:07:55,917] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:07:55,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:07:55,921] {logging_mixin.py:115} INFO - [2023-08-13 13:07:55,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:07:56,049] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:07:56,081] {logging_mixin.py:115} INFO - [2023-08-13 13:07:56,081] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:07:56,229] {logging_mixin.py:115} INFO - [2023-08-13 13:07:56,229] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:07:56,253] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.340 seconds
[2023-08-13 13:08:26,366] {processor.py:153} INFO - Started process (PID=580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:08:26,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:08:26,370] {logging_mixin.py:115} INFO - [2023-08-13 13:08:26,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:08:26,500] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:08:26,536] {logging_mixin.py:115} INFO - [2023-08-13 13:08:26,536] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:08:26,683] {logging_mixin.py:115} INFO - [2023-08-13 13:08:26,683] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:08:26,697] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 13:08:56,775] {processor.py:153} INFO - Started process (PID=585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:08:56,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:08:56,777] {logging_mixin.py:115} INFO - [2023-08-13 13:08:56,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:08:56,895] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:08:56,931] {logging_mixin.py:115} INFO - [2023-08-13 13:08:56,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:08:57,075] {logging_mixin.py:115} INFO - [2023-08-13 13:08:57,075] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:08:57,088] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 13:09:27,187] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:09:27,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:09:27,190] {logging_mixin.py:115} INFO - [2023-08-13 13:09:27,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:09:27,274] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:09:27,307] {logging_mixin.py:115} INFO - [2023-08-13 13:09:27,307] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:09:27,448] {logging_mixin.py:115} INFO - [2023-08-13 13:09:27,448] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:09:27,463] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.302 seconds
[2023-08-13 13:09:57,543] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:09:57,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:09:57,545] {logging_mixin.py:115} INFO - [2023-08-13 13:09:57,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:09:57,646] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:09:57,673] {logging_mixin.py:115} INFO - [2023-08-13 13:09:57,673] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:09:57,806] {logging_mixin.py:115} INFO - [2023-08-13 13:09:57,806] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:09:57,819] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.280 seconds
[2023-08-13 13:10:27,907] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:10:27,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:10:27,909] {logging_mixin.py:115} INFO - [2023-08-13 13:10:27,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:10:28,010] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:10:28,039] {logging_mixin.py:115} INFO - [2023-08-13 13:10:28,039] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:10:28,172] {logging_mixin.py:115} INFO - [2023-08-13 13:10:28,172] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:10:28,185] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.282 seconds
[2023-08-13 13:10:58,265] {processor.py:153} INFO - Started process (PID=605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:10:58,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:10:58,267] {logging_mixin.py:115} INFO - [2023-08-13 13:10:58,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:10:58,372] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:10:58,405] {logging_mixin.py:115} INFO - [2023-08-13 13:10:58,405] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:10:58,541] {logging_mixin.py:115} INFO - [2023-08-13 13:10:58,541] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:10:58,554] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.294 seconds
[2023-08-13 13:11:10,629] {processor.py:153} INFO - Started process (PID=610) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:10,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:11:10,632] {logging_mixin.py:115} INFO - [2023-08-13 13:11:10,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:10,757] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:10,793] {logging_mixin.py:115} INFO - [2023-08-13 13:11:10,793] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:11:10,952] {logging_mixin.py:115} INFO - [2023-08-13 13:11:10,952] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:11:10,970] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:11:19,652] {processor.py:153} INFO - Started process (PID=615) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:19,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:11:19,656] {logging_mixin.py:115} INFO - [2023-08-13 13:11:19,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:19,786] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:19,840] {logging_mixin.py:115} INFO - [2023-08-13 13:11:19,840] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:11:20,008] {logging_mixin.py:115} INFO - [2023-08-13 13:11:20,007] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:11:20,025] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 13:11:50,108] {processor.py:153} INFO - Started process (PID=620) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:50,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:11:50,110] {logging_mixin.py:115} INFO - [2023-08-13 13:11:50,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:50,214] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:50,245] {logging_mixin.py:115} INFO - [2023-08-13 13:11:50,245] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:11:50,397] {logging_mixin.py:115} INFO - [2023-08-13 13:11:50,396] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:11:50,417] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 13:11:59,352] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:59,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:11:59,356] {logging_mixin.py:115} INFO - [2023-08-13 13:11:59,355] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:59,501] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:11:59,543] {logging_mixin.py:115} INFO - [2023-08-13 13:11:59,543] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:11:59,706] {logging_mixin.py:115} INFO - [2023-08-13 13:11:59,706] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:11:59,723] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 13:12:29,812] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:29,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:29,816] {logging_mixin.py:115} INFO - [2023-08-13 13:12:29,815] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:29,934] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:29,969] {logging_mixin.py:115} INFO - [2023-08-13 13:12:29,969] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:30,124] {logging_mixin.py:115} INFO - [2023-08-13 13:12:30,124] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:12:30,139] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:12:30,634] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:30,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:30,638] {logging_mixin.py:115} INFO - [2023-08-13 13:12:30,638] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:30,811] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:30,822] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:30,853] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:30,997] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:31,032] {logging_mixin.py:115} INFO - [2023-08-13 13:12:31,032] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:31,063] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.435 seconds
[2023-08-13 13:12:31,815] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:31,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:31,818] {logging_mixin.py:115} INFO - [2023-08-13 13:12:31,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:31,939] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:31,947] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:31,975] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:32,121] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:32,130] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:32,140] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:32,181] {logging_mixin.py:115} INFO - [2023-08-13 13:12:32,181] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:32,212] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.402 seconds
[2023-08-13 13:12:32,880] {processor.py:153} INFO - Started process (PID=192) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:32,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:32,884] {logging_mixin.py:115} INFO - [2023-08-13 13:12:32,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:33,005] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:33,013] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:33,037] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:33,169] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:33,208] {logging_mixin.py:115} INFO - [2023-08-13 13:12:33,208] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:33,244] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.372 seconds
[2023-08-13 13:12:34,000] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:34,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:34,003] {logging_mixin.py:115} INFO - [2023-08-13 13:12:34,003] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:34,128] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:34,135] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:34,162] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:34,309] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:34,317] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:34,329] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:34,366] {logging_mixin.py:115} INFO - [2023-08-13 13:12:34,366] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:34,405] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.409 seconds
[2023-08-13 13:12:34,503] {processor.py:153} INFO - Started process (PID=206) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:34,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:34,507] {logging_mixin.py:115} INFO - [2023-08-13 13:12:34,506] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:34,681] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:34,689] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:34,722] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:34,863] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:34,908] {logging_mixin.py:115} INFO - [2023-08-13 13:12:34,908] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:34,941] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.444 seconds
[2023-08-13 13:12:35,677] {processor.py:153} INFO - Started process (PID=213) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:35,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:35,681] {logging_mixin.py:115} INFO - [2023-08-13 13:12:35,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:35,864] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:35,876] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:35,955] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:36,111] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:36,119] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:36,133] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:36,176] {logging_mixin.py:115} INFO - [2023-08-13 13:12:36,176] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:36,209] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.539 seconds
[2023-08-13 13:12:36,746] {processor.py:153} INFO - Started process (PID=218) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:36,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:36,751] {logging_mixin.py:115} INFO - [2023-08-13 13:12:36,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:36,973] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:36,985] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:37,020] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:37,174] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:37,229] {logging_mixin.py:115} INFO - [2023-08-13 13:12:37,229] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:37,269] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.528 seconds
[2023-08-13 13:12:37,919] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:37,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:37,922] {logging_mixin.py:115} INFO - [2023-08-13 13:12:37,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:38,049] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:38,056] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:38,080] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:38,205] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:38,213] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:38,221] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:38,253] {logging_mixin.py:115} INFO - [2023-08-13 13:12:38,253] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:38,278] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.364 seconds
[2023-08-13 13:12:38,964] {processor.py:153} INFO - Started process (PID=230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:38,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:38,967] {logging_mixin.py:115} INFO - [2023-08-13 13:12:38,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:39,074] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:39,081] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:39,106] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:39,237] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:39,277] {logging_mixin.py:115} INFO - [2023-08-13 13:12:39,277] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:39,310] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 13:12:39,428] {processor.py:153} INFO - Started process (PID=235) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:39,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:39,432] {logging_mixin.py:115} INFO - [2023-08-13 13:12:39,431] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:39,589] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:39,596] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:39,624] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:39,749] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:39,787] {logging_mixin.py:115} INFO - [2023-08-13 13:12:39,787] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:39,817] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.395 seconds
[2023-08-13 13:12:40,664] {processor.py:153} INFO - Started process (PID=240) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:40,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:40,669] {logging_mixin.py:115} INFO - [2023-08-13 13:12:40,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:40,786] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:40,796] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:40,825] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:40,961] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:40,970] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:40,979] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:41,014] {logging_mixin.py:115} INFO - [2023-08-13 13:12:41,014] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:41,048] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.392 seconds
[2023-08-13 13:12:41,737] {processor.py:153} INFO - Started process (PID=245) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:41,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:41,741] {logging_mixin.py:115} INFO - [2023-08-13 13:12:41,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:41,924] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:41,931] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:41,954] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:42,090] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:42,133] {logging_mixin.py:115} INFO - [2023-08-13 13:12:42,133] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:42,169] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.441 seconds
[2023-08-13 13:12:42,793] {processor.py:153} INFO - Started process (PID=250) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:42,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:42,795] {logging_mixin.py:115} INFO - [2023-08-13 13:12:42,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:42,901] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:42,907] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:42,927] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:43,048] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:43,083] {logging_mixin.py:115} INFO - [2023-08-13 13:12:43,083] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:43,109] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:12:43,840] {processor.py:153} INFO - Started process (PID=255) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:43,841] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:43,842] {logging_mixin.py:115} INFO - [2023-08-13 13:12:43,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:43,940] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:43,945] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:43,965] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:44,084] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:44,120] {logging_mixin.py:115} INFO - [2023-08-13 13:12:44,120] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:44,150] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 13:12:44,350] {processor.py:153} INFO - Started process (PID=260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:44,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:44,352] {logging_mixin.py:115} INFO - [2023-08-13 13:12:44,352] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:44,449] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:44,456] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:44,474] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:44,598] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:44,632] {logging_mixin.py:115} INFO - [2023-08-13 13:12:44,631] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:44,656] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 13:12:45,672] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:45,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:45,674] {logging_mixin.py:115} INFO - [2023-08-13 13:12:45,674] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:45,776] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:45,783] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:45,803] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:45,928] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:45,935] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:45,944] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:45,977] {logging_mixin.py:115} INFO - [2023-08-13 13:12:45,977] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:46,009] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 13:12:46,833] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:46,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:46,836] {logging_mixin.py:115} INFO - [2023-08-13 13:12:46,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:46,943] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:46,950] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:46,970] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:47,088] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:47,124] {logging_mixin.py:115} INFO - [2023-08-13 13:12:47,124] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:47,153] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.324 seconds
[2023-08-13 13:12:47,889] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:47,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:47,891] {logging_mixin.py:115} INFO - [2023-08-13 13:12:47,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:47,990] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:47,995] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:48,014] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:48,131] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:48,169] {logging_mixin.py:115} INFO - [2023-08-13 13:12:48,169] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:48,195] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 13:12:48,940] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:48,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:48,942] {logging_mixin.py:115} INFO - [2023-08-13 13:12:48,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:49,038] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:49,044] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:49,063] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:49,178] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:49,211] {logging_mixin.py:115} INFO - [2023-08-13 13:12:49,211] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:49,235] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.300 seconds
[2023-08-13 13:12:49,467] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:49,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:49,469] {logging_mixin.py:115} INFO - [2023-08-13 13:12:49,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:49,568] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:49,575] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:49,596] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:49,716] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:49,752] {logging_mixin.py:115} INFO - [2023-08-13 13:12:49,752] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:49,781] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 13:12:50,713] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:50,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:50,715] {logging_mixin.py:115} INFO - [2023-08-13 13:12:50,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:50,831] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:50,837] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:50,860] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:50,979] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:50,986] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:50,993] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:51,023] {logging_mixin.py:115} INFO - [2023-08-13 13:12:51,023] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:51,047] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:12:51,764] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:51,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:51,766] {logging_mixin.py:115} INFO - [2023-08-13 13:12:51,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:51,878] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:51,886] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:51,909] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:52,035] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:52,071] {logging_mixin.py:115} INFO - [2023-08-13 13:12:52,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:52,097] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:12:52,805] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:52,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:52,808] {logging_mixin.py:115} INFO - [2023-08-13 13:12:52,807] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:52,919] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:52,929] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:52,955] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:53,079] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:53,111] {logging_mixin.py:115} INFO - [2023-08-13 13:12:53,111] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:53,135] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:12:53,866] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:53,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:53,869] {logging_mixin.py:115} INFO - [2023-08-13 13:12:53,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:53,969] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:53,976] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:53,995] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:54,113] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:54,147] {logging_mixin.py:115} INFO - [2023-08-13 13:12:54,147] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:54,172] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.310 seconds
[2023-08-13 13:12:54,711] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:54,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:54,713] {logging_mixin.py:115} INFO - [2023-08-13 13:12:54,713] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:54,807] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:54,812] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:54,831] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:54,955] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:54,990] {logging_mixin.py:115} INFO - [2023-08-13 13:12:54,990] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:55,017] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.310 seconds
[2023-08-13 13:12:55,764] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:55,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:55,767] {logging_mixin.py:115} INFO - [2023-08-13 13:12:55,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:55,892] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:55,901] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:55,930] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:56,073] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:56,111] {logging_mixin.py:115} INFO - [2023-08-13 13:12:56,111] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:56,143] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.383 seconds
[2023-08-13 13:12:56,814] {processor.py:153} INFO - Started process (PID=320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:56,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:56,818] {logging_mixin.py:115} INFO - [2023-08-13 13:12:56,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:56,942] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:56,959] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:56,984] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:57,116] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:57,133] {logging_mixin.py:115} INFO - [2023-08-13 13:12:57,133] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:57,161] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.374 seconds
[2023-08-13 13:12:57,849] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:57,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:57,851] {logging_mixin.py:115} INFO - [2023-08-13 13:12:57,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:58,008] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:58,017] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:58,049] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:58,217] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:58,262] {logging_mixin.py:115} INFO - [2023-08-13 13:12:58,262] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:58,296] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.455 seconds
[2023-08-13 13:12:58,901] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:58,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:58,904] {logging_mixin.py:115} INFO - [2023-08-13 13:12:58,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:59,038] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:59,046] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:59,075] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:59,217] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:59,254] {logging_mixin.py:115} INFO - [2023-08-13 13:12:59,254] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:59,286] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.389 seconds
[2023-08-13 13:12:59,385] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:59,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:12:59,388] {logging_mixin.py:115} INFO - [2023-08-13 13:12:59,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:59,521] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:12:59,529] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:12:59,553] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:12:59,686] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:12:59,726] {logging_mixin.py:115} INFO - [2023-08-13 13:12:59,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:12:59,761] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.381 seconds
[2023-08-13 13:13:00,807] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:00,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:00,811] {logging_mixin.py:115} INFO - [2023-08-13 13:13:00,811] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:00,935] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:00,944] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:00,972] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:01,116] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:01,125] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:01,134] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:01,140] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:01,147] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:01,182] {logging_mixin.py:115} INFO - [2023-08-13 13:13:01,182] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:01,216] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.416 seconds
[2023-08-13 13:13:01,854] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:01,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:01,857] {logging_mixin.py:115} INFO - [2023-08-13 13:13:01,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:01,977] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:01,984] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:02,010] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:02,148] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:02,183] {logging_mixin.py:115} INFO - [2023-08-13 13:13:02,183] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:02,211] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 13:13:02,907] {processor.py:153} INFO - Started process (PID=350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:02,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:02,910] {logging_mixin.py:115} INFO - [2023-08-13 13:13:02,910] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:03,159] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:03,170] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:03,205] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:03,381] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:03,435] {logging_mixin.py:115} INFO - [2023-08-13 13:13:03,434] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:03,484] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.583 seconds
[2023-08-13 13:13:03,998] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:04,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:04,002] {logging_mixin.py:115} INFO - [2023-08-13 13:13:04,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:04,157] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:04,165] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:04,198] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:04,374] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:04,420] {logging_mixin.py:115} INFO - [2023-08-13 13:13:04,420] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:04,464] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.475 seconds
[2023-08-13 13:13:04,799] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:04,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:04,801] {logging_mixin.py:115} INFO - [2023-08-13 13:13:04,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:04,939] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:04,949] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:04,987] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:05,138] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:05,187] {logging_mixin.py:115} INFO - [2023-08-13 13:13:05,187] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:05,220] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.426 seconds
[2023-08-13 13:13:05,854] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:05,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:05,857] {logging_mixin.py:115} INFO - [2023-08-13 13:13:05,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:05,994] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:06,002] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:06,030] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:06,196] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:06,269] {logging_mixin.py:115} INFO - [2023-08-13 13:13:06,269] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:06,321] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.472 seconds
[2023-08-13 13:13:06,901] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:06,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:06,903] {logging_mixin.py:115} INFO - [2023-08-13 13:13:06,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:07,016] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:07,026] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:07,055] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:07,186] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:07,221] {logging_mixin.py:115} INFO - [2023-08-13 13:13:07,221] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:07,248] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 13:13:07,955] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:07,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:07,958] {logging_mixin.py:115} INFO - [2023-08-13 13:13:07,958] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:08,094] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:08,103] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:08,132] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:08,278] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:08,323] {logging_mixin.py:115} INFO - [2023-08-13 13:13:08,323] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:08,361] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.411 seconds
[2023-08-13 13:13:09,016] {processor.py:153} INFO - Started process (PID=380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:09,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:09,019] {logging_mixin.py:115} INFO - [2023-08-13 13:13:09,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:09,140] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:09,148] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:09,177] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:09,513] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:09,601] {logging_mixin.py:115} INFO - [2023-08-13 13:13:09,601] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:09,649] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.639 seconds
[2023-08-13 13:13:09,880] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:09,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:09,885] {logging_mixin.py:115} INFO - [2023-08-13 13:13:09,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:10,071] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:10,081] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:10,112] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:10,255] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:10,262] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:10,270] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:10,308] {logging_mixin.py:115} INFO - [2023-08-13 13:13:10,307] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:10,340] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.466 seconds
[2023-08-13 13:13:10,933] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:10,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:10,936] {logging_mixin.py:115} INFO - [2023-08-13 13:13:10,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:11,061] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:11,070] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:11,099] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:11,240] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:11,278] {logging_mixin.py:115} INFO - [2023-08-13 13:13:11,277] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:11,344] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.416 seconds
[2023-08-13 13:13:12,099] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:12,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:12,106] {logging_mixin.py:115} INFO - [2023-08-13 13:13:12,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:12,334] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:12,344] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:12,384] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:12,517] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:12,555] {logging_mixin.py:115} INFO - [2023-08-13 13:13:12,554] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:12,583] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.493 seconds
[2023-08-13 13:13:13,138] {processor.py:153} INFO - Started process (PID=400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:13,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:13,141] {logging_mixin.py:115} INFO - [2023-08-13 13:13:13,140] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:13,276] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:13,284] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:13,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:13,445] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:13,481] {logging_mixin.py:115} INFO - [2023-08-13 13:13:13,481] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:13,512] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 13:13:14,192] {processor.py:153} INFO - Started process (PID=405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:14,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:14,194] {logging_mixin.py:115} INFO - [2023-08-13 13:13:14,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:14,312] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:14,321] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:14,349] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:14,477] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:14,512] {logging_mixin.py:115} INFO - [2023-08-13 13:13:14,512] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:14,544] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 13:13:14,925] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:14,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:14,928] {logging_mixin.py:115} INFO - [2023-08-13 13:13:14,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:15,063] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:15,071] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:15,097] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:15,234] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:15,241] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:15,251] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:15,288] {logging_mixin.py:115} INFO - [2023-08-13 13:13:15,288] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:15,329] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.409 seconds
[2023-08-13 13:13:16,034] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:16,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:16,038] {logging_mixin.py:115} INFO - [2023-08-13 13:13:16,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:16,341] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:16,377] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:16,446] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:16,719] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:16,777] {logging_mixin.py:115} INFO - [2023-08-13 13:13:16,777] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:16,814] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.787 seconds
[2023-08-13 13:13:17,074] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:17,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:17,076] {logging_mixin.py:115} INFO - [2023-08-13 13:13:17,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:17,206] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:17,216] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:17,243] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:17,376] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:17,411] {logging_mixin.py:115} INFO - [2023-08-13 13:13:17,411] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:17,439] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 13:13:18,118] {processor.py:153} INFO - Started process (PID=425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:18,119] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:18,121] {logging_mixin.py:115} INFO - [2023-08-13 13:13:18,121] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:18,232] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:18,240] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:18,263] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:18,386] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:18,420] {logging_mixin.py:115} INFO - [2023-08-13 13:13:18,420] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:18,447] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:13:19,165] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:19,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:19,168] {logging_mixin.py:115} INFO - [2023-08-13 13:13:19,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:19,289] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:19,298] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:19,325] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:19,464] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:19,499] {logging_mixin.py:115} INFO - [2023-08-13 13:13:19,499] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:19,528] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.367 seconds
[2023-08-13 13:13:19,679] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:19,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:19,682] {logging_mixin.py:115} INFO - [2023-08-13 13:13:19,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:19,824] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:19,833] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:19,865] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:20,017] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:20,058] {logging_mixin.py:115} INFO - [2023-08-13 13:13:20,058] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:20,094] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.419 seconds
[2023-08-13 13:13:21,039] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:21,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:21,042] {logging_mixin.py:115} INFO - [2023-08-13 13:13:21,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:21,190] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:21,205] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:21,233] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:21,390] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:21,404] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:21,424] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:21,487] {logging_mixin.py:115} INFO - [2023-08-13 13:13:21,487] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:21,528] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.496 seconds
[2023-08-13 13:13:22,086] {processor.py:153} INFO - Started process (PID=445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:22,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:22,090] {logging_mixin.py:115} INFO - [2023-08-13 13:13:22,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:22,226] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:22,234] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:22,261] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:22,395] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:22,432] {logging_mixin.py:115} INFO - [2023-08-13 13:13:22,431] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:22,461] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.381 seconds
[2023-08-13 13:13:23,131] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:23,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:23,134] {logging_mixin.py:115} INFO - [2023-08-13 13:13:23,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:23,269] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:23,278] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:23,307] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:23,446] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:23,483] {logging_mixin.py:115} INFO - [2023-08-13 13:13:23,483] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:23,511] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.385 seconds
[2023-08-13 13:13:24,181] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:24,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:24,184] {logging_mixin.py:115} INFO - [2023-08-13 13:13:24,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:24,312] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:24,320] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:24,345] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:24,479] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:24,516] {logging_mixin.py:115} INFO - [2023-08-13 13:13:24,516] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:24,545] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.368 seconds
[2023-08-13 13:13:25,038] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:25,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:25,041] {logging_mixin.py:115} INFO - [2023-08-13 13:13:25,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:25,158] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:25,165] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:25,191] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:25,331] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:25,376] {logging_mixin.py:115} INFO - [2023-08-13 13:13:25,376] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:25,406] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.372 seconds
[2023-08-13 13:13:26,095] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:26,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:26,098] {logging_mixin.py:115} INFO - [2023-08-13 13:13:26,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:26,221] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:26,228] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:26,255] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:26,393] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:26,464] {logging_mixin.py:115} INFO - [2023-08-13 13:13:26,464] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:26,503] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.413 seconds
[2023-08-13 13:13:27,126] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:27,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:27,129] {logging_mixin.py:115} INFO - [2023-08-13 13:13:27,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:27,245] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:27,253] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:27,277] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:27,408] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:27,445] {logging_mixin.py:115} INFO - [2023-08-13 13:13:27,445] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:27,476] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.355 seconds
[2023-08-13 13:13:28,170] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:28,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:28,173] {logging_mixin.py:115} INFO - [2023-08-13 13:13:28,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:28,288] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:28,296] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:28,328] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:28,501] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:28,560] {logging_mixin.py:115} INFO - [2023-08-13 13:13:28,560] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:28,594] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.429 seconds
[2023-08-13 13:13:29,232] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:29,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:29,254] {logging_mixin.py:115} INFO - [2023-08-13 13:13:29,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:29,376] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:29,383] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:29,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:29,535] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:29,574] {logging_mixin.py:115} INFO - [2023-08-13 13:13:29,573] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:29,606] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 13:13:29,712] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:29,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:29,715] {logging_mixin.py:115} INFO - [2023-08-13 13:13:29,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:29,842] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:29,851] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:29,878] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:30,019] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:30,027] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:30,036] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:30,072] {logging_mixin.py:115} INFO - [2023-08-13 13:13:30,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:30,106] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.399 seconds
[2023-08-13 13:13:31,132] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:31,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:31,135] {logging_mixin.py:115} INFO - [2023-08-13 13:13:31,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:31,264] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:31,273] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:31,302] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:31,454] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:31,462] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:31,470] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:31,502] {logging_mixin.py:115} INFO - [2023-08-13 13:13:31,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:31,535] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.408 seconds
[2023-08-13 13:13:32,182] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:32,183] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:32,185] {logging_mixin.py:115} INFO - [2023-08-13 13:13:32,185] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:32,296] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:32,303] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:32,326] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:32,454] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:32,554] {logging_mixin.py:115} INFO - [2023-08-13 13:13:32,554] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:32,583] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.405 seconds
[2023-08-13 13:13:33,248] {processor.py:153} INFO - Started process (PID=500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:33,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:33,250] {logging_mixin.py:115} INFO - [2023-08-13 13:13:33,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:33,359] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:33,366] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:33,390] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:33,518] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:33,559] {logging_mixin.py:115} INFO - [2023-08-13 13:13:33,559] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:33,590] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:13:34,298] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:34,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:34,300] {logging_mixin.py:115} INFO - [2023-08-13 13:13:34,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:34,413] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:34,421] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:34,448] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:34,586] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:34,622] {logging_mixin.py:115} INFO - [2023-08-13 13:13:34,621] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:34,649] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 13:13:35,134] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:35,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:35,136] {logging_mixin.py:115} INFO - [2023-08-13 13:13:35,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:35,243] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:35,250] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:35,273] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:35,490] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:35,544] {logging_mixin.py:115} INFO - [2023-08-13 13:13:35,544] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:35,588] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.459 seconds
[2023-08-13 13:13:36,183] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:36,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:36,186] {logging_mixin.py:115} INFO - [2023-08-13 13:13:36,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:36,309] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:36,316] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:36,345] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:36,496] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:36,553] {logging_mixin.py:115} INFO - [2023-08-13 13:13:36,553] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:36,601] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.423 seconds
[2023-08-13 13:13:37,237] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:37,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:37,239] {logging_mixin.py:115} INFO - [2023-08-13 13:13:37,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:37,368] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:37,376] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:37,405] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:37,549] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:37,594] {logging_mixin.py:115} INFO - [2023-08-13 13:13:37,594] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:37,626] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.394 seconds
[2023-08-13 13:13:38,291] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:38,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:38,294] {logging_mixin.py:115} INFO - [2023-08-13 13:13:38,294] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:38,411] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:38,418] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:38,438] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:38,576] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:38,615] {logging_mixin.py:115} INFO - [2023-08-13 13:13:38,615] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:38,648] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 13:13:39,340] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:39,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:13:39,342] {logging_mixin.py:115} INFO - [2023-08-13 13:13:39,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:39,446] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:13:39,453] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:13:39,475] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:13:39,596] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:04:13.675221+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:13:39,632] {logging_mixin.py:115} INFO - [2023-08-13 13:13:39,632] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:13:39,655] {logging_mixin.py:115} INFO - [2023-08-13 13:13:39,655] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:13:39,669] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:14:09,788] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:14:09,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:14:09,790] {logging_mixin.py:115} INFO - [2023-08-13 13:14:09,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:14:09,901] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:14:09,936] {logging_mixin.py:115} INFO - [2023-08-13 13:14:09,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:14:10,095] {logging_mixin.py:115} INFO - [2023-08-13 13:14:10,095] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:14:10,109] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 13:14:40,206] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:14:40,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:14:40,208] {logging_mixin.py:115} INFO - [2023-08-13 13:14:40,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:14:40,310] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:14:40,351] {logging_mixin.py:115} INFO - [2023-08-13 13:14:40,351] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:14:40,499] {logging_mixin.py:115} INFO - [2023-08-13 13:14:40,499] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:14:40,514] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.312 seconds
[2023-08-13 13:15:10,604] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:15:10,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:15:10,609] {logging_mixin.py:115} INFO - [2023-08-13 13:15:10,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:15:10,749] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:15:10,788] {logging_mixin.py:115} INFO - [2023-08-13 13:15:10,788] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:15:10,946] {logging_mixin.py:115} INFO - [2023-08-13 13:15:10,946] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:15:10,961] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 13:15:41,058] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:15:41,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:15:41,061] {logging_mixin.py:115} INFO - [2023-08-13 13:15:41,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:15:41,207] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:15:41,249] {logging_mixin.py:115} INFO - [2023-08-13 13:15:41,249] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:15:41,436] {logging_mixin.py:115} INFO - [2023-08-13 13:15:41,436] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:15:41,453] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.400 seconds
[2023-08-13 13:16:11,565] {processor.py:153} INFO - Started process (PID=555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:16:11,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:16:11,569] {logging_mixin.py:115} INFO - [2023-08-13 13:16:11,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:16:11,696] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:16:11,732] {logging_mixin.py:115} INFO - [2023-08-13 13:16:11,732] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:16:11,887] {logging_mixin.py:115} INFO - [2023-08-13 13:16:11,887] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:16:11,901] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:16:42,004] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:16:42,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:16:42,006] {logging_mixin.py:115} INFO - [2023-08-13 13:16:42,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:16:42,118] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:16:42,153] {logging_mixin.py:115} INFO - [2023-08-13 13:16:42,153] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:16:42,304] {logging_mixin.py:115} INFO - [2023-08-13 13:16:42,304] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:16:42,320] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:17:12,473] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:17:12,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:17:12,476] {logging_mixin.py:115} INFO - [2023-08-13 13:17:12,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:17:12,593] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:17:12,630] {logging_mixin.py:115} INFO - [2023-08-13 13:17:12,630] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:17:12,804] {logging_mixin.py:115} INFO - [2023-08-13 13:17:12,803] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:17:12,821] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 13:17:42,909] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:17:42,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:17:42,912] {logging_mixin.py:115} INFO - [2023-08-13 13:17:42,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:17:43,035] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:17:43,070] {logging_mixin.py:115} INFO - [2023-08-13 13:17:43,070] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:17:43,234] {logging_mixin.py:115} INFO - [2023-08-13 13:17:43,234] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:17:43,248] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:18:13,350] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:18:13,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:18:13,354] {logging_mixin.py:115} INFO - [2023-08-13 13:18:13,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:18:13,471] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:18:13,504] {logging_mixin.py:115} INFO - [2023-08-13 13:18:13,504] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:18:13,652] {logging_mixin.py:115} INFO - [2023-08-13 13:18:13,652] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:18:13,665] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.319 seconds
[2023-08-13 13:18:43,753] {processor.py:153} INFO - Started process (PID=580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:18:43,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:18:43,756] {logging_mixin.py:115} INFO - [2023-08-13 13:18:43,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:18:43,876] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:18:43,912] {logging_mixin.py:115} INFO - [2023-08-13 13:18:43,911] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:18:44,053] {logging_mixin.py:115} INFO - [2023-08-13 13:18:44,053] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:18:44,066] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.317 seconds
[2023-08-13 13:19:14,154] {processor.py:153} INFO - Started process (PID=585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:19:14,155] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:19:14,156] {logging_mixin.py:115} INFO - [2023-08-13 13:19:14,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:19:14,265] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:19:14,298] {logging_mixin.py:115} INFO - [2023-08-13 13:19:14,298] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:19:14,455] {logging_mixin.py:115} INFO - [2023-08-13 13:19:14,455] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:19:14,471] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.322 seconds
[2023-08-13 13:19:44,568] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:19:44,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:19:44,572] {logging_mixin.py:115} INFO - [2023-08-13 13:19:44,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:19:44,685] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:19:44,723] {logging_mixin.py:115} INFO - [2023-08-13 13:19:44,723] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:19:44,872] {logging_mixin.py:115} INFO - [2023-08-13 13:19:44,872] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:19:44,886] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:20:14,977] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:20:14,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:20:14,980] {logging_mixin.py:115} INFO - [2023-08-13 13:20:14,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:20:15,090] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:20:15,123] {logging_mixin.py:115} INFO - [2023-08-13 13:20:15,123] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:20:15,268] {logging_mixin.py:115} INFO - [2023-08-13 13:20:15,268] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:20:15,281] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 13:20:45,370] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:20:45,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:20:45,373] {logging_mixin.py:115} INFO - [2023-08-13 13:20:45,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:20:45,505] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:20:45,562] {logging_mixin.py:115} INFO - [2023-08-13 13:20:45,562] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:20:45,714] {logging_mixin.py:115} INFO - [2023-08-13 13:20:45,714] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:20:45,728] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 13:21:04,402] {processor.py:153} INFO - Started process (PID=605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:04,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:21:04,405] {logging_mixin.py:115} INFO - [2023-08-13 13:21:04,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:04,426] {logging_mixin.py:115} INFO - [2023-08-13 13:21:04,425] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:21:04,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:04,451] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.053 seconds
[2023-08-13 13:21:28,655] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:28,656] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:21:28,657] {logging_mixin.py:115} INFO - [2023-08-13 13:21:28,657] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:28,665] {logging_mixin.py:115} INFO - [2023-08-13 13:21:28,663] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:21:28,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:28,689] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.037 seconds
[2023-08-13 13:21:31,732] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:31,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:21:31,734] {logging_mixin.py:115} INFO - [2023-08-13 13:21:31,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:31,768] {logging_mixin.py:115} INFO - [2023-08-13 13:21:31,766] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:21:31,769] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:21:31,794] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.067 seconds
[2023-08-13 13:22:01,869] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:22:01,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:22:01,873] {logging_mixin.py:115} INFO - [2023-08-13 13:22:01,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:22:01,887] {logging_mixin.py:115} INFO - [2023-08-13 13:22:01,885] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:22:01,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:22:01,915] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.052 seconds
[2023-08-13 13:22:31,949] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:22:31,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:22:31,951] {logging_mixin.py:115} INFO - [2023-08-13 13:22:31,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:22:31,958] {logging_mixin.py:115} INFO - [2023-08-13 13:22:31,957] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:22:31,959] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:22:31,981] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.036 seconds
[2023-08-13 13:23:02,045] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:02,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:02,047] {logging_mixin.py:115} INFO - [2023-08-13 13:23:02,047] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:02,055] {logging_mixin.py:115} INFO - [2023-08-13 13:23:02,053] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:23:02,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:02,079] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.039 seconds
[2023-08-13 13:23:32,138] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:32,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:32,142] {logging_mixin.py:115} INFO - [2023-08-13 13:23:32,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:32,152] {logging_mixin.py:115} INFO - [2023-08-13 13:23:32,150] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/orchestration/submit_spark_job_to_emr.py", line 3, in <module>
    from general import *
ModuleNotFoundError: No module named 'general'
[2023-08-13 13:23:32,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:32,182] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.048 seconds
[2023-08-13 13:23:36,161] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:36,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:36,164] {logging_mixin.py:115} INFO - [2023-08-13 13:23:36,164] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:36,301] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:36,550] {logging_mixin.py:115} INFO - [2023-08-13 13:23:36,550] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:23:36,589] {logging_mixin.py:115} INFO - [2023-08-13 13:23:36,589] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:23:36,625] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.468 seconds
[2023-08-13 13:23:46,092] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:46,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:46,095] {logging_mixin.py:115} INFO - [2023-08-13 13:23:46,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:46,201] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:46,207] {logging_mixin.py:115} INFO - [2023-08-13 13:23:46,207] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:23:46,231] {logging_mixin.py:115} INFO - [2023-08-13 13:23:46,231] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:23:46,364] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.276 seconds
[2023-08-13 13:23:57,238] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:57,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:57,241] {logging_mixin.py:115} INFO - [2023-08-13 13:23:57,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:57,358] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:57,366] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:23:57,394] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:23:57,526] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:23:57,535] {logging_mixin.py:115} INFO - [2023-08-13 13:23:57,535] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:23:57,566] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:23:58,372] {processor.py:153} INFO - Started process (PID=182) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:58,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:58,376] {logging_mixin.py:115} INFO - [2023-08-13 13:23:58,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:58,518] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:58,530] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:23:58,560] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:23:58,701] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:23:58,708] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:23:58,717] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:23:58,728] {logging_mixin.py:115} INFO - [2023-08-13 13:23:58,728] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:23:58,763] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.397 seconds
[2023-08-13 13:23:59,432] {processor.py:153} INFO - Started process (PID=187) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:59,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:23:59,435] {logging_mixin.py:115} INFO - [2023-08-13 13:23:59,434] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:59,549] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:23:59,557] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:23:59,581] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:23:59,717] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:23:59,727] {logging_mixin.py:115} INFO - [2023-08-13 13:23:59,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:23:59,761] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:24:00,563] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:24:00,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:24:00,565] {logging_mixin.py:115} INFO - [2023-08-13 13:24:00,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:24:00,718] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:24:00,729] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:24:00,778] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:24:00,972] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:24:00,981] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:24:00,989] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:24:00,996] {logging_mixin.py:115} INFO - [2023-08-13 13:24:00,996] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:24:01,029] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.471 seconds
[2023-08-13 13:24:31,137] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:24:31,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:24:31,151] {logging_mixin.py:115} INFO - [2023-08-13 13:24:31,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:24:31,325] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:24:31,349] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:24:31,416] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:24:31,606] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:24:31,657] {logging_mixin.py:115} INFO - [2023-08-13 13:24:31,656] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:24:31,686] {logging_mixin.py:115} INFO - [2023-08-13 13:24:31,686] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:24:31,710] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.578 seconds
[2023-08-13 13:25:01,815] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:01,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:25:01,818] {logging_mixin.py:115} INFO - [2023-08-13 13:25:01,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:01,954] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:01,994] {logging_mixin.py:115} INFO - [2023-08-13 13:25:01,994] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:25:02,153] {logging_mixin.py:115} INFO - [2023-08-13 13:25:02,153] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:25:02,169] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 13:25:32,257] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:32,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:25:32,259] {logging_mixin.py:115} INFO - [2023-08-13 13:25:32,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:32,377] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:32,416] {logging_mixin.py:115} INFO - [2023-08-13 13:25:32,415] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:25:32,561] {logging_mixin.py:115} INFO - [2023-08-13 13:25:32,561] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:25:32,574] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:25:53,323] {processor.py:153} INFO - Started process (PID=215) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:53,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:25:53,325] {logging_mixin.py:115} INFO - [2023-08-13 13:25:53,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:53,454] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:25:53,645] {logging_mixin.py:115} INFO - [2023-08-13 13:25:53,645] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:25:53,666] {logging_mixin.py:115} INFO - [2023-08-13 13:25:53,666] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:25:53,682] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.364 seconds
[2023-08-13 13:26:14,086] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:14,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:14,088] {logging_mixin.py:115} INFO - [2023-08-13 13:26:14,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:14,204] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:14,210] {logging_mixin.py:115} INFO - [2023-08-13 13:26:14,210] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:14,236] {logging_mixin.py:115} INFO - [2023-08-13 13:26:14,236] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:26:14,370] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.288 seconds
[2023-08-13 13:26:16,295] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:16,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:16,298] {logging_mixin.py:115} INFO - [2023-08-13 13:26:16,298] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:16,437] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:16,444] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:16,470] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:16,617] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:16,629] {logging_mixin.py:115} INFO - [2023-08-13 13:26:16,629] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:16,659] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.369 seconds
[2023-08-13 13:26:17,368] {processor.py:153} INFO - Started process (PID=180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:17,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:17,372] {logging_mixin.py:115} INFO - [2023-08-13 13:26:17,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:17,487] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:17,494] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:17,519] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:17,655] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:17,666] {logging_mixin.py:115} INFO - [2023-08-13 13:26:17,665] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:17,697] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:26:18,450] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:18,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:18,453] {logging_mixin.py:115} INFO - [2023-08-13 13:26:18,453] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:18,577] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:18,586] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:18,617] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:18,776] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:18,793] {logging_mixin.py:115} INFO - [2023-08-13 13:26:18,793] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:18,837] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.392 seconds
[2023-08-13 13:26:19,115] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:19,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:19,120] {logging_mixin.py:115} INFO - [2023-08-13 13:26:19,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:19,257] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:19,265] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:19,291] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:19,422] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:19,432] {logging_mixin.py:115} INFO - [2023-08-13 13:26:19,432] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:19,462] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 13:26:20,220] {processor.py:153} INFO - Started process (PID=195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:20,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:20,223] {logging_mixin.py:115} INFO - [2023-08-13 13:26:20,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:20,369] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:20,383] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:20,442] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:20,602] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:20,617] {logging_mixin.py:115} INFO - [2023-08-13 13:26:20,616] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:20,651] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.437 seconds
[2023-08-13 13:26:21,297] {processor.py:153} INFO - Started process (PID=200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:21,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:21,301] {logging_mixin.py:115} INFO - [2023-08-13 13:26:21,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:21,466] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:21,477] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:21,520] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:21,650] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:21,660] {logging_mixin.py:115} INFO - [2023-08-13 13:26:21,660] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:21,695] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.403 seconds
[2023-08-13 13:26:22,376] {processor.py:153} INFO - Started process (PID=205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:22,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:22,379] {logging_mixin.py:115} INFO - [2023-08-13 13:26:22,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:22,489] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:22,496] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:22,518] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:22,643] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:12:30.141639+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:22,652] {logging_mixin.py:115} INFO - [2023-08-13 13:26:22,652] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:22,683] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.312 seconds
[2023-08-13 13:26:23,508] {processor.py:153} INFO - Started process (PID=210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:23,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:23,515] {logging_mixin.py:115} INFO - [2023-08-13 13:26:23,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:23,662] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:23,669] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:23,691] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:23,817] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:23,856] {logging_mixin.py:115} INFO - [2023-08-13 13:26:23,856] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:23,890] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.390 seconds
[2023-08-13 13:26:24,065] {processor.py:153} INFO - Started process (PID=217) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:24,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:24,069] {logging_mixin.py:115} INFO - [2023-08-13 13:26:24,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:24,189] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:24,200] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:24,225] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:24,372] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:24,381] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:24,391] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:24,420] {logging_mixin.py:115} INFO - [2023-08-13 13:26:24,420] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:24,446] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.386 seconds
[2023-08-13 13:26:25,296] {processor.py:153} INFO - Started process (PID=222) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:25,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:25,331] {logging_mixin.py:115} INFO - [2023-08-13 13:26:25,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:25,583] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:25,595] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:25,626] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:25,787] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:25,797] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:25,806] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:25,854] {logging_mixin.py:115} INFO - [2023-08-13 13:26:25,854] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:25,889] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.609 seconds
[2023-08-13 13:26:26,522] {processor.py:153} INFO - Started process (PID=231) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:26,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:26,525] {logging_mixin.py:115} INFO - [2023-08-13 13:26:26,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:26,655] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:26,668] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:26,699] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:26,934] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:26,944] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:26,953] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:26,993] {logging_mixin.py:115} INFO - [2023-08-13 13:26:26,992] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:27,031] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.535 seconds
[2023-08-13 13:26:27,572] {processor.py:153} INFO - Started process (PID=236) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:27,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:27,575] {logging_mixin.py:115} INFO - [2023-08-13 13:26:27,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:27,777] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:27,791] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:27,839] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:28,054] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:28,103] {logging_mixin.py:115} INFO - [2023-08-13 13:26:28,103] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:28,148] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.584 seconds
[2023-08-13 13:26:28,765] {processor.py:153} INFO - Started process (PID=243) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:28,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:28,768] {logging_mixin.py:115} INFO - [2023-08-13 13:26:28,768] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:28,948] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:28,958] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:28,991] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:29,166] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:29,176] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:29,186] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:29,245] {logging_mixin.py:115} INFO - [2023-08-13 13:26:29,245] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:29,298] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.540 seconds
[2023-08-13 13:26:30,409] {processor.py:153} INFO - Started process (PID=248) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:30,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:30,416] {logging_mixin.py:115} INFO - [2023-08-13 13:26:30,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:30,662] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:30,672] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:30,702] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:30,872] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:30,882] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:30,893] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:30,898] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:30,906] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:30,941] {logging_mixin.py:115} INFO - [2023-08-13 13:26:30,941] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:30,987] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.585 seconds
[2023-08-13 13:26:31,859] {processor.py:153} INFO - Started process (PID=255) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:31,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:31,862] {logging_mixin.py:115} INFO - [2023-08-13 13:26:31,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:31,993] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:32,002] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:32,028] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:32,215] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:32,223] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:32,232] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:32,271] {logging_mixin.py:115} INFO - [2023-08-13 13:26:32,271] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:32,301] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.447 seconds
[2023-08-13 13:26:32,912] {processor.py:153} INFO - Started process (PID=260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:32,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:32,915] {logging_mixin.py:115} INFO - [2023-08-13 13:26:32,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:33,025] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:33,033] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:33,057] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:33,189] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:33,224] {logging_mixin.py:115} INFO - [2023-08-13 13:26:33,224] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:33,251] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 13:26:33,965] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:33,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:33,967] {logging_mixin.py:115} INFO - [2023-08-13 13:26:33,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:34,099] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:34,107] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:34,137] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:34,278] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:34,321] {logging_mixin.py:115} INFO - [2023-08-13 13:26:34,321] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:34,358] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.399 seconds
[2023-08-13 13:26:35,465] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:35,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:35,468] {logging_mixin.py:115} INFO - [2023-08-13 13:26:35,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:35,618] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:35,633] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:35,668] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:35,818] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:35,829] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:35,838] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:35,843] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:35,852] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:35,888] {logging_mixin.py:115} INFO - [2023-08-13 13:26:35,888] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:35,921] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.462 seconds
[2023-08-13 13:26:36,521] {processor.py:153} INFO - Started process (PID=275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:36,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:36,525] {logging_mixin.py:115} INFO - [2023-08-13 13:26:36,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:36,667] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:36,674] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:36,698] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:36,828] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:36,864] {logging_mixin.py:115} INFO - [2023-08-13 13:26:36,864] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:36,899] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.385 seconds
[2023-08-13 13:26:37,562] {processor.py:153} INFO - Started process (PID=280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:37,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:37,565] {logging_mixin.py:115} INFO - [2023-08-13 13:26:37,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:37,669] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:37,674] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:37,693] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:37,817] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:37,856] {logging_mixin.py:115} INFO - [2023-08-13 13:26:37,856] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:37,890] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:26:38,611] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:38,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:38,614] {logging_mixin.py:115} INFO - [2023-08-13 13:26:38,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:38,774] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:38,788] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:38,818] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:38,953] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:38,987] {logging_mixin.py:115} INFO - [2023-08-13 13:26:38,987] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:39,016] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.410 seconds
[2023-08-13 13:26:39,420] {processor.py:153} INFO - Started process (PID=290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:39,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:39,422] {logging_mixin.py:115} INFO - [2023-08-13 13:26:39,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:39,522] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:39,529] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:39,552] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:39,681] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:39,718] {logging_mixin.py:115} INFO - [2023-08-13 13:26:39,718] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:39,746] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.331 seconds
[2023-08-13 13:26:40,484] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:40,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:40,500] {logging_mixin.py:115} INFO - [2023-08-13 13:26:40,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:40,628] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:40,635] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:40,661] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:40,792] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:40,829] {logging_mixin.py:115} INFO - [2023-08-13 13:26:40,829] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:40,861] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.382 seconds
[2023-08-13 13:26:41,571] {processor.py:153} INFO - Started process (PID=300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:41,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:41,576] {logging_mixin.py:115} INFO - [2023-08-13 13:26:41,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:41,702] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:41,708] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:41,734] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:41,860] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:41,897] {logging_mixin.py:115} INFO - [2023-08-13 13:26:41,897] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:41,926] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.364 seconds
[2023-08-13 13:26:42,617] {processor.py:153} INFO - Started process (PID=305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:42,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:42,621] {logging_mixin.py:115} INFO - [2023-08-13 13:26:42,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:42,740] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:42,747] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:42,770] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:42,896] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:42,934] {logging_mixin.py:115} INFO - [2023-08-13 13:26:42,934] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:42,966] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 13:26:43,671] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:43,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:43,674] {logging_mixin.py:115} INFO - [2023-08-13 13:26:43,674] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:43,793] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:43,800] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:43,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:43,955] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:43,989] {logging_mixin.py:115} INFO - [2023-08-13 13:26:43,989] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:44,015] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 13:26:44,093] {processor.py:153} INFO - Started process (PID=315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:44,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:44,095] {logging_mixin.py:115} INFO - [2023-08-13 13:26:44,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:44,207] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:44,214] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:44,235] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:44,357] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:44,395] {logging_mixin.py:115} INFO - [2023-08-13 13:26:44,395] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:44,423] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:26:44,479] {processor.py:153} INFO - Started process (PID=320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:44,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:44,482] {logging_mixin.py:115} INFO - [2023-08-13 13:26:44,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:44,598] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:44,606] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:44,631] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:44,760] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:44,767] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:44,775] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:44,808] {logging_mixin.py:115} INFO - [2023-08-13 13:26:44,808] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:44,834] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 13:26:45,587] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:45,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:45,591] {logging_mixin.py:115} INFO - [2023-08-13 13:26:45,591] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:45,743] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:45,752] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:45,785] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:45,924] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:45,960] {logging_mixin.py:115} INFO - [2023-08-13 13:26:45,960] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:45,988] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.407 seconds
[2023-08-13 13:26:46,631] {processor.py:153} INFO - Started process (PID=330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:46,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:46,634] {logging_mixin.py:115} INFO - [2023-08-13 13:26:46,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:46,765] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:46,775] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:46,800] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:46,929] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:46,964] {logging_mixin.py:115} INFO - [2023-08-13 13:26:46,964] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:46,992] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.365 seconds
[2023-08-13 13:26:47,681] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:47,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:47,683] {logging_mixin.py:115} INFO - [2023-08-13 13:26:47,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:47,792] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:47,800] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:47,824] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:47,958] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:47,995] {logging_mixin.py:115} INFO - [2023-08-13 13:26:47,995] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:48,026] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 13:26:48,726] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:48,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:48,729] {logging_mixin.py:115} INFO - [2023-08-13 13:26:48,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:48,842] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:48,852] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:48,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:49,023] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:49,080] {logging_mixin.py:115} INFO - [2023-08-13 13:26:49,080] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:49,108] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.386 seconds
[2023-08-13 13:26:49,535] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:49,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:49,538] {logging_mixin.py:115} INFO - [2023-08-13 13:26:49,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:49,659] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:49,667] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:49,697] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:49,820] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:49,852] {logging_mixin.py:115} INFO - [2023-08-13 13:26:49,852] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:49,876] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:26:50,595] {processor.py:153} INFO - Started process (PID=350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:50,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:50,598] {logging_mixin.py:115} INFO - [2023-08-13 13:26:50,598] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:50,708] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:50,715] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:50,739] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:50,874] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:50,919] {logging_mixin.py:115} INFO - [2023-08-13 13:26:50,919] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:50,945] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 13:26:51,647] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:51,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:51,649] {logging_mixin.py:115} INFO - [2023-08-13 13:26:51,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:51,763] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:51,770] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:51,798] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:51,931] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:51,968] {logging_mixin.py:115} INFO - [2023-08-13 13:26:51,967] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:51,995] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.355 seconds
[2023-08-13 13:26:52,698] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:52,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:52,702] {logging_mixin.py:115} INFO - [2023-08-13 13:26:52,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:52,864] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:52,872] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:52,905] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:53,038] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:53,077] {logging_mixin.py:115} INFO - [2023-08-13 13:26:53,077] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:53,107] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.414 seconds
[2023-08-13 13:26:53,749] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:53,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:53,752] {logging_mixin.py:115} INFO - [2023-08-13 13:26:53,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:53,889] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:53,896] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:53,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:54,056] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:54,093] {logging_mixin.py:115} INFO - [2023-08-13 13:26:54,093] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:54,122] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 13:26:54,212] {processor.py:153} INFO - Started process (PID=370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:54,213] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:54,215] {logging_mixin.py:115} INFO - [2023-08-13 13:26:54,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:54,362] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:54,371] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:54,407] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:54,659] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:54,722] {logging_mixin.py:115} INFO - [2023-08-13 13:26:54,722] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:54,756] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.549 seconds
[2023-08-13 13:26:55,732] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:55,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:55,735] {logging_mixin.py:115} INFO - [2023-08-13 13:26:55,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:55,866] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:55,875] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:55,904] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:56,044] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:56,055] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:56,065] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:56,098] {logging_mixin.py:115} INFO - [2023-08-13 13:26:56,098] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:56,126] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.400 seconds
[2023-08-13 13:26:56,764] {processor.py:153} INFO - Started process (PID=380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:56,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:56,767] {logging_mixin.py:115} INFO - [2023-08-13 13:26:56,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:56,890] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:56,897] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:56,925] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:57,053] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:57,091] {logging_mixin.py:115} INFO - [2023-08-13 13:26:57,091] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:57,120] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 13:26:57,810] {processor.py:153} INFO - Started process (PID=385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:57,812] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:57,813] {logging_mixin.py:115} INFO - [2023-08-13 13:26:57,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:57,935] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:57,943] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:57,974] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:58,107] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:58,147] {logging_mixin.py:115} INFO - [2023-08-13 13:26:58,147] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:58,177] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.372 seconds
[2023-08-13 13:26:58,859] {processor.py:153} INFO - Started process (PID=390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:58,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:58,862] {logging_mixin.py:115} INFO - [2023-08-13 13:26:58,862] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:58,973] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:58,980] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:59,002] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:26:59,125] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:26:59,161] {logging_mixin.py:115} INFO - [2023-08-13 13:26:59,161] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:26:59,188] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:26:59,712] {processor.py:153} INFO - Started process (PID=395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:59,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:26:59,715] {logging_mixin.py:115} INFO - [2023-08-13 13:26:59,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:59,840] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:26:59,847] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:26:59,874] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:00,009] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:00,017] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:00,026] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:00,058] {logging_mixin.py:115} INFO - [2023-08-13 13:27:00,058] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:00,090] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.383 seconds
[2023-08-13 13:27:00,777] {processor.py:153} INFO - Started process (PID=400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:00,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:00,780] {logging_mixin.py:115} INFO - [2023-08-13 13:27:00,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:00,909] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:00,917] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:00,942] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:01,079] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:01,120] {logging_mixin.py:115} INFO - [2023-08-13 13:27:01,120] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:01,150] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 13:27:01,824] {processor.py:153} INFO - Started process (PID=405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:01,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:01,826] {logging_mixin.py:115} INFO - [2023-08-13 13:27:01,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:01,947] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:01,953] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:01,976] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:02,105] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:02,145] {logging_mixin.py:115} INFO - [2023-08-13 13:27:02,145] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:02,175] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.357 seconds
[2023-08-13 13:27:02,874] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:02,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:02,877] {logging_mixin.py:115} INFO - [2023-08-13 13:27:02,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:03,008] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:03,016] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:03,041] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:03,181] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:03,218] {logging_mixin.py:115} INFO - [2023-08-13 13:27:03,217] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:03,247] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.378 seconds
[2023-08-13 13:27:03,929] {processor.py:153} INFO - Started process (PID=415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:03,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:03,932] {logging_mixin.py:115} INFO - [2023-08-13 13:27:03,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:04,085] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:04,095] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:04,134] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:04,285] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:04,326] {logging_mixin.py:115} INFO - [2023-08-13 13:27:04,325] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:04,359] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.435 seconds
[2023-08-13 13:27:04,769] {processor.py:153} INFO - Started process (PID=420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:04,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:04,772] {logging_mixin.py:115} INFO - [2023-08-13 13:27:04,772] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:04,901] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:04,909] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:04,937] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:05,077] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:05,084] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:05,091] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:05,124] {logging_mixin.py:115} INFO - [2023-08-13 13:27:05,124] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:05,155] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.392 seconds
[2023-08-13 13:27:05,825] {processor.py:153} INFO - Started process (PID=425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:05,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:05,828] {logging_mixin.py:115} INFO - [2023-08-13 13:27:05,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:05,934] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:05,941] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:05,961] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:06,085] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:06,122] {logging_mixin.py:115} INFO - [2023-08-13 13:27:06,122] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:06,150] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.331 seconds
[2023-08-13 13:27:06,873] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:06,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:06,877] {logging_mixin.py:115} INFO - [2023-08-13 13:27:06,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:06,983] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:06,990] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:07,015] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:07,140] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:07,175] {logging_mixin.py:115} INFO - [2023-08-13 13:27:07,175] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:07,202] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:27:07,920] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:07,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:07,923] {logging_mixin.py:115} INFO - [2023-08-13 13:27:07,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:08,023] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:08,029] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:08,049] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:08,170] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:08,204] {logging_mixin.py:115} INFO - [2023-08-13 13:27:08,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:08,234] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 13:27:08,966] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:08,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:08,969] {logging_mixin.py:115} INFO - [2023-08-13 13:27:08,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:09,077] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:09,083] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:09,104] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:09,228] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:09,264] {logging_mixin.py:115} INFO - [2023-08-13 13:27:09,264] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:09,290] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.328 seconds
[2023-08-13 13:27:09,825] {processor.py:153} INFO - Started process (PID=445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:09,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:09,828] {logging_mixin.py:115} INFO - [2023-08-13 13:27:09,828] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:09,941] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:09,949] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:09,973] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:10,097] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:10,131] {logging_mixin.py:115} INFO - [2023-08-13 13:27:10,131] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:10,159] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:27:10,889] {processor.py:153} INFO - Started process (PID=450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:10,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:10,891] {logging_mixin.py:115} INFO - [2023-08-13 13:27:10,891] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:10,997] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:11,004] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:11,027] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:11,156] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:11,199] {logging_mixin.py:115} INFO - [2023-08-13 13:27:11,199] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:11,243] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 13:27:11,937] {processor.py:153} INFO - Started process (PID=455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:11,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:11,940] {logging_mixin.py:115} INFO - [2023-08-13 13:27:11,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:12,045] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:12,052] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:12,072] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:12,194] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:12,229] {logging_mixin.py:115} INFO - [2023-08-13 13:27:12,229] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:12,258] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.325 seconds
[2023-08-13 13:27:12,988] {processor.py:153} INFO - Started process (PID=460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:12,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:12,991] {logging_mixin.py:115} INFO - [2023-08-13 13:27:12,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:13,109] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:13,116] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:13,139] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:13,271] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:13,308] {logging_mixin.py:115} INFO - [2023-08-13 13:27:13,308] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:13,338] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 13:27:14,038] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:14,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:14,060] {logging_mixin.py:115} INFO - [2023-08-13 13:27:14,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:14,171] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:14,178] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:14,201] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:14,335] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:14,374] {logging_mixin.py:115} INFO - [2023-08-13 13:27:14,374] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:14,406] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.373 seconds
[2023-08-13 13:27:14,885] {processor.py:153} INFO - Started process (PID=470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:14,888] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:14,889] {logging_mixin.py:115} INFO - [2023-08-13 13:27:14,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:14,997] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:15,005] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:15,029] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:15,163] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:15,171] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:15,180] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:15,185] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:15,193] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:15,228] {logging_mixin.py:115} INFO - [2023-08-13 13:27:15,228] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:15,259] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.379 seconds
[2023-08-13 13:27:15,943] {processor.py:153} INFO - Started process (PID=475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:15,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:15,946] {logging_mixin.py:115} INFO - [2023-08-13 13:27:15,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:16,051] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:16,058] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:16,080] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:16,207] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:16,247] {logging_mixin.py:115} INFO - [2023-08-13 13:27:16,247] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:16,274] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 13:27:16,991] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:16,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:16,994] {logging_mixin.py:115} INFO - [2023-08-13 13:27:16,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:17,108] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:17,115] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:17,139] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:17,274] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:17,308] {logging_mixin.py:115} INFO - [2023-08-13 13:27:17,308] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:17,337] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 13:27:18,036] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:18,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:18,039] {logging_mixin.py:115} INFO - [2023-08-13 13:27:18,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:18,143] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:18,150] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:18,170] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:18,295] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:18,329] {logging_mixin.py:115} INFO - [2023-08-13 13:27:18,329] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:18,355] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:27:19,079] {processor.py:153} INFO - Started process (PID=490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:19,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:19,081] {logging_mixin.py:115} INFO - [2023-08-13 13:27:19,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:19,179] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:19,185] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:19,204] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:19,329] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:19,364] {logging_mixin.py:115} INFO - [2023-08-13 13:27:19,364] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:19,393] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 13:27:19,950] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:19,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:19,953] {logging_mixin.py:115} INFO - [2023-08-13 13:27:19,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:20,054] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:20,061] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:20,082] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:20,203] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:20,241] {logging_mixin.py:115} INFO - [2023-08-13 13:27:20,241] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:20,274] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.328 seconds
[2023-08-13 13:27:21,003] {processor.py:153} INFO - Started process (PID=500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:21,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:21,006] {logging_mixin.py:115} INFO - [2023-08-13 13:27:21,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:21,119] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:21,127] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:21,151] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:21,277] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:21,312] {logging_mixin.py:115} INFO - [2023-08-13 13:27:21,312] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:21,345] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:27:22,049] {processor.py:153} INFO - Started process (PID=505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:22,050] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:22,052] {logging_mixin.py:115} INFO - [2023-08-13 13:27:22,051] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:22,161] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:22,169] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:22,193] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:22,318] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:22,351] {logging_mixin.py:115} INFO - [2023-08-13 13:27:22,351] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:22,377] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:27:23,100] {processor.py:153} INFO - Started process (PID=510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:23,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:23,103] {logging_mixin.py:115} INFO - [2023-08-13 13:27:23,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:23,228] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:23,235] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:23,264] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:23,401] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:23,439] {logging_mixin.py:115} INFO - [2023-08-13 13:27:23,438] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:23,466] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.371 seconds
[2023-08-13 13:27:24,145] {processor.py:153} INFO - Started process (PID=515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:24,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:24,148] {logging_mixin.py:115} INFO - [2023-08-13 13:27:24,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:24,245] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:24,252] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:24,275] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:24,401] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:24,436] {logging_mixin.py:115} INFO - [2023-08-13 13:27:24,436] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:24,464] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:27:25,017] {processor.py:153} INFO - Started process (PID=520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:25,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:25,020] {logging_mixin.py:115} INFO - [2023-08-13 13:27:25,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:25,125] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:25,131] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:25,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:25,269] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:25,277] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:25,285] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:25,316] {logging_mixin.py:115} INFO - [2023-08-13 13:27:25,316] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:25,345] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:27:26,078] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:26,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:26,080] {logging_mixin.py:115} INFO - [2023-08-13 13:27:26,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:26,199] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:26,205] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:26,228] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:26,356] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:26,407] {logging_mixin.py:115} INFO - [2023-08-13 13:27:26,407] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:26,442] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.369 seconds
[2023-08-13 13:27:27,106] {processor.py:153} INFO - Started process (PID=530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:27,107] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:27,109] {logging_mixin.py:115} INFO - [2023-08-13 13:27:27,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:27,213] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:27,225] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:27,253] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:27,389] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:27,425] {logging_mixin.py:115} INFO - [2023-08-13 13:27:27,425] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:27,452] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 13:27:28,151] {processor.py:153} INFO - Started process (PID=535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:28,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:28,154] {logging_mixin.py:115} INFO - [2023-08-13 13:27:28,153] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:28,276] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:28,284] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:28,309] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:28,446] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:28,481] {logging_mixin.py:115} INFO - [2023-08-13 13:27:28,481] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:28,508] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 13:27:29,191] {processor.py:153} INFO - Started process (PID=540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:29,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:29,194] {logging_mixin.py:115} INFO - [2023-08-13 13:27:29,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:29,309] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:29,317] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:29,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:29,469] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:29,509] {logging_mixin.py:115} INFO - [2023-08-13 13:27:29,509] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:29,543] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 13:27:30,062] {processor.py:153} INFO - Started process (PID=545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:30,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:30,065] {logging_mixin.py:115} INFO - [2023-08-13 13:27:30,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:30,189] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:30,197] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:30,222] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:30,361] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:30,399] {logging_mixin.py:115} INFO - [2023-08-13 13:27:30,399] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:30,430] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.373 seconds
[2023-08-13 13:27:31,125] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:31,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:31,127] {logging_mixin.py:115} INFO - [2023-08-13 13:27:31,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:31,247] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:31,254] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:31,279] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:31,423] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:31,457] {logging_mixin.py:115} INFO - [2023-08-13 13:27:31,457] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:31,482] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.362 seconds
[2023-08-13 13:27:32,165] {processor.py:153} INFO - Started process (PID=555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:32,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:32,167] {logging_mixin.py:115} INFO - [2023-08-13 13:27:32,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:32,263] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:32,271] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:32,294] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:32,420] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:32,455] {logging_mixin.py:115} INFO - [2023-08-13 13:27:32,454] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:32,481] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:27:33,211] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:33,212] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:33,213] {logging_mixin.py:115} INFO - [2023-08-13 13:27:33,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:33,323] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:33,329] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:33,353] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:33,480] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:33,518] {logging_mixin.py:115} INFO - [2023-08-13 13:27:33,518] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:33,551] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:27:34,260] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:34,261] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:34,263] {logging_mixin.py:115} INFO - [2023-08-13 13:27:34,263] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:34,394] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:34,404] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:34,433] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:34,568] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:34,603] {logging_mixin.py:115} INFO - [2023-08-13 13:27:34,603] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:34,632] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.377 seconds
[2023-08-13 13:27:35,122] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:35,124] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:35,125] {logging_mixin.py:115} INFO - [2023-08-13 13:27:35,125] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:35,224] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:35,230] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:35,249] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:35,379] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:35,386] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:35,394] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:35,425] {logging_mixin.py:115} INFO - [2023-08-13 13:27:35,424] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:35,450] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:27:36,208] {processor.py:153} INFO - Started process (PID=575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:36,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:36,210] {logging_mixin.py:115} INFO - [2023-08-13 13:27:36,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:36,307] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:36,313] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:36,340] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:36,471] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:36,509] {logging_mixin.py:115} INFO - [2023-08-13 13:27:36,509] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:36,542] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:27:37,229] {processor.py:153} INFO - Started process (PID=580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:37,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:37,232] {logging_mixin.py:115} INFO - [2023-08-13 13:27:37,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:37,340] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:37,347] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:37,370] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:37,498] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:37,533] {logging_mixin.py:115} INFO - [2023-08-13 13:27:37,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:37,560] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 13:27:38,279] {processor.py:153} INFO - Started process (PID=585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:38,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:38,281] {logging_mixin.py:115} INFO - [2023-08-13 13:27:38,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:38,388] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:38,395] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:38,418] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:38,542] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:38,576] {logging_mixin.py:115} INFO - [2023-08-13 13:27:38,576] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:38,605] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.331 seconds
[2023-08-13 13:27:39,323] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:39,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:39,326] {logging_mixin.py:115} INFO - [2023-08-13 13:27:39,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:39,436] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:39,442] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:39,463] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:39,586] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:39,622] {logging_mixin.py:115} INFO - [2023-08-13 13:27:39,622] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:39,649] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 13:27:40,177] {processor.py:153} INFO - Started process (PID=595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:40,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:40,180] {logging_mixin.py:115} INFO - [2023-08-13 13:27:40,180] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:40,278] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:40,285] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:40,304] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:40,437] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:40,498] {logging_mixin.py:115} INFO - [2023-08-13 13:27:40,498] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:40,535] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 13:27:41,238] {processor.py:153} INFO - Started process (PID=600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:41,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:41,241] {logging_mixin.py:115} INFO - [2023-08-13 13:27:41,240] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:41,360] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:41,370] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:41,408] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:41,579] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:41,616] {logging_mixin.py:115} INFO - [2023-08-13 13:27:41,616] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:41,651] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.417 seconds
[2023-08-13 13:27:42,288] {processor.py:153} INFO - Started process (PID=605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:42,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:42,291] {logging_mixin.py:115} INFO - [2023-08-13 13:27:42,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:42,457] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:42,473] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:42,508] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:42,676] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:42,717] {logging_mixin.py:115} INFO - [2023-08-13 13:27:42,717] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:42,766] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.482 seconds
[2023-08-13 13:27:43,335] {processor.py:153} INFO - Started process (PID=610) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:43,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:43,337] {logging_mixin.py:115} INFO - [2023-08-13 13:27:43,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:43,452] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:43,459] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:43,482] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:43,606] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:43,643] {logging_mixin.py:115} INFO - [2023-08-13 13:27:43,643] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:43,672] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:27:44,243] {processor.py:153} INFO - Started process (PID=615) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:44,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:44,246] {logging_mixin.py:115} INFO - [2023-08-13 13:27:44,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:44,357] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:44,365] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:44,389] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:44,523] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:44,559] {logging_mixin.py:115} INFO - [2023-08-13 13:27:44,558] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:44,590] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.351 seconds
[2023-08-13 13:27:45,254] {processor.py:153} INFO - Started process (PID=620) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:45,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:45,259] {logging_mixin.py:115} INFO - [2023-08-13 13:27:45,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:45,408] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:45,418] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:45,444] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:45,625] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:45,634] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:45,642] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:45,674] {logging_mixin.py:115} INFO - [2023-08-13 13:27:45,674] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:45,702] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.453 seconds
[2023-08-13 13:27:46,320] {processor.py:153} INFO - Started process (PID=625) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:46,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:46,323] {logging_mixin.py:115} INFO - [2023-08-13 13:27:46,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:46,471] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:46,481] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:46,524] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:46,739] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:46,776] {logging_mixin.py:115} INFO - [2023-08-13 13:27:46,776] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:46,802] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.486 seconds
[2023-08-13 13:27:47,370] {processor.py:153} INFO - Started process (PID=630) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:47,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:47,373] {logging_mixin.py:115} INFO - [2023-08-13 13:27:47,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:47,475] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:47,481] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:47,502] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:47,624] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:47,658] {logging_mixin.py:115} INFO - [2023-08-13 13:27:47,658] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:47,685] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.319 seconds
[2023-08-13 13:27:48,426] {processor.py:153} INFO - Started process (PID=635) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:48,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:48,428] {logging_mixin.py:115} INFO - [2023-08-13 13:27:48,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:48,537] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:48,543] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:48,567] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:48,691] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:48,725] {logging_mixin.py:115} INFO - [2023-08-13 13:27:48,725] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:48,752] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 13:27:49,469] {processor.py:153} INFO - Started process (PID=640) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:49,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:49,472] {logging_mixin.py:115} INFO - [2023-08-13 13:27:49,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:49,576] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:49,582] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:49,602] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:49,727] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:49,763] {logging_mixin.py:115} INFO - [2023-08-13 13:27:49,762] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:49,791] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 13:27:50,335] {processor.py:153} INFO - Started process (PID=645) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:50,338] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:50,340] {logging_mixin.py:115} INFO - [2023-08-13 13:27:50,340] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:50,501] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:50,509] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:50,536] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:50,674] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:50,721] {logging_mixin.py:115} INFO - [2023-08-13 13:27:50,721] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:50,755] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.429 seconds
[2023-08-13 13:27:51,399] {processor.py:153} INFO - Started process (PID=650) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:51,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:51,402] {logging_mixin.py:115} INFO - [2023-08-13 13:27:51,402] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:51,503] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:51,508] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:51,530] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:51,666] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:51,707] {logging_mixin.py:115} INFO - [2023-08-13 13:27:51,706] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:51,739] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:27:52,438] {processor.py:153} INFO - Started process (PID=655) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:52,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:52,440] {logging_mixin.py:115} INFO - [2023-08-13 13:27:52,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:52,552] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:52,559] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:52,578] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:52,705] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:52,740] {logging_mixin.py:115} INFO - [2023-08-13 13:27:52,740] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:52,767] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:27:53,483] {processor.py:153} INFO - Started process (PID=660) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:53,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:53,485] {logging_mixin.py:115} INFO - [2023-08-13 13:27:53,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:53,578] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:53,584] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:53,604] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:53,733] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:53,765] {logging_mixin.py:115} INFO - [2023-08-13 13:27:53,765] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:53,791] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.312 seconds
[2023-08-13 13:27:54,502] {processor.py:153} INFO - Started process (PID=665) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:54,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:54,505] {logging_mixin.py:115} INFO - [2023-08-13 13:27:54,505] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:54,617] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:54,624] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:54,647] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:54,767] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:54,802] {logging_mixin.py:115} INFO - [2023-08-13 13:27:54,802] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:54,830] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:27:55,389] {processor.py:153} INFO - Started process (PID=670) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:55,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:55,393] {logging_mixin.py:115} INFO - [2023-08-13 13:27:55,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:55,521] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:55,529] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:55,560] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:55,691] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:55,736] {logging_mixin.py:115} INFO - [2023-08-13 13:27:55,736] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:55,769] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.385 seconds
[2023-08-13 13:27:56,449] {processor.py:153} INFO - Started process (PID=675) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:56,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:56,452] {logging_mixin.py:115} INFO - [2023-08-13 13:27:56,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:56,563] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:56,572] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:56,598] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:56,721] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:56,809] {logging_mixin.py:115} INFO - [2023-08-13 13:27:56,809] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:56,839] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.416 seconds
[2023-08-13 13:27:57,484] {processor.py:153} INFO - Started process (PID=680) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:57,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:57,486] {logging_mixin.py:115} INFO - [2023-08-13 13:27:57,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:57,602] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:57,610] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:57,635] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:57,771] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:57,784] {logging_mixin.py:115} INFO - [2023-08-13 13:27:57,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:57,819] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.340 seconds
[2023-08-13 13:27:58,545] {processor.py:153} INFO - Started process (PID=685) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:58,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:58,548] {logging_mixin.py:115} INFO - [2023-08-13 13:27:58,548] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:58,678] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:58,690] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:58,724] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:58,865] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:58,876] {logging_mixin.py:115} INFO - [2023-08-13 13:27:58,876] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:58,906] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.365 seconds
[2023-08-13 13:27:59,270] {processor.py:153} INFO - Started process (PID=690) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:59,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:27:59,273] {logging_mixin.py:115} INFO - [2023-08-13 13:27:59,273] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:59,406] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:27:59,415] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:27:59,444] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:27:59,578] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:27:59,589] {logging_mixin.py:115} INFO - [2023-08-13 13:27:59,588] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:27:59,619] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 13:28:00,328] {processor.py:153} INFO - Started process (PID=695) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:00,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:00,332] {logging_mixin.py:115} INFO - [2023-08-13 13:28:00,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:00,605] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:00,616] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:00,652] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:00,876] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:00,893] {logging_mixin.py:115} INFO - [2023-08-13 13:28:00,892] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:00,936] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.612 seconds
[2023-08-13 13:28:01,590] {processor.py:153} INFO - Started process (PID=700) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:01,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:01,593] {logging_mixin.py:115} INFO - [2023-08-13 13:28:01,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:01,709] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:01,717] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:01,748] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:01,890] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:01,899] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:01,907] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:01,915] {logging_mixin.py:115} INFO - [2023-08-13 13:28:01,915] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:01,948] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 13:28:02,635] {processor.py:153} INFO - Started process (PID=705) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:02,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:02,638] {logging_mixin.py:115} INFO - [2023-08-13 13:28:02,638] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:02,765] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:02,773] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:02,801] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:02,934] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:02,944] {logging_mixin.py:115} INFO - [2023-08-13 13:28:02,944] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:02,976] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:28:03,684] {processor.py:153} INFO - Started process (PID=710) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:03,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:03,687] {logging_mixin.py:115} INFO - [2023-08-13 13:28:03,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:03,808] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:03,816] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:03,845] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:04,016] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:04,026] {logging_mixin.py:115} INFO - [2023-08-13 13:28:04,026] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:04,061] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.381 seconds
[2023-08-13 13:28:04,528] {processor.py:153} INFO - Started process (PID=715) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:04,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:04,531] {logging_mixin.py:115} INFO - [2023-08-13 13:28:04,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:04,648] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:04,656] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:04,680] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:04,806] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:04,816] {logging_mixin.py:115} INFO - [2023-08-13 13:28:04,816] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:04,845] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:28:05,583] {processor.py:153} INFO - Started process (PID=720) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:05,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:05,587] {logging_mixin.py:115} INFO - [2023-08-13 13:28:05,586] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:05,705] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:05,712] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:05,734] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:05,861] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:05,880] {logging_mixin.py:115} INFO - [2023-08-13 13:28:05,880] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:05,921] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 13:28:06,638] {processor.py:153} INFO - Started process (PID=725) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:06,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:06,640] {logging_mixin.py:115} INFO - [2023-08-13 13:28:06,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:06,754] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:06,764] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:06,788] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:06,921] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:06,931] {logging_mixin.py:115} INFO - [2023-08-13 13:28:06,931] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:06,962] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.328 seconds
[2023-08-13 13:28:07,688] {processor.py:153} INFO - Started process (PID=730) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:07,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:07,691] {logging_mixin.py:115} INFO - [2023-08-13 13:28:07,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:07,803] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:07,812] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:07,839] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:07,977] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:07,987] {logging_mixin.py:115} INFO - [2023-08-13 13:28:07,987] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:08,018] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:28:08,735] {processor.py:153} INFO - Started process (PID=735) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:08,737] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:08,738] {logging_mixin.py:115} INFO - [2023-08-13 13:28:08,738] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:08,885] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:08,893] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:08,920] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:09,076] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:09,088] {logging_mixin.py:115} INFO - [2023-08-13 13:28:09,088] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:09,130] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.399 seconds
[2023-08-13 13:28:09,830] {processor.py:153} INFO - Started process (PID=740) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:09,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:09,833] {logging_mixin.py:115} INFO - [2023-08-13 13:28:09,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:09,961] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:09,968] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:09,993] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:10,127] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:10,138] {logging_mixin.py:115} INFO - [2023-08-13 13:28:10,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:10,169] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 13:28:10,664] {processor.py:153} INFO - Started process (PID=745) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:10,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:10,668] {logging_mixin.py:115} INFO - [2023-08-13 13:28:10,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:10,947] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:10,957] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:10,991] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:11,229] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:11,250] {logging_mixin.py:115} INFO - [2023-08-13 13:28:11,250] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:11,290] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.634 seconds
[2023-08-13 13:28:11,717] {processor.py:153} INFO - Started process (PID=750) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:11,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:11,719] {logging_mixin.py:115} INFO - [2023-08-13 13:28:11,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:11,854] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:11,862] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:11,891] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:12,020] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:12,030] {logging_mixin.py:115} INFO - [2023-08-13 13:28:12,030] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:12,060] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 13:28:12,839] {processor.py:153} INFO - Started process (PID=755) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:12,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:12,847] {logging_mixin.py:115} INFO - [2023-08-13 13:28:12,847] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:13,007] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:13,019] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:13,047] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:13,177] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:13,187] {logging_mixin.py:115} INFO - [2023-08-13 13:28:13,187] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:13,216] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.395 seconds
[2023-08-13 13:28:13,898] {processor.py:153} INFO - Started process (PID=760) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:13,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:13,907] {logging_mixin.py:115} INFO - [2023-08-13 13:28:13,907] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:14,093] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:14,103] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:14,130] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:14,261] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:14,271] {logging_mixin.py:115} INFO - [2023-08-13 13:28:14,271] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:14,301] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.409 seconds
[2023-08-13 13:28:14,598] {processor.py:153} INFO - Started process (PID=765) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:14,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:14,602] {logging_mixin.py:115} INFO - [2023-08-13 13:28:14,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:14,726] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:14,733] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:14,759] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:14,895] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:14,902] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:14,911] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:14,917] {logging_mixin.py:115} INFO - [2023-08-13 13:28:14,917] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:14,947] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.354 seconds
[2023-08-13 13:28:15,654] {processor.py:153} INFO - Started process (PID=770) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:15,656] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:15,658] {logging_mixin.py:115} INFO - [2023-08-13 13:28:15,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:15,783] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:15,793] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:15,822] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:15,948] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:15,958] {logging_mixin.py:115} INFO - [2023-08-13 13:28:15,958] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:15,987] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:28:16,778] {processor.py:153} INFO - Started process (PID=775) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:16,793] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:16,795] {logging_mixin.py:115} INFO - [2023-08-13 13:28:16,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:16,921] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:16,931] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:16,956] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:17,089] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:17,096] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:17,104] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:17,112] {logging_mixin.py:115} INFO - [2023-08-13 13:28:17,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:17,145] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.374 seconds
[2023-08-13 13:28:17,824] {processor.py:153} INFO - Started process (PID=780) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:17,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:17,826] {logging_mixin.py:115} INFO - [2023-08-13 13:28:17,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:17,934] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:17,940] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:17,963] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:18,087] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:18,098] {logging_mixin.py:115} INFO - [2023-08-13 13:28:18,098] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:18,127] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.307 seconds
[2023-08-13 13:28:18,875] {processor.py:153} INFO - Started process (PID=785) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:18,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:18,877] {logging_mixin.py:115} INFO - [2023-08-13 13:28:18,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:18,986] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:18,994] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:19,018] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:19,147] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:19,157] {logging_mixin.py:115} INFO - [2023-08-13 13:28:19,157] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:19,191] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:28:19,925] {processor.py:153} INFO - Started process (PID=790) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:19,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:19,928] {logging_mixin.py:115} INFO - [2023-08-13 13:28:19,927] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:20,036] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:20,043] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:20,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:20,200] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:20,210] {logging_mixin.py:115} INFO - [2023-08-13 13:28:20,210] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:20,241] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:28:20,798] {processor.py:153} INFO - Started process (PID=795) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:20,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:20,801] {logging_mixin.py:115} INFO - [2023-08-13 13:28:20,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:20,912] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:20,919] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:20,942] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:21,068] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:21,078] {logging_mixin.py:115} INFO - [2023-08-13 13:28:21,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:21,108] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 13:28:21,859] {processor.py:153} INFO - Started process (PID=800) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:21,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:21,862] {logging_mixin.py:115} INFO - [2023-08-13 13:28:21,862] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:21,988] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:21,995] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:22,019] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:22,159] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:22,169] {logging_mixin.py:115} INFO - [2023-08-13 13:28:22,169] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:22,210] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.356 seconds
[2023-08-13 13:28:22,937] {processor.py:153} INFO - Started process (PID=805) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:22,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:22,942] {logging_mixin.py:115} INFO - [2023-08-13 13:28:22,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:23,116] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:23,124] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:23,153] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:23,290] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:23,301] {logging_mixin.py:115} INFO - [2023-08-13 13:28:23,301] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:23,331] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.401 seconds
[2023-08-13 13:28:23,977] {processor.py:153} INFO - Started process (PID=810) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:23,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:23,980] {logging_mixin.py:115} INFO - [2023-08-13 13:28:23,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:24,091] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:24,098] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:24,123] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:24,257] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:24,268] {logging_mixin.py:115} INFO - [2023-08-13 13:28:24,268] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:24,299] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 13:28:24,658] {processor.py:153} INFO - Started process (PID=815) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:24,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:24,661] {logging_mixin.py:115} INFO - [2023-08-13 13:28:24,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:24,763] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:24,770] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:24,793] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:24,925] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:24,935] {logging_mixin.py:115} INFO - [2023-08-13 13:28:24,935] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:24,966] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.312 seconds
[2023-08-13 13:28:25,721] {processor.py:153} INFO - Started process (PID=820) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:25,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:25,724] {logging_mixin.py:115} INFO - [2023-08-13 13:28:25,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:25,902] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:25,910] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:25,935] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:26,062] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:26,072] {logging_mixin.py:115} INFO - [2023-08-13 13:28:26,072] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:26,104] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.391 seconds
[2023-08-13 13:28:26,945] {processor.py:153} INFO - Started process (PID=825) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:26,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:26,947] {logging_mixin.py:115} INFO - [2023-08-13 13:28:26,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:27,067] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:27,074] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:27,098] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:27,238] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:27,247] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:27,255] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:27,293] {logging_mixin.py:115} INFO - [2023-08-13 13:28:27,293] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:27,327] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.387 seconds
[2023-08-13 13:28:27,994] {processor.py:153} INFO - Started process (PID=830) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:27,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:27,997] {logging_mixin.py:115} INFO - [2023-08-13 13:28:27,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:28,111] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:28,119] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:28,142] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:28,271] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:28,307] {logging_mixin.py:115} INFO - [2023-08-13 13:28:28,307] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:28,336] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:28:29,041] {processor.py:153} INFO - Started process (PID=835) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:29,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:29,044] {logging_mixin.py:115} INFO - [2023-08-13 13:28:29,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:29,159] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:29,167] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:29,192] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:29,324] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:29,362] {logging_mixin.py:115} INFO - [2023-08-13 13:28:29,362] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:29,395] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.359 seconds
[2023-08-13 13:28:30,414] {processor.py:153} INFO - Started process (PID=840) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:30,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:30,416] {logging_mixin.py:115} INFO - [2023-08-13 13:28:30,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:30,534] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:30,545] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:30,571] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:30,703] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:30,710] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:30,718] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:30,752] {logging_mixin.py:115} INFO - [2023-08-13 13:28:30,752] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:30,783] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.374 seconds
[2023-08-13 13:28:30,948] {processor.py:153} INFO - Started process (PID=845) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:30,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:30,951] {logging_mixin.py:115} INFO - [2023-08-13 13:28:30,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:31,064] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:31,072] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:31,095] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:31,234] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:31,271] {logging_mixin.py:115} INFO - [2023-08-13 13:28:31,271] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:31,301] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 13:28:32,004] {processor.py:153} INFO - Started process (PID=850) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:32,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:32,007] {logging_mixin.py:115} INFO - [2023-08-13 13:28:32,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:32,120] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:32,127] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:32,150] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:32,283] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:23:56.682019+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:32,318] {logging_mixin.py:115} INFO - [2023-08-13 13:28:32,318] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:32,346] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:28:33,067] {processor.py:153} INFO - Started process (PID=855) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:33,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:28:33,070] {logging_mixin.py:115} INFO - [2023-08-13 13:28:33,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:33,187] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:28:33,194] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:28:33,221] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:28:33,357] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:28:33,393] {logging_mixin.py:115} INFO - [2023-08-13 13:28:33,393] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:28:33,454] {logging_mixin.py:115} INFO - [2023-08-13 13:28:33,453] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:28:33,469] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.408 seconds
[2023-08-13 13:29:03,573] {processor.py:153} INFO - Started process (PID=860) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:29:03,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:29:03,576] {logging_mixin.py:115} INFO - [2023-08-13 13:29:03,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:29:03,700] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:29:03,737] {logging_mixin.py:115} INFO - [2023-08-13 13:29:03,736] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:29:03,885] {logging_mixin.py:115} INFO - [2023-08-13 13:29:03,884] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:29:03,900] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.332 seconds
[2023-08-13 13:29:33,992] {processor.py:153} INFO - Started process (PID=865) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:29:33,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:29:33,995] {logging_mixin.py:115} INFO - [2023-08-13 13:29:33,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:29:34,105] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:29:34,137] {logging_mixin.py:115} INFO - [2023-08-13 13:29:34,137] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:29:34,275] {logging_mixin.py:115} INFO - [2023-08-13 13:29:34,275] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:29:34,291] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.304 seconds
[2023-08-13 13:30:04,370] {processor.py:153} INFO - Started process (PID=870) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:30:04,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:30:04,373] {logging_mixin.py:115} INFO - [2023-08-13 13:30:04,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:30:04,506] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:30:04,547] {logging_mixin.py:115} INFO - [2023-08-13 13:30:04,547] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:30:04,698] {logging_mixin.py:115} INFO - [2023-08-13 13:30:04,698] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:30:04,712] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:30:34,811] {processor.py:153} INFO - Started process (PID=875) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:30:34,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:30:34,814] {logging_mixin.py:115} INFO - [2023-08-13 13:30:34,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:30:34,929] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:30:34,962] {logging_mixin.py:115} INFO - [2023-08-13 13:30:34,962] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:30:35,107] {logging_mixin.py:115} INFO - [2023-08-13 13:30:35,107] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:30:35,119] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.313 seconds
[2023-08-13 13:31:05,202] {processor.py:153} INFO - Started process (PID=880) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:05,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:05,204] {logging_mixin.py:115} INFO - [2023-08-13 13:31:05,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:05,326] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:05,363] {logging_mixin.py:115} INFO - [2023-08-13 13:31:05,363] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:05,510] {logging_mixin.py:115} INFO - [2023-08-13 13:31:05,510] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:31:05,525] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:31:35,610] {processor.py:153} INFO - Started process (PID=885) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:35,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:35,617] {logging_mixin.py:115} INFO - [2023-08-13 13:31:35,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:35,837] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:35,875] {logging_mixin.py:115} INFO - [2023-08-13 13:31:35,875] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:36,033] {logging_mixin.py:115} INFO - [2023-08-13 13:31:36,033] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:31:36,047] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.445 seconds
[2023-08-13 13:31:40,968] {processor.py:153} INFO - Started process (PID=890) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:40,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:40,972] {logging_mixin.py:115} INFO - [2023-08-13 13:31:40,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:41,155] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:41,164] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:41,317] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:41,329] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:41,380] {logging_mixin.py:115} INFO - [2023-08-13 13:31:41,380] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:41,424] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.462 seconds
[2023-08-13 13:31:42,149] {processor.py:153} INFO - Started process (PID=897) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:42,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:42,152] {logging_mixin.py:115} INFO - [2023-08-13 13:31:42,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:42,258] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:42,265] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:42,418] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:42,431] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:42,439] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:42,448] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:42,478] {logging_mixin.py:115} INFO - [2023-08-13 13:31:42,478] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:42,505] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.360 seconds
[2023-08-13 13:31:42,857] {processor.py:153} INFO - Started process (PID=902) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:42,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:42,860] {logging_mixin.py:115} INFO - [2023-08-13 13:31:42,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:42,994] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:43,003] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:43,159] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:43,172] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:43,213] {logging_mixin.py:115} INFO - [2023-08-13 13:31:43,213] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:43,254] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.402 seconds
[2023-08-13 13:31:43,993] {processor.py:153} INFO - Started process (PID=911) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:43,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:43,996] {logging_mixin.py:115} INFO - [2023-08-13 13:31:43,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:44,114] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:44,123] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:44,274] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:44,286] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:44,293] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:44,302] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:44,382] {logging_mixin.py:115} INFO - [2023-08-13 13:31:44,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:44,427] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.439 seconds
[2023-08-13 13:31:44,848] {processor.py:153} INFO - Started process (PID=916) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:44,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:44,851] {logging_mixin.py:115} INFO - [2023-08-13 13:31:44,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:45,000] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:45,008] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:45,182] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:45,215] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:45,271] {logging_mixin.py:115} INFO - [2023-08-13 13:31:45,270] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:45,315] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.473 seconds
[2023-08-13 13:31:45,444] {processor.py:153} INFO - Started process (PID=922) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:45,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:45,449] {logging_mixin.py:115} INFO - [2023-08-13 13:31:45,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:45,604] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:45,615] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:45,845] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:45,862] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:45,871] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:45,882] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:45,953] {logging_mixin.py:115} INFO - [2023-08-13 13:31:45,953] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:45,994] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.557 seconds
[2023-08-13 13:31:46,554] {processor.py:153} INFO - Started process (PID=928) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:46,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:46,559] {logging_mixin.py:115} INFO - [2023-08-13 13:31:46,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:46,704] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:46,716] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:46,909] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:46,931] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:46,980] {logging_mixin.py:115} INFO - [2023-08-13 13:31:46,980] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:47,036] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.489 seconds
[2023-08-13 13:31:47,630] {processor.py:153} INFO - Started process (PID=933) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:47,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:47,633] {logging_mixin.py:115} INFO - [2023-08-13 13:31:47,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:47,761] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:47,768] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:47,943] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:47,973] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:48,042] {logging_mixin.py:115} INFO - [2023-08-13 13:31:48,042] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:48,089] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.466 seconds
[2023-08-13 13:31:49,038] {processor.py:153} INFO - Started process (PID=940) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:49,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:49,042] {logging_mixin.py:115} INFO - [2023-08-13 13:31:49,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:49,201] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:49,210] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:49,359] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:49,373] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:49,384] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:49,393] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:49,398] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:49,406] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:49,440] {logging_mixin.py:115} INFO - [2023-08-13 13:31:49,440] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:49,490] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.460 seconds
[2023-08-13 13:31:50,101] {processor.py:153} INFO - Started process (PID=945) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:50,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:50,105] {logging_mixin.py:115} INFO - [2023-08-13 13:31:50,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:50,245] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:50,251] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:50,402] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:50,414] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:50,460] {logging_mixin.py:115} INFO - [2023-08-13 13:31:50,460] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:50,496] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.402 seconds
[2023-08-13 13:31:51,146] {processor.py:153} INFO - Started process (PID=950) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:51,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:51,149] {logging_mixin.py:115} INFO - [2023-08-13 13:31:51,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:51,247] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:51,252] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:51,387] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:51,404] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:51,456] {logging_mixin.py:115} INFO - [2023-08-13 13:31:51,456] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:51,485] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.344 seconds
[2023-08-13 13:31:52,196] {processor.py:153} INFO - Started process (PID=955) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:52,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:52,199] {logging_mixin.py:115} INFO - [2023-08-13 13:31:52,199] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:52,298] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:52,306] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:52,439] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:52,451] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:52,484] {logging_mixin.py:115} INFO - [2023-08-13 13:31:52,484] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:52,510] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 13:31:53,048] {processor.py:153} INFO - Started process (PID=960) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:53,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:53,061] {logging_mixin.py:115} INFO - [2023-08-13 13:31:53,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:53,204] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:53,211] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:53,346] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:53,358] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:53,391] {logging_mixin.py:115} INFO - [2023-08-13 13:31:53,391] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:53,416] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.373 seconds
[2023-08-13 13:31:54,153] {processor.py:153} INFO - Started process (PID=965) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:54,155] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:54,156] {logging_mixin.py:115} INFO - [2023-08-13 13:31:54,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:54,257] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:54,264] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:54,394] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:54,406] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:54,447] {logging_mixin.py:115} INFO - [2023-08-13 13:31:54,447] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:54,472] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.324 seconds
[2023-08-13 13:31:55,199] {processor.py:153} INFO - Started process (PID=970) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:55,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:55,202] {logging_mixin.py:115} INFO - [2023-08-13 13:31:55,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:55,301] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:55,307] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:55,443] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:55,456] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:55,494] {logging_mixin.py:115} INFO - [2023-08-13 13:31:55,494] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:55,531] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:31:56,535] {processor.py:153} INFO - Started process (PID=975) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:56,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:56,538] {logging_mixin.py:115} INFO - [2023-08-13 13:31:56,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:56,648] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:56,656] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:56,794] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:56,806] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:56,812] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:56,820] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:56,851] {logging_mixin.py:115} INFO - [2023-08-13 13:31:56,851] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:56,879] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 13:31:57,582] {processor.py:153} INFO - Started process (PID=980) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:57,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:57,584] {logging_mixin.py:115} INFO - [2023-08-13 13:31:57,584] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:57,698] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:57,706] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:57,839] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:57,851] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:57,885] {logging_mixin.py:115} INFO - [2023-08-13 13:31:57,885] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:57,911] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:31:58,129] {processor.py:153} INFO - Started process (PID=985) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:58,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:58,131] {logging_mixin.py:115} INFO - [2023-08-13 13:31:58,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:58,238] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:58,244] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:58,395] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:58,408] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:58,446] {logging_mixin.py:115} INFO - [2023-08-13 13:31:58,446] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:58,472] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.348 seconds
[2023-08-13 13:31:59,184] {processor.py:153} INFO - Started process (PID=990) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:59,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:59,187] {logging_mixin.py:115} INFO - [2023-08-13 13:31:59,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:59,284] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:59,290] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:31:59,422] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:31:59,436] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:31:59,473] {logging_mixin.py:115} INFO - [2023-08-13 13:31:59,473] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:31:59,500] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 13:31:59,897] {processor.py:153} INFO - Started process (PID=995) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:31:59,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:31:59,900] {logging_mixin.py:115} INFO - [2023-08-13 13:31:59,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:00,003] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:00,010] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:00,142] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:00,155] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:00,189] {logging_mixin.py:115} INFO - [2023-08-13 13:32:00,189] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:00,217] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.324 seconds
[2023-08-13 13:32:00,949] {processor.py:153} INFO - Started process (PID=1000) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:00,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:00,952] {logging_mixin.py:115} INFO - [2023-08-13 13:32:00,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:01,052] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:01,059] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:01,190] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:01,203] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:01,237] {logging_mixin.py:115} INFO - [2023-08-13 13:32:01,237] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:01,263] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.319 seconds
[2023-08-13 13:32:02,034] {processor.py:153} INFO - Started process (PID=1005) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:02,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:02,037] {logging_mixin.py:115} INFO - [2023-08-13 13:32:02,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:02,144] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:02,151] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:02,283] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:02,294] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:02,328] {logging_mixin.py:115} INFO - [2023-08-13 13:32:02,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:02,355] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 13:32:03,082] {processor.py:153} INFO - Started process (PID=1010) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:03,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:03,084] {logging_mixin.py:115} INFO - [2023-08-13 13:32:03,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:03,192] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:03,198] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:03,329] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:03,340] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:03,376] {logging_mixin.py:115} INFO - [2023-08-13 13:32:03,375] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:03,406] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:32:04,233] {processor.py:153} INFO - Started process (PID=1015) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:04,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:04,235] {logging_mixin.py:115} INFO - [2023-08-13 13:32:04,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:04,334] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:04,340] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:04,467] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:04,479] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:04,488] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:04,495] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:04,526] {logging_mixin.py:115} INFO - [2023-08-13 13:32:04,526] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:04,552] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:32:05,281] {processor.py:153} INFO - Started process (PID=1020) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:05,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:05,284] {logging_mixin.py:115} INFO - [2023-08-13 13:32:05,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:05,397] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:05,405] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:05,541] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:05,554] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:05,590] {logging_mixin.py:115} INFO - [2023-08-13 13:32:05,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:05,619] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 13:32:06,584] {processor.py:153} INFO - Started process (PID=1025) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:06,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:06,587] {logging_mixin.py:115} INFO - [2023-08-13 13:32:06,587] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:06,693] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:06,700] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:06,838] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:06,850] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:06,857] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:06,864] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:06,894] {logging_mixin.py:115} INFO - [2023-08-13 13:32:06,894] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:06,920] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.340 seconds
[2023-08-13 13:32:07,629] {processor.py:153} INFO - Started process (PID=1030) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:07,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:07,631] {logging_mixin.py:115} INFO - [2023-08-13 13:32:07,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:07,735] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:07,742] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:07,880] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:07,892] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:07,928] {logging_mixin.py:115} INFO - [2023-08-13 13:32:07,928] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:07,960] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 13:32:08,241] {processor.py:153} INFO - Started process (PID=1035) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:08,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:08,244] {logging_mixin.py:115} INFO - [2023-08-13 13:32:08,244] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:08,349] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:08,356] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:08,482] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:08,493] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:08,533] {logging_mixin.py:115} INFO - [2023-08-13 13:32:08,533] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:08,559] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.322 seconds
[2023-08-13 13:32:09,301] {processor.py:153} INFO - Started process (PID=1040) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:09,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:09,304] {logging_mixin.py:115} INFO - [2023-08-13 13:32:09,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:09,402] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:09,408] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:09,538] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:09,549] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:09,583] {logging_mixin.py:115} INFO - [2023-08-13 13:32:09,583] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:09,610] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 13:32:10,357] {processor.py:153} INFO - Started process (PID=1045) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:10,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:10,360] {logging_mixin.py:115} INFO - [2023-08-13 13:32:10,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:10,468] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:10,477] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:10,615] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:10,626] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:10,659] {logging_mixin.py:115} INFO - [2023-08-13 13:32:10,659] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:10,685] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:32:11,413] {processor.py:153} INFO - Started process (PID=1050) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:11,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:11,416] {logging_mixin.py:115} INFO - [2023-08-13 13:32:11,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:11,522] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:11,529] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:11,668] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:11,681] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:11,715] {logging_mixin.py:115} INFO - [2023-08-13 13:32:11,715] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:11,744] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 13:32:12,464] {processor.py:153} INFO - Started process (PID=1055) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:12,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:12,466] {logging_mixin.py:115} INFO - [2023-08-13 13:32:12,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:12,566] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:12,572] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:12,699] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:12,710] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:12,743] {logging_mixin.py:115} INFO - [2023-08-13 13:32:12,743] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:12,770] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.311 seconds
[2023-08-13 13:32:13,289] {processor.py:153} INFO - Started process (PID=1060) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:13,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:13,291] {logging_mixin.py:115} INFO - [2023-08-13 13:32:13,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:13,385] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:13,391] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:13,523] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:13,535] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:13,568] {logging_mixin.py:115} INFO - [2023-08-13 13:32:13,568] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:13,594] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.309 seconds
[2023-08-13 13:32:14,344] {processor.py:153} INFO - Started process (PID=1065) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:14,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:14,347] {logging_mixin.py:115} INFO - [2023-08-13 13:32:14,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:14,458] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:14,465] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:14,605] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:14,617] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:14,653] {logging_mixin.py:115} INFO - [2023-08-13 13:32:14,653] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:14,686] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:32:14,940] {processor.py:153} INFO - Started process (PID=1070) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:14,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:14,942] {logging_mixin.py:115} INFO - [2023-08-13 13:32:14,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:15,058] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:15,065] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:15,206] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:15,218] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:15,252] {logging_mixin.py:115} INFO - [2023-08-13 13:32:15,252] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:15,280] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:32:15,588] {processor.py:153} INFO - Started process (PID=1075) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:15,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:15,591] {logging_mixin.py:115} INFO - [2023-08-13 13:32:15,591] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:15,708] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:15,716] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:15,858] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:15,871] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:15,913] {logging_mixin.py:115} INFO - [2023-08-13 13:32:15,913] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:15,942] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.358 seconds
[2023-08-13 13:32:16,637] {processor.py:153} INFO - Started process (PID=1080) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:16,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:16,640] {logging_mixin.py:115} INFO - [2023-08-13 13:32:16,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:16,752] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:16,759] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:16,909] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:16,921] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:16,955] {logging_mixin.py:115} INFO - [2023-08-13 13:32:16,955] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:16,980] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:32:17,687] {processor.py:153} INFO - Started process (PID=1085) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:17,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:17,689] {logging_mixin.py:115} INFO - [2023-08-13 13:32:17,689] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:17,798] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:17,804] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:17,941] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:17,953] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:17,988] {logging_mixin.py:115} INFO - [2023-08-13 13:32:17,988] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:18,015] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:32:18,356] {processor.py:153} INFO - Started process (PID=1090) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:18,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:18,360] {logging_mixin.py:115} INFO - [2023-08-13 13:32:18,359] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:18,492] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:18,500] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:18,638] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:18,652] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:18,695] {logging_mixin.py:115} INFO - [2023-08-13 13:32:18,695] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:18,726] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.375 seconds
[2023-08-13 13:32:19,416] {processor.py:153} INFO - Started process (PID=1095) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:19,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:19,418] {logging_mixin.py:115} INFO - [2023-08-13 13:32:19,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:19,527] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:19,534] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:19,666] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:19,681] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:19,715] {logging_mixin.py:115} INFO - [2023-08-13 13:32:19,715] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:19,740] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:32:20,461] {processor.py:153} INFO - Started process (PID=1100) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:20,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:20,464] {logging_mixin.py:115} INFO - [2023-08-13 13:32:20,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:20,580] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:20,587] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:20,729] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:20,741] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:20,781] {logging_mixin.py:115} INFO - [2023-08-13 13:32:20,781] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:20,808] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 13:32:21,507] {processor.py:153} INFO - Started process (PID=1105) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:21,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:21,509] {logging_mixin.py:115} INFO - [2023-08-13 13:32:21,509] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:21,636] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:21,645] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:21,780] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:21,792] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:21,825] {logging_mixin.py:115} INFO - [2023-08-13 13:32:21,825] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:21,851] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 13:32:22,552] {processor.py:153} INFO - Started process (PID=1110) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:22,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:22,554] {logging_mixin.py:115} INFO - [2023-08-13 13:32:22,554] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:22,665] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:22,672] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:22,809] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:22,822] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:22,857] {logging_mixin.py:115} INFO - [2023-08-13 13:32:22,857] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:22,885] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:32:23,416] {processor.py:153} INFO - Started process (PID=1115) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:23,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:23,422] {logging_mixin.py:115} INFO - [2023-08-13 13:32:23,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:23,530] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:23,537] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:23,674] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:23,686] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:23,727] {logging_mixin.py:115} INFO - [2023-08-13 13:32:23,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:23,754] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.342 seconds
[2023-08-13 13:32:24,475] {processor.py:153} INFO - Started process (PID=1120) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:24,477] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:24,478] {logging_mixin.py:115} INFO - [2023-08-13 13:32:24,478] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:24,581] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:24,588] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:24,727] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:24,738] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:24,774] {logging_mixin.py:115} INFO - [2023-08-13 13:32:24,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:24,849] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.379 seconds
[2023-08-13 13:32:25,523] {processor.py:153} INFO - Started process (PID=1125) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:25,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:25,526] {logging_mixin.py:115} INFO - [2023-08-13 13:32:25,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:25,639] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:25,645] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:25,786] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:25,798] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:25,835] {logging_mixin.py:115} INFO - [2023-08-13 13:32:25,835] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:25,863] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:32:26,718] {processor.py:153} INFO - Started process (PID=1130) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:26,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:26,721] {logging_mixin.py:115} INFO - [2023-08-13 13:32:26,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:26,828] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:26,835] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:26,968] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:26,981] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:26,988] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:26,995] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:27,026] {logging_mixin.py:115} INFO - [2023-08-13 13:32:27,025] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:27,051] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 13:32:27,766] {processor.py:153} INFO - Started process (PID=1135) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:27,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:27,768] {logging_mixin.py:115} INFO - [2023-08-13 13:32:27,768] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:27,871] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:27,878] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:28,010] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:28,022] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:28,057] {logging_mixin.py:115} INFO - [2023-08-13 13:32:28,056] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:28,086] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.324 seconds
[2023-08-13 13:32:28,459] {processor.py:153} INFO - Started process (PID=1140) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:28,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:28,461] {logging_mixin.py:115} INFO - [2023-08-13 13:32:28,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:28,568] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:28,575] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:28,714] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:28,727] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:28,762] {logging_mixin.py:115} INFO - [2023-08-13 13:32:28,761] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:28,787] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:32:29,514] {processor.py:153} INFO - Started process (PID=1145) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:29,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:29,517] {logging_mixin.py:115} INFO - [2023-08-13 13:32:29,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:29,614] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:29,620] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:29,753] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:29,765] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:29,800] {logging_mixin.py:115} INFO - [2023-08-13 13:32:29,800] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:29,826] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.316 seconds
[2023-08-13 13:32:29,972] {processor.py:153} INFO - Started process (PID=1150) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:29,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:29,975] {logging_mixin.py:115} INFO - [2023-08-13 13:32:29,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:30,072] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:30,079] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:30,212] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:30,224] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:30,258] {logging_mixin.py:115} INFO - [2023-08-13 13:32:30,258] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:30,287] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.319 seconds
[2023-08-13 13:32:31,017] {processor.py:153} INFO - Started process (PID=1155) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:31,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:31,020] {logging_mixin.py:115} INFO - [2023-08-13 13:32:31,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:31,144] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:31,151] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:31,289] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:31,301] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:31,338] {logging_mixin.py:115} INFO - [2023-08-13 13:32:31,337] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:31,375] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.363 seconds
[2023-08-13 13:32:32,063] {processor.py:153} INFO - Started process (PID=1160) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:32,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:32,065] {logging_mixin.py:115} INFO - [2023-08-13 13:32:32,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:32,178] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:32,185] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:32,318] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:32,331] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:32,366] {logging_mixin.py:115} INFO - [2023-08-13 13:32:32,366] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:32,393] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.334 seconds
[2023-08-13 13:32:33,111] {processor.py:153} INFO - Started process (PID=1165) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:33,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:33,114] {logging_mixin.py:115} INFO - [2023-08-13 13:32:33,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:33,215] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:33,221] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:33,351] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:33,364] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:33,398] {logging_mixin.py:115} INFO - [2023-08-13 13:32:33,398] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:33,426] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.319 seconds
[2023-08-13 13:32:33,515] {processor.py:153} INFO - Started process (PID=1170) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:33,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:33,518] {logging_mixin.py:115} INFO - [2023-08-13 13:32:33,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:33,628] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:33,635] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:33,777] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:33,788] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:33,824] {logging_mixin.py:115} INFO - [2023-08-13 13:32:33,824] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:33,855] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:32:34,560] {processor.py:153} INFO - Started process (PID=1175) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:34,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:34,562] {logging_mixin.py:115} INFO - [2023-08-13 13:32:34,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:34,660] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:34,666] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:34,801] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:34,814] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:34,849] {logging_mixin.py:115} INFO - [2023-08-13 13:32:34,849] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:34,876] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:32:35,608] {processor.py:153} INFO - Started process (PID=1180) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:35,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:35,611] {logging_mixin.py:115} INFO - [2023-08-13 13:32:35,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:35,719] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:35,727] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:35,866] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:35,878] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:35,920] {logging_mixin.py:115} INFO - [2023-08-13 13:32:35,920] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:35,945] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:32:36,717] {processor.py:153} INFO - Started process (PID=1185) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:36,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:36,721] {logging_mixin.py:115} INFO - [2023-08-13 13:32:36,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:36,832] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:36,839] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:36,976] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:36,988] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:36,995] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:37,003] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:37,034] {logging_mixin.py:115} INFO - [2023-08-13 13:32:37,034] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:37,060] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:32:37,770] {processor.py:153} INFO - Started process (PID=1190) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:37,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:37,773] {logging_mixin.py:115} INFO - [2023-08-13 13:32:37,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:37,878] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:37,885] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:38,017] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:38,029] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:38,063] {logging_mixin.py:115} INFO - [2023-08-13 13:32:38,063] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:38,089] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.324 seconds
[2023-08-13 13:32:38,566] {processor.py:153} INFO - Started process (PID=1195) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:38,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:38,568] {logging_mixin.py:115} INFO - [2023-08-13 13:32:38,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:38,667] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:38,673] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:38,802] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:38,816] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:38,853] {logging_mixin.py:115} INFO - [2023-08-13 13:32:38,853] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:38,880] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.318 seconds
[2023-08-13 13:32:39,624] {processor.py:153} INFO - Started process (PID=1200) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:39,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:39,627] {logging_mixin.py:115} INFO - [2023-08-13 13:32:39,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:39,726] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:39,733] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:39,865] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:39,878] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:39,915] {logging_mixin.py:115} INFO - [2023-08-13 13:32:39,915] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:39,941] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:32:40,677] {processor.py:153} INFO - Started process (PID=1205) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:40,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:40,680] {logging_mixin.py:115} INFO - [2023-08-13 13:32:40,680] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:40,786] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:40,793] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:40,928] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:40,939] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:40,975] {logging_mixin.py:115} INFO - [2023-08-13 13:32:40,975] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:41,002] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:32:41,726] {processor.py:153} INFO - Started process (PID=1210) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:41,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:41,730] {logging_mixin.py:115} INFO - [2023-08-13 13:32:41,730] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:41,839] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:41,848] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:41,989] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:42,005] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:42,042] {logging_mixin.py:115} INFO - [2023-08-13 13:32:42,042] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:42,070] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 13:32:42,775] {processor.py:153} INFO - Started process (PID=1215) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:42,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:42,777] {logging_mixin.py:115} INFO - [2023-08-13 13:32:42,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:42,877] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:42,884] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:43,013] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:43,025] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:43,063] {logging_mixin.py:115} INFO - [2023-08-13 13:32:43,063] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:43,092] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:32:43,628] {processor.py:153} INFO - Started process (PID=1220) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:43,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:43,631] {logging_mixin.py:115} INFO - [2023-08-13 13:32:43,630] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:43,730] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:43,736] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:43,875] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:43,889] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:43,923] {logging_mixin.py:115} INFO - [2023-08-13 13:32:43,923] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:43,951] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 13:32:44,686] {processor.py:153} INFO - Started process (PID=1225) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:44,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:44,688] {logging_mixin.py:115} INFO - [2023-08-13 13:32:44,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:44,792] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:44,798] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:44,929] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:44,962] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:44,996] {logging_mixin.py:115} INFO - [2023-08-13 13:32:44,996] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:45,020] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 13:32:45,716] {processor.py:153} INFO - Started process (PID=1230) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:45,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:45,719] {logging_mixin.py:115} INFO - [2023-08-13 13:32:45,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:45,830] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:45,837] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:45,973] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:45,985] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:45,991] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:45,999] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:46,028] {logging_mixin.py:115} INFO - [2023-08-13 13:32:46,028] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:46,053] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.341 seconds
[2023-08-13 13:32:46,774] {processor.py:153} INFO - Started process (PID=1235) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:46,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:46,776] {logging_mixin.py:115} INFO - [2023-08-13 13:32:46,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:46,886] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:46,894] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:47,031] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:47,043] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:47,078] {logging_mixin.py:115} INFO - [2023-08-13 13:32:47,078] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:47,105] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 13:32:47,827] {processor.py:153} INFO - Started process (PID=1240) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:47,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:47,830] {logging_mixin.py:115} INFO - [2023-08-13 13:32:47,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:47,937] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:47,944] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:48,074] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:48,086] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:48,121] {logging_mixin.py:115} INFO - [2023-08-13 13:32:48,121] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:48,151] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:32:48,679] {processor.py:153} INFO - Started process (PID=1245) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:48,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:48,681] {logging_mixin.py:115} INFO - [2023-08-13 13:32:48,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:48,774] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:48,780] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:48,915] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:48,926] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:48,961] {logging_mixin.py:115} INFO - [2023-08-13 13:32:48,961] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:48,995] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 13:32:49,743] {processor.py:153} INFO - Started process (PID=1250) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:49,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:49,745] {logging_mixin.py:115} INFO - [2023-08-13 13:32:49,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:49,848] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:49,855] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:49,987] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:50,000] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:50,035] {logging_mixin.py:115} INFO - [2023-08-13 13:32:50,035] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:50,062] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.323 seconds
[2023-08-13 13:32:50,796] {processor.py:153} INFO - Started process (PID=1255) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:50,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:50,799] {logging_mixin.py:115} INFO - [2023-08-13 13:32:50,799] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:50,915] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:50,921] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:51,060] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:51,072] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:51,107] {logging_mixin.py:115} INFO - [2023-08-13 13:32:51,106] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:51,135] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:32:51,852] {processor.py:153} INFO - Started process (PID=1260) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:51,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:51,854] {logging_mixin.py:115} INFO - [2023-08-13 13:32:51,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:51,960] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:51,966] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:52,094] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:52,106] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:52,143] {logging_mixin.py:115} INFO - [2023-08-13 13:32:52,142] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:52,170] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.324 seconds
[2023-08-13 13:32:52,893] {processor.py:153} INFO - Started process (PID=1265) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:52,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:52,895] {logging_mixin.py:115} INFO - [2023-08-13 13:32:52,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:52,994] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:53,000] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:53,134] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:53,147] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:53,183] {logging_mixin.py:115} INFO - [2023-08-13 13:32:53,183] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:53,209] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:32:53,742] {processor.py:153} INFO - Started process (PID=1270) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:53,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:53,745] {logging_mixin.py:115} INFO - [2023-08-13 13:32:53,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:53,853] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:53,860] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:54,003] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:54,015] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:54,051] {logging_mixin.py:115} INFO - [2023-08-13 13:32:54,051] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:54,078] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.340 seconds
[2023-08-13 13:32:54,791] {processor.py:153} INFO - Started process (PID=1275) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:54,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:54,796] {logging_mixin.py:115} INFO - [2023-08-13 13:32:54,796] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:54,915] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:54,934] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:55,065] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:55,077] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:55,112] {logging_mixin.py:115} INFO - [2023-08-13 13:32:55,112] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:55,140] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 13:32:55,773] {processor.py:153} INFO - Started process (PID=1280) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:55,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:55,775] {logging_mixin.py:115} INFO - [2023-08-13 13:32:55,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:55,893] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:55,900] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:56,032] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:56,045] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:56,080] {logging_mixin.py:115} INFO - [2023-08-13 13:32:56,080] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:56,107] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 13:32:56,807] {processor.py:153} INFO - Started process (PID=1285) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:56,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:56,810] {logging_mixin.py:115} INFO - [2023-08-13 13:32:56,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:56,924] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:56,933] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:57,066] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:57,078] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:57,114] {logging_mixin.py:115} INFO - [2023-08-13 13:32:57,113] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:57,140] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.337 seconds
[2023-08-13 13:32:57,860] {processor.py:153} INFO - Started process (PID=1290) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:57,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:57,864] {logging_mixin.py:115} INFO - [2023-08-13 13:32:57,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:57,971] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:57,978] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:58,109] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:58,123] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:58,157] {logging_mixin.py:115} INFO - [2023-08-13 13:32:58,157] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:58,184] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 13:32:58,781] {processor.py:153} INFO - Started process (PID=1295) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:58,782] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:58,783] {logging_mixin.py:115} INFO - [2023-08-13 13:32:58,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:58,890] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:58,897] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:32:59,034] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:32:59,047] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:32:59,082] {logging_mixin.py:115} INFO - [2023-08-13 13:32:59,082] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:32:59,110] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:32:59,835] {processor.py:153} INFO - Started process (PID=1300) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:59,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:32:59,837] {logging_mixin.py:115} INFO - [2023-08-13 13:32:59,837] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:59,945] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:32:59,952] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:00,083] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:00,096] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:00,130] {logging_mixin.py:115} INFO - [2023-08-13 13:33:00,130] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:00,157] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 13:33:01,086] {processor.py:153} INFO - Started process (PID=1305) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:01,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:01,089] {logging_mixin.py:115} INFO - [2023-08-13 13:33:01,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:01,194] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:01,201] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:01,341] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:01,353] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:01,364] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:01,372] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:01,407] {logging_mixin.py:115} INFO - [2023-08-13 13:33:01,407] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:01,439] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.357 seconds
[2023-08-13 13:33:02,137] {processor.py:153} INFO - Started process (PID=1310) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:02,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:02,140] {logging_mixin.py:115} INFO - [2023-08-13 13:33:02,140] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:02,240] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:02,245] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:02,373] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:02,385] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:02,419] {logging_mixin.py:115} INFO - [2023-08-13 13:33:02,419] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:02,446] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.313 seconds
[2023-08-13 13:33:03,190] {processor.py:153} INFO - Started process (PID=1315) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:03,191] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:03,193] {logging_mixin.py:115} INFO - [2023-08-13 13:33:03,192] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:03,297] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:03,304] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:03,433] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:03,446] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:03,480] {logging_mixin.py:115} INFO - [2023-08-13 13:33:03,480] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:03,516] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:33:03,842] {processor.py:153} INFO - Started process (PID=1320) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:03,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:03,844] {logging_mixin.py:115} INFO - [2023-08-13 13:33:03,844] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:03,950] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:03,956] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:04,096] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:04,109] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:04,146] {logging_mixin.py:115} INFO - [2023-08-13 13:33:04,146] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:04,173] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.336 seconds
[2023-08-13 13:33:04,895] {processor.py:153} INFO - Started process (PID=1325) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:04,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:04,897] {logging_mixin.py:115} INFO - [2023-08-13 13:33:04,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:04,997] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:05,004] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:05,137] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:05,149] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:05,183] {logging_mixin.py:115} INFO - [2023-08-13 13:33:05,183] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:05,211] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 13:33:05,807] {processor.py:153} INFO - Started process (PID=1330) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:05,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:05,811] {logging_mixin.py:115} INFO - [2023-08-13 13:33:05,811] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:05,926] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:05,936] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:06,072] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:06,084] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:06,120] {logging_mixin.py:115} INFO - [2023-08-13 13:33:06,120] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:06,149] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.346 seconds
[2023-08-13 13:33:06,867] {processor.py:153} INFO - Started process (PID=1335) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:06,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:06,870] {logging_mixin.py:115} INFO - [2023-08-13 13:33:06,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:06,984] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:06,991] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:07,127] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:07,140] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:07,174] {logging_mixin.py:115} INFO - [2023-08-13 13:33:07,174] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:07,201] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:33:07,915] {processor.py:153} INFO - Started process (PID=1340) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:07,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:07,917] {logging_mixin.py:115} INFO - [2023-08-13 13:33:07,917] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:08,017] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:08,024] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:08,156] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:08,170] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:08,204] {logging_mixin.py:115} INFO - [2023-08-13 13:33:08,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:08,230] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:33:08,897] {processor.py:153} INFO - Started process (PID=1345) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:08,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:08,900] {logging_mixin.py:115} INFO - [2023-08-13 13:33:08,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:09,001] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:09,008] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:09,144] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:09,157] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:09,191] {logging_mixin.py:115} INFO - [2023-08-13 13:33:09,191] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:09,219] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 13:33:09,957] {processor.py:153} INFO - Started process (PID=1350) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:09,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:09,959] {logging_mixin.py:115} INFO - [2023-08-13 13:33:09,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:10,060] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:10,066] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:10,198] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:10,211] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:10,245] {logging_mixin.py:115} INFO - [2023-08-13 13:33:10,245] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:10,272] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.320 seconds
[2023-08-13 13:33:10,997] {processor.py:153} INFO - Started process (PID=1355) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:10,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:11,000] {logging_mixin.py:115} INFO - [2023-08-13 13:33:10,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:11,095] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:11,102] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:11,243] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:11,255] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:11,290] {logging_mixin.py:115} INFO - [2023-08-13 13:33:11,290] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:11,320] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 13:33:12,041] {processor.py:153} INFO - Started process (PID=1360) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:12,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:12,045] {logging_mixin.py:115} INFO - [2023-08-13 13:33:12,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:12,164] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:12,171] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:12,305] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:12,316] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:12,349] {logging_mixin.py:115} INFO - [2023-08-13 13:33:12,349] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:12,375] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 13:33:13,086] {processor.py:153} INFO - Started process (PID=1365) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:13,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:13,089] {logging_mixin.py:115} INFO - [2023-08-13 13:33:13,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:13,193] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:13,200] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:13,335] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:13,347] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:13,382] {logging_mixin.py:115} INFO - [2023-08-13 13:33:13,382] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:13,409] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 13:33:13,957] {processor.py:153} INFO - Started process (PID=1370) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:13,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:13,960] {logging_mixin.py:115} INFO - [2023-08-13 13:33:13,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:14,069] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:14,076] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:14,209] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:14,222] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:14,257] {logging_mixin.py:115} INFO - [2023-08-13 13:33:14,257] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:14,286] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.333 seconds
[2023-08-13 13:33:15,020] {processor.py:153} INFO - Started process (PID=1375) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:15,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:15,023] {logging_mixin.py:115} INFO - [2023-08-13 13:33:15,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:15,134] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:15,143] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:15,274] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:15,286] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:15,323] {logging_mixin.py:115} INFO - [2023-08-13 13:33:15,323] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:15,353] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.338 seconds
[2023-08-13 13:33:15,855] {processor.py:153} INFO - Started process (PID=1380) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:15,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:15,858] {logging_mixin.py:115} INFO - [2023-08-13 13:33:15,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:15,975] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:15,982] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:16,123] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:16,137] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:16,145] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:16,153] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:16,184] {logging_mixin.py:115} INFO - [2023-08-13 13:33:16,184] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:16,211] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.361 seconds
[2023-08-13 13:33:16,909] {processor.py:153} INFO - Started process (PID=1385) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:16,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:16,912] {logging_mixin.py:115} INFO - [2023-08-13 13:33:16,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:17,013] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:17,019] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:17,152] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:17,165] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:17,200] {logging_mixin.py:115} INFO - [2023-08-13 13:33:17,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:17,231] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 13:33:17,957] {processor.py:153} INFO - Started process (PID=1390) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:17,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:17,960] {logging_mixin.py:115} INFO - [2023-08-13 13:33:17,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:18,064] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:18,070] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:18,200] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:18,212] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:18,247] {logging_mixin.py:115} INFO - [2023-08-13 13:33:18,247] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:18,274] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.321 seconds
[2023-08-13 13:33:19,002] {processor.py:153} INFO - Started process (PID=1395) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:19,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:19,005] {logging_mixin.py:115} INFO - [2023-08-13 13:33:19,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:19,109] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:19,117] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:19,254] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:19,269] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:19,304] {logging_mixin.py:115} INFO - [2023-08-13 13:33:19,304] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:19,333] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.335 seconds
[2023-08-13 13:33:20,057] {processor.py:153} INFO - Started process (PID=1400) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:20,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:20,060] {logging_mixin.py:115} INFO - [2023-08-13 13:33:20,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:20,164] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:20,171] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:20,301] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:20,313] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:20,359] {logging_mixin.py:115} INFO - [2023-08-13 13:33:20,359] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:20,399] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.345 seconds
[2023-08-13 13:33:21,106] {processor.py:153} INFO - Started process (PID=1405) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:21,107] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:21,108] {logging_mixin.py:115} INFO - [2023-08-13 13:33:21,108] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:21,212] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:21,219] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:21,353] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:21,364] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:21,406] {logging_mixin.py:115} INFO - [2023-08-13 13:33:21,406] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:21,441] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 13:33:22,153] {processor.py:153} INFO - Started process (PID=1410) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:22,155] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:22,156] {logging_mixin.py:115} INFO - [2023-08-13 13:33:22,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:22,255] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:22,262] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:22,391] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:22,403] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:22,437] {logging_mixin.py:115} INFO - [2023-08-13 13:33:22,436] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:22,464] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.315 seconds
[2023-08-13 13:33:23,200] {processor.py:153} INFO - Started process (PID=1415) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:23,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:23,204] {logging_mixin.py:115} INFO - [2023-08-13 13:33:23,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:23,315] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:23,322] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:23,463] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:23,477] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:23,513] {logging_mixin.py:115} INFO - [2023-08-13 13:33:23,513] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:23,543] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.347 seconds
[2023-08-13 13:33:24,076] {processor.py:153} INFO - Started process (PID=1420) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:24,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:24,080] {logging_mixin.py:115} INFO - [2023-08-13 13:33:24,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:24,225] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:24,236] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:24,443] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:24,455] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:24,494] {logging_mixin.py:115} INFO - [2023-08-13 13:33:24,494] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:24,527] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.456 seconds
[2023-08-13 13:33:25,153] {processor.py:153} INFO - Started process (PID=1425) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:25,155] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:25,156] {logging_mixin.py:115} INFO - [2023-08-13 13:33:25,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:25,289] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:25,298] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:25,455] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:25,475] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:25,513] {logging_mixin.py:115} INFO - [2023-08-13 13:33:25,513] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:25,549] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.402 seconds
[2023-08-13 13:33:25,914] {processor.py:153} INFO - Started process (PID=1430) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:25,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:25,917] {logging_mixin.py:115} INFO - [2023-08-13 13:33:25,917] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:26,051] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:26,058] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:26,215] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:26,228] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:26,266] {logging_mixin.py:115} INFO - [2023-08-13 13:33:26,266] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:26,298] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.390 seconds
[2023-08-13 13:33:27,028] {processor.py:153} INFO - Started process (PID=1435) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:27,030] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:27,033] {logging_mixin.py:115} INFO - [2023-08-13 13:33:27,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:27,205] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:27,214] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:27,388] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:27,410] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:27,575] {logging_mixin.py:115} INFO - [2023-08-13 13:33:27,574] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:27,620] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.600 seconds
[2023-08-13 13:33:28,156] {processor.py:153} INFO - Started process (PID=1440) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:28,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:28,162] {logging_mixin.py:115} INFO - [2023-08-13 13:33:28,161] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:28,346] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:28,357] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:28,546] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:28,561] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:28,600] {logging_mixin.py:115} INFO - [2023-08-13 13:33:28,600] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:28,636] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.490 seconds
[2023-08-13 13:33:29,119] {processor.py:153} INFO - Started process (PID=1445) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:29,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:29,124] {logging_mixin.py:115} INFO - [2023-08-13 13:33:29,124] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:29,248] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:29,255] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:29,402] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:29,414] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:29,452] {logging_mixin.py:115} INFO - [2023-08-13 13:33:29,452] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:29,484] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 13:33:30,201] {processor.py:153} INFO - Started process (PID=1450) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:30,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:30,209] {logging_mixin.py:115} INFO - [2023-08-13 13:33:30,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:30,526] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:30,553] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:30,701] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:30,713] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:30,751] {logging_mixin.py:115} INFO - [2023-08-13 13:33:30,751] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:30,782] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.597 seconds
[2023-08-13 13:33:31,250] {processor.py:153} INFO - Started process (PID=1455) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:31,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:31,253] {logging_mixin.py:115} INFO - [2023-08-13 13:33:31,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:31,371] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:31,384] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:31,558] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:31,571] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:31,609] {logging_mixin.py:115} INFO - [2023-08-13 13:33:31,609] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:31,639] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.394 seconds
[2023-08-13 13:33:32,292] {processor.py:153} INFO - Started process (PID=1460) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:32,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:32,295] {logging_mixin.py:115} INFO - [2023-08-13 13:33:32,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:32,402] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:32,409] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:32,547] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:32,558] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:32,592] {logging_mixin.py:115} INFO - [2023-08-13 13:33:32,592] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:32,618] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.330 seconds
[2023-08-13 13:33:33,343] {processor.py:153} INFO - Started process (PID=1465) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:33,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:33,345] {logging_mixin.py:115} INFO - [2023-08-13 13:33:33,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:33,450] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:33,456] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:33,594] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:33,606] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:33,640] {logging_mixin.py:115} INFO - [2023-08-13 13:33:33,640] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:33,667] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.329 seconds
[2023-08-13 13:33:34,181] {processor.py:153} INFO - Started process (PID=1470) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:34,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:34,184] {logging_mixin.py:115} INFO - [2023-08-13 13:33:34,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:34,290] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:34,296] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:34,426] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:34,439] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:34,474] {logging_mixin.py:115} INFO - [2023-08-13 13:33:34,474] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:34,505] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.328 seconds
[2023-08-13 13:33:35,246] {processor.py:153} INFO - Started process (PID=1475) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:35,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:35,249] {logging_mixin.py:115} INFO - [2023-08-13 13:33:35,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:35,390] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:35,403] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:35,587] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:35,601] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:35,637] {logging_mixin.py:115} INFO - [2023-08-13 13:33:35,637] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:35,666] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.425 seconds
[2023-08-13 13:33:36,017] {processor.py:153} INFO - Started process (PID=1480) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:36,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:36,020] {logging_mixin.py:115} INFO - [2023-08-13 13:33:36,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:36,144] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:36,151] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:36,298] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:36,310] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:36,357] {logging_mixin.py:115} INFO - [2023-08-13 13:33:36,357] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:36,397] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.385 seconds
[2023-08-13 13:33:37,065] {processor.py:153} INFO - Started process (PID=1485) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:37,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:37,068] {logging_mixin.py:115} INFO - [2023-08-13 13:33:37,067] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:37,188] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:37,196] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:37,348] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:37,361] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:37,400] {logging_mixin.py:115} INFO - [2023-08-13 13:33:37,400] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:37,432] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.371 seconds
[2023-08-13 13:33:38,120] {processor.py:153} INFO - Started process (PID=1490) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:38,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:38,143] {logging_mixin.py:115} INFO - [2023-08-13 13:33:38,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:38,283] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:38,292] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:38,441] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:38,461] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:38,507] {logging_mixin.py:115} INFO - [2023-08-13 13:33:38,506] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:38,538] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.423 seconds
[2023-08-13 13:33:39,172] {processor.py:153} INFO - Started process (PID=1495) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:39,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:39,176] {logging_mixin.py:115} INFO - [2023-08-13 13:33:39,176] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:39,305] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:39,313] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:39,459] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:39,471] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:39,508] {logging_mixin.py:115} INFO - [2023-08-13 13:33:39,508] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:39,539] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.372 seconds
[2023-08-13 13:33:40,296] {processor.py:153} INFO - Started process (PID=1500) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:40,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:40,299] {logging_mixin.py:115} INFO - [2023-08-13 13:33:40,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:40,421] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:40,430] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:40,584] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:40,597] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:40,607] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:40,616] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:40,649] {logging_mixin.py:115} INFO - [2023-08-13 13:33:40,649] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:40,681] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.389 seconds
[2023-08-13 13:33:41,354] {processor.py:153} INFO - Started process (PID=1505) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:41,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:41,357] {logging_mixin.py:115} INFO - [2023-08-13 13:33:41,357] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:41,499] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:41,506] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:41,659] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:41,673] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:41,712] {logging_mixin.py:115} INFO - [2023-08-13 13:33:41,712] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:41,741] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.393 seconds
[2023-08-13 13:33:42,396] {processor.py:153} INFO - Started process (PID=1510) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:42,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:42,398] {logging_mixin.py:115} INFO - [2023-08-13 13:33:42,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:42,563] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:42,575] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:42,766] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:42,778] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:42,812] {logging_mixin.py:115} INFO - [2023-08-13 13:33:42,812] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:42,840] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.449 seconds
[2023-08-13 13:33:43,444] {processor.py:153} INFO - Started process (PID=1515) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:43,445] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:43,446] {logging_mixin.py:115} INFO - [2023-08-13 13:33:43,446] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:43,554] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:43,561] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:43,710] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:43,724] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:43,759] {logging_mixin.py:115} INFO - [2023-08-13 13:33:43,759] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:43,788] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.349 seconds
[2023-08-13 13:33:44,293] {processor.py:153} INFO - Started process (PID=1520) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:44,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:44,295] {logging_mixin.py:115} INFO - [2023-08-13 13:33:44,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:44,405] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:44,413] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:44,542] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:44,554] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:44,589] {logging_mixin.py:115} INFO - [2023-08-13 13:33:44,589] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:44,615] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.327 seconds
[2023-08-13 13:33:45,243] {processor.py:153} INFO - Started process (PID=1525) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:45,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:45,246] {logging_mixin.py:115} INFO - [2023-08-13 13:33:45,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:45,348] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:45,355] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:45,487] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:45,499] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:45,536] {logging_mixin.py:115} INFO - [2023-08-13 13:33:45,536] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:45,564] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.326 seconds
[2023-08-13 13:33:46,096] {processor.py:153} INFO - Started process (PID=1530) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:46,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:46,099] {logging_mixin.py:115} INFO - [2023-08-13 13:33:46,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:46,208] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:46,215] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:46,350] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:46,365] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:46,413] {logging_mixin.py:115} INFO - [2023-08-13 13:33:46,413] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:46,445] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.353 seconds
[2023-08-13 13:33:47,121] {processor.py:153} INFO - Started process (PID=1535) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:47,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:47,124] {logging_mixin.py:115} INFO - [2023-08-13 13:33:47,124] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:47,242] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:47,250] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:47,369] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:47,378] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:47,406] {logging_mixin.py:115} INFO - [2023-08-13 13:33:47,406] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:47,430] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.313 seconds
[2023-08-13 13:33:48,164] {processor.py:153} INFO - Started process (PID=1540) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:48,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:48,166] {logging_mixin.py:115} INFO - [2023-08-13 13:33:48,166] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:48,284] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:48,291] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:48,428] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:48,440] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:48,475] {logging_mixin.py:115} INFO - [2023-08-13 13:33:48,475] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:48,502] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.343 seconds
[2023-08-13 13:33:49,207] {processor.py:153} INFO - Started process (PID=1545) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:49,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:49,209] {logging_mixin.py:115} INFO - [2023-08-13 13:33:49,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:49,322] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:49,329] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:49,467] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:49,480] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:26:15.433626+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:49,516] {logging_mixin.py:115} INFO - [2023-08-13 13:33:49,516] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:49,542] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.339 seconds
[2023-08-13 13:33:50,422] {processor.py:153} INFO - Started process (PID=1550) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:50,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:33:50,425] {logging_mixin.py:115} INFO - [2023-08-13 13:33:50,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:50,535] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:33:50,542] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:50,681] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/configuration.py:525 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-08-13 13:33:50,692] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:31:40.657502+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:50,699] {processor.py:370} INFO - Running SLA Checks for submit_pyspark_script_to_emr
[2023-08-13 13:33:50,706] {processor.py:418} INFO - Skipping SLA check for <TaskInstance: submit_pyspark_script_to_emr.execute_pyspark_script_sensor manual__2023-08-13T13:31:40.657502+00:00 [success]> because task does not have scheduled date
[2023-08-13 13:33:50,738] {logging_mixin.py:115} INFO - [2023-08-13 13:33:50,738] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:33:50,754] {logging_mixin.py:115} INFO - [2023-08-13 13:33:50,754] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:33:50,765] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.350 seconds
[2023-08-13 13:34:20,863] {processor.py:153} INFO - Started process (PID=1555) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:34:20,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:34:20,867] {logging_mixin.py:115} INFO - [2023-08-13 13:34:20,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:34:20,968] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:34:20,997] {logging_mixin.py:115} INFO - [2023-08-13 13:34:20,997] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:34:21,130] {logging_mixin.py:115} INFO - [2023-08-13 13:34:21,130] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:34:21,143] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.285 seconds
[2023-08-13 13:34:51,231] {processor.py:153} INFO - Started process (PID=1560) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:34:51,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 13:34:51,234] {logging_mixin.py:115} INFO - [2023-08-13 13:34:51,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:34:51,330] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 13:34:51,364] {logging_mixin.py:115} INFO - [2023-08-13 13:34:51,364] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 13:34:51,509] {logging_mixin.py:115} INFO - [2023-08-13 13:34:51,509] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 13:34:51,524] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.297 seconds
[2023-08-13 15:19:25,969] {processor.py:153} INFO - Started process (PID=1565) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:19:25,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:19:25,973] {logging_mixin.py:115} INFO - [2023-08-13 15:19:25,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:19:26,149] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:19:26,227] {logging_mixin.py:115} INFO - [2023-08-13 15:19:26,227] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:19:26,569] {logging_mixin.py:115} INFO - [2023-08-13 15:19:26,569] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:19:26,668] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.705 seconds
[2023-08-13 15:19:57,808] {processor.py:153} INFO - Started process (PID=1570) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:19:57,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:19:57,841] {logging_mixin.py:115} INFO - [2023-08-13 15:19:57,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:19:58,789] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:19:59,329] {logging_mixin.py:115} INFO - [2023-08-13 15:19:59,328] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:20:00,661] {logging_mixin.py:115} INFO - [2023-08-13 15:20:00,661] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:20:00,755] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 2.983 seconds
[2023-08-13 15:20:31,189] {processor.py:153} INFO - Started process (PID=1575) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:20:31,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:20:31,203] {logging_mixin.py:115} INFO - [2023-08-13 15:20:31,203] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:20:31,975] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:20:32,170] {logging_mixin.py:115} INFO - [2023-08-13 15:20:32,170] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:20:32,759] {logging_mixin.py:115} INFO - [2023-08-13 15:20:32,759] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:20:32,821] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.656 seconds
[2023-08-13 15:36:54,848] {processor.py:153} INFO - Started process (PID=1580) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:36:54,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:36:54,855] {logging_mixin.py:115} INFO - [2023-08-13 15:36:54,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:36:55,200] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:36:55,265] {logging_mixin.py:115} INFO - [2023-08-13 15:36:55,265] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:36:55,498] {logging_mixin.py:115} INFO - [2023-08-13 15:36:55,498] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:36:55,518] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.713 seconds
[2023-08-13 15:37:25,768] {processor.py:153} INFO - Started process (PID=1585) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:37:25,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:37:25,782] {logging_mixin.py:115} INFO - [2023-08-13 15:37:25,782] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:37:26,536] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:37:26,710] {logging_mixin.py:115} INFO - [2023-08-13 15:37:26,709] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:37:27,260] {logging_mixin.py:115} INFO - [2023-08-13 15:37:27,259] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:37:27,312] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.571 seconds
[2023-08-13 15:37:57,578] {processor.py:153} INFO - Started process (PID=1590) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:37:57,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:37:57,600] {logging_mixin.py:115} INFO - [2023-08-13 15:37:57,598] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:37:58,143] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:37:58,303] {logging_mixin.py:115} INFO - [2023-08-13 15:37:58,303] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:37:58,795] {logging_mixin.py:115} INFO - [2023-08-13 15:37:58,795] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:37:58,844] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.296 seconds
[2023-08-13 15:38:29,105] {processor.py:153} INFO - Started process (PID=1595) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:38:29,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:38:29,116] {logging_mixin.py:115} INFO - [2023-08-13 15:38:29,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:38:29,674] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:38:29,923] {logging_mixin.py:115} INFO - [2023-08-13 15:38:29,922] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:38:30,629] {logging_mixin.py:115} INFO - [2023-08-13 15:38:30,629] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:38:30,699] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.613 seconds
[2023-08-13 15:39:01,058] {processor.py:153} INFO - Started process (PID=1600) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:39:01,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:39:01,081] {logging_mixin.py:115} INFO - [2023-08-13 15:39:01,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:39:01,627] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:39:01,784] {logging_mixin.py:115} INFO - [2023-08-13 15:39:01,783] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:39:02,276] {logging_mixin.py:115} INFO - [2023-08-13 15:39:02,275] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:39:02,331] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.306 seconds
[2023-08-13 15:39:32,559] {processor.py:153} INFO - Started process (PID=1605) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:39:32,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:39:32,569] {logging_mixin.py:115} INFO - [2023-08-13 15:39:32,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:39:33,001] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:39:33,175] {logging_mixin.py:115} INFO - [2023-08-13 15:39:33,174] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:39:33,644] {logging_mixin.py:115} INFO - [2023-08-13 15:39:33,643] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:39:33,721] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.177 seconds
[2023-08-13 15:40:03,948] {processor.py:153} INFO - Started process (PID=1610) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:40:03,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:40:03,960] {logging_mixin.py:115} INFO - [2023-08-13 15:40:03,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:40:04,390] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:40:04,542] {logging_mixin.py:115} INFO - [2023-08-13 15:40:04,541] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:40:04,987] {logging_mixin.py:115} INFO - [2023-08-13 15:40:04,986] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:40:05,036] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.104 seconds
[2023-08-13 15:40:35,229] {processor.py:153} INFO - Started process (PID=1615) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:40:35,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:40:35,235] {logging_mixin.py:115} INFO - [2023-08-13 15:40:35,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:40:35,507] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:40:35,613] {logging_mixin.py:115} INFO - [2023-08-13 15:40:35,612] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:40:35,956] {logging_mixin.py:115} INFO - [2023-08-13 15:40:35,955] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:40:35,990] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.772 seconds
[2023-08-13 15:41:06,122] {processor.py:153} INFO - Started process (PID=1620) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:41:06,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:41:06,127] {logging_mixin.py:115} INFO - [2023-08-13 15:41:06,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:41:06,337] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:41:06,403] {logging_mixin.py:115} INFO - [2023-08-13 15:41:06,403] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:41:06,639] {logging_mixin.py:115} INFO - [2023-08-13 15:41:06,638] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:41:06,661] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.547 seconds
[2023-08-13 15:41:36,805] {processor.py:153} INFO - Started process (PID=1625) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:41:36,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:41:36,810] {logging_mixin.py:115} INFO - [2023-08-13 15:41:36,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:41:37,009] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:41:37,071] {logging_mixin.py:115} INFO - [2023-08-13 15:41:37,071] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:41:37,285] {logging_mixin.py:115} INFO - [2023-08-13 15:41:37,285] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:41:37,304] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.507 seconds
[2023-08-13 15:42:07,426] {processor.py:153} INFO - Started process (PID=1630) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:42:07,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:42:07,430] {logging_mixin.py:115} INFO - [2023-08-13 15:42:07,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:42:07,606] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:42:07,668] {logging_mixin.py:115} INFO - [2023-08-13 15:42:07,667] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:42:07,862] {logging_mixin.py:115} INFO - [2023-08-13 15:42:07,862] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:42:07,880] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.461 seconds
[2023-08-13 15:42:38,005] {processor.py:153} INFO - Started process (PID=1635) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:42:38,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:42:38,012] {logging_mixin.py:115} INFO - [2023-08-13 15:42:38,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:42:38,195] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:42:38,252] {logging_mixin.py:115} INFO - [2023-08-13 15:42:38,252] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:42:38,451] {logging_mixin.py:115} INFO - [2023-08-13 15:42:38,450] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:42:38,468] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.472 seconds
[2023-08-13 15:43:08,562] {processor.py:153} INFO - Started process (PID=1640) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:43:08,565] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:43:08,566] {logging_mixin.py:115} INFO - [2023-08-13 15:43:08,566] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:43:08,714] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:43:08,763] {logging_mixin.py:115} INFO - [2023-08-13 15:43:08,763] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:43:08,927] {logging_mixin.py:115} INFO - [2023-08-13 15:43:08,927] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:43:08,943] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.387 seconds
[2023-08-13 15:58:42,943] {processor.py:153} INFO - Started process (PID=1645) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:58:42,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:58:42,953] {logging_mixin.py:115} INFO - [2023-08-13 15:58:42,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:58:43,195] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:58:43,471] {logging_mixin.py:115} INFO - [2023-08-13 15:58:43,471] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:58:43,507] {logging_mixin.py:115} INFO - [2023-08-13 15:58:43,507] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:58:43,522] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.616 seconds
[2023-08-13 15:59:13,728] {processor.py:153} INFO - Started process (PID=1650) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:59:13,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:59:13,740] {logging_mixin.py:115} INFO - [2023-08-13 15:59:13,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:59:14,260] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:59:14,852] {logging_mixin.py:115} INFO - [2023-08-13 15:59:14,852] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:59:14,944] {logging_mixin.py:115} INFO - [2023-08-13 15:59:14,943] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:59:15,008] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.299 seconds
[2023-08-13 15:59:45,289] {processor.py:153} INFO - Started process (PID=1655) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:59:45,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 15:59:45,302] {logging_mixin.py:115} INFO - [2023-08-13 15:59:45,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:59:45,984] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 15:59:46,834] {logging_mixin.py:115} INFO - [2023-08-13 15:59:46,834] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 15:59:46,958] {logging_mixin.py:115} INFO - [2023-08-13 15:59:46,957] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 15:59:47,025] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.760 seconds
[2023-08-13 16:00:17,294] {processor.py:153} INFO - Started process (PID=1660) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:00:17,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:00:17,305] {logging_mixin.py:115} INFO - [2023-08-13 16:00:17,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:00:17,812] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:00:18,392] {logging_mixin.py:115} INFO - [2023-08-13 16:00:18,392] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:00:18,497] {logging_mixin.py:115} INFO - [2023-08-13 16:00:18,497] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:00:18,547] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.273 seconds
[2023-08-13 16:00:48,772] {processor.py:153} INFO - Started process (PID=1665) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:00:48,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:00:48,789] {logging_mixin.py:115} INFO - [2023-08-13 16:00:48,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:00:49,238] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:00:49,710] {logging_mixin.py:115} INFO - [2023-08-13 16:00:49,709] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:00:49,808] {logging_mixin.py:115} INFO - [2023-08-13 16:00:49,807] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:00:49,892] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.137 seconds
[2023-08-13 16:01:20,143] {processor.py:153} INFO - Started process (PID=1670) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:01:20,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:01:20,156] {logging_mixin.py:115} INFO - [2023-08-13 16:01:20,155] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:01:20,633] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:01:21,158] {logging_mixin.py:115} INFO - [2023-08-13 16:01:21,158] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:01:21,250] {logging_mixin.py:115} INFO - [2023-08-13 16:01:21,249] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:01:21,295] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.178 seconds
[2023-08-13 16:01:51,515] {processor.py:153} INFO - Started process (PID=1675) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:01:51,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:01:51,527] {logging_mixin.py:115} INFO - [2023-08-13 16:01:51,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:01:51,896] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:01:52,320] {logging_mixin.py:115} INFO - [2023-08-13 16:01:52,319] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:01:52,396] {logging_mixin.py:115} INFO - [2023-08-13 16:01:52,395] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:01:52,434] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.933 seconds
[2023-08-13 16:02:22,600] {processor.py:153} INFO - Started process (PID=1680) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:02:22,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:02:22,607] {logging_mixin.py:115} INFO - [2023-08-13 16:02:22,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:02:22,890] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:02:23,222] {logging_mixin.py:115} INFO - [2023-08-13 16:02:23,222] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:02:23,273] {logging_mixin.py:115} INFO - [2023-08-13 16:02:23,273] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:02:23,307] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.717 seconds
[2023-08-13 16:02:53,460] {processor.py:153} INFO - Started process (PID=1685) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:02:53,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:02:53,466] {logging_mixin.py:115} INFO - [2023-08-13 16:02:53,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:02:53,689] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:02:53,961] {logging_mixin.py:115} INFO - [2023-08-13 16:02:53,961] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:02:54,003] {logging_mixin.py:115} INFO - [2023-08-13 16:02:54,003] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:02:54,026] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.575 seconds
[2023-08-13 16:03:24,146] {processor.py:153} INFO - Started process (PID=1690) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:03:24,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:03:24,152] {logging_mixin.py:115} INFO - [2023-08-13 16:03:24,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:03:24,343] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:03:24,614] {logging_mixin.py:115} INFO - [2023-08-13 16:03:24,614] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:03:24,654] {logging_mixin.py:115} INFO - [2023-08-13 16:03:24,654] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:03:24,677] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.538 seconds
[2023-08-13 16:20:36,966] {processor.py:153} INFO - Started process (PID=1702) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:20:36,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:20:36,970] {logging_mixin.py:115} INFO - [2023-08-13 16:20:36,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:20:37,177] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:20:37,208] {logging_mixin.py:115} INFO - [2023-08-13 16:20:37,208] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:20:37,253] {logging_mixin.py:115} INFO - [2023-08-13 16:20:37,253] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:20:37,271] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.314 seconds
[2023-08-13 16:21:08,012] {processor.py:153} INFO - Started process (PID=1707) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:21:08,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:21:08,026] {logging_mixin.py:115} INFO - [2023-08-13 16:21:08,025] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:21:08,588] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:21:08,668] {logging_mixin.py:115} INFO - [2023-08-13 16:21:08,668] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:21:08,776] {logging_mixin.py:115} INFO - [2023-08-13 16:21:08,776] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:21:08,832] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.841 seconds
[2023-08-13 16:21:39,093] {processor.py:153} INFO - Started process (PID=1712) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:21:39,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 16:21:39,106] {logging_mixin.py:115} INFO - [2023-08-13 16:21:39,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:21:39,618] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 16:21:39,699] {logging_mixin.py:115} INFO - [2023-08-13 16:21:39,699] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 16:21:39,788] {logging_mixin.py:115} INFO - [2023-08-13 16:21:39,788] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 16:21:39,841] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.768 seconds
[2023-08-13 18:21:23,634] {processor.py:153} INFO - Started process (PID=1718) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:21:23,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:21:23,660] {logging_mixin.py:115} INFO - [2023-08-13 18:21:23,660] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:21:24,760] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:21:24,804] {logging_mixin.py:115} INFO - [2023-08-13 18:21:24,803] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:21:24,841] {logging_mixin.py:115} INFO - [2023-08-13 18:21:24,841] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:21:24,887] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.259 seconds
[2023-08-13 18:21:55,574] {processor.py:153} INFO - Started process (PID=1723) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:21:55,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:21:55,589] {logging_mixin.py:115} INFO - [2023-08-13 18:21:55,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:21:56,456] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:21:56,582] {logging_mixin.py:115} INFO - [2023-08-13 18:21:56,581] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:21:56,727] {logging_mixin.py:115} INFO - [2023-08-13 18:21:56,727] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:21:56,819] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.281 seconds
[2023-08-13 18:22:27,191] {processor.py:153} INFO - Started process (PID=1728) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:22:27,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:22:27,206] {logging_mixin.py:115} INFO - [2023-08-13 18:22:27,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:22:28,027] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:22:28,215] {logging_mixin.py:115} INFO - [2023-08-13 18:22:28,214] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:22:28,367] {logging_mixin.py:115} INFO - [2023-08-13 18:22:28,366] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:22:28,445] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 1.279 seconds
[2023-08-13 18:32:56,834] {processor.py:153} INFO - Started process (PID=1735) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:32:56,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:32:56,841] {logging_mixin.py:115} INFO - [2023-08-13 18:32:56,841] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:32:57,148] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:32:57,200] {logging_mixin.py:115} INFO - [2023-08-13 18:32:57,200] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:32:57,239] {logging_mixin.py:115} INFO - [2023-08-13 18:32:57,239] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:32:57,259] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.433 seconds
[2023-08-13 18:33:27,367] {processor.py:153} INFO - Started process (PID=1740) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:33:27,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:33:27,369] {logging_mixin.py:115} INFO - [2023-08-13 18:33:27,369] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:33:27,485] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:33:27,506] {logging_mixin.py:115} INFO - [2023-08-13 18:33:27,506] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:33:27,532] {logging_mixin.py:115} INFO - [2023-08-13 18:33:27,531] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:33:27,546] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.184 seconds
[2023-08-13 18:33:57,602] {processor.py:153} INFO - Started process (PID=1745) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:33:57,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:33:57,604] {logging_mixin.py:115} INFO - [2023-08-13 18:33:57,604] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:33:57,700] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:33:57,715] {logging_mixin.py:115} INFO - [2023-08-13 18:33:57,715] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:33:57,732] {logging_mixin.py:115} INFO - [2023-08-13 18:33:57,732] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:33:57,745] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.147 seconds
[2023-08-13 18:34:27,803] {processor.py:153} INFO - Started process (PID=1750) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:34:27,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:34:27,806] {logging_mixin.py:115} INFO - [2023-08-13 18:34:27,806] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:34:27,902] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:34:27,917] {logging_mixin.py:115} INFO - [2023-08-13 18:34:27,917] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:34:27,934] {logging_mixin.py:115} INFO - [2023-08-13 18:34:27,934] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:34:27,944] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.145 seconds
[2023-08-13 18:34:58,000] {processor.py:153} INFO - Started process (PID=1755) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:34:58,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:34:58,002] {logging_mixin.py:115} INFO - [2023-08-13 18:34:58,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:34:58,095] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:34:58,110] {logging_mixin.py:115} INFO - [2023-08-13 18:34:58,109] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:34:58,127] {logging_mixin.py:115} INFO - [2023-08-13 18:34:58,127] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:34:58,137] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.142 seconds
[2023-08-13 18:35:28,227] {processor.py:153} INFO - Started process (PID=1760) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:35:28,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:35:28,230] {logging_mixin.py:115} INFO - [2023-08-13 18:35:28,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:35:28,329] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:35:28,344] {logging_mixin.py:115} INFO - [2023-08-13 18:35:28,344] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:35:28,360] {logging_mixin.py:115} INFO - [2023-08-13 18:35:28,360] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:35:28,370] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.147 seconds
[2023-08-13 18:35:58,455] {processor.py:153} INFO - Started process (PID=1765) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:35:58,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:35:58,457] {logging_mixin.py:115} INFO - [2023-08-13 18:35:58,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:35:58,558] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:35:58,572] {logging_mixin.py:115} INFO - [2023-08-13 18:35:58,572] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:35:58,588] {logging_mixin.py:115} INFO - [2023-08-13 18:35:58,588] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:35:58,598] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.148 seconds
[2023-08-13 18:36:28,718] {processor.py:153} INFO - Started process (PID=1770) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:36:28,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:36:28,720] {logging_mixin.py:115} INFO - [2023-08-13 18:36:28,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:36:28,821] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:36:28,836] {logging_mixin.py:115} INFO - [2023-08-13 18:36:28,836] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:36:28,853] {logging_mixin.py:115} INFO - [2023-08-13 18:36:28,853] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:36:28,863] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.150 seconds
[2023-08-13 18:36:58,932] {processor.py:153} INFO - Started process (PID=1775) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:36:58,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:36:58,938] {logging_mixin.py:115} INFO - [2023-08-13 18:36:58,938] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:36:59,042] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:36:59,059] {logging_mixin.py:115} INFO - [2023-08-13 18:36:59,059] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:36:59,079] {logging_mixin.py:115} INFO - [2023-08-13 18:36:59,079] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:36:59,090] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.164 seconds
[2023-08-13 18:37:29,165] {processor.py:153} INFO - Started process (PID=1780) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:37:29,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:37:29,167] {logging_mixin.py:115} INFO - [2023-08-13 18:37:29,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:37:29,267] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:37:29,283] {logging_mixin.py:115} INFO - [2023-08-13 18:37:29,283] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:37:29,300] {logging_mixin.py:115} INFO - [2023-08-13 18:37:29,299] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:37:29,309] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.149 seconds
[2023-08-13 18:37:59,376] {processor.py:153} INFO - Started process (PID=1785) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:37:59,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:37:59,378] {logging_mixin.py:115} INFO - [2023-08-13 18:37:59,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:37:59,479] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:37:59,494] {logging_mixin.py:115} INFO - [2023-08-13 18:37:59,494] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:37:59,511] {logging_mixin.py:115} INFO - [2023-08-13 18:37:59,511] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:37:59,521] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.150 seconds
[2023-08-13 18:38:29,601] {processor.py:153} INFO - Started process (PID=1790) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:38:29,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:38:29,603] {logging_mixin.py:115} INFO - [2023-08-13 18:38:29,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:38:29,708] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:38:29,724] {logging_mixin.py:115} INFO - [2023-08-13 18:38:29,724] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:38:29,740] {logging_mixin.py:115} INFO - [2023-08-13 18:38:29,740] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:38:29,752] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.156 seconds
[2023-08-13 18:38:59,826] {processor.py:153} INFO - Started process (PID=1795) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:38:59,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:38:59,828] {logging_mixin.py:115} INFO - [2023-08-13 18:38:59,828] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:38:59,929] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:38:59,943] {logging_mixin.py:115} INFO - [2023-08-13 18:38:59,943] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:38:59,962] {logging_mixin.py:115} INFO - [2023-08-13 18:38:59,962] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:38:59,972] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.151 seconds
[2023-08-13 18:39:30,063] {processor.py:153} INFO - Started process (PID=1800) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:39:30,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:39:30,065] {logging_mixin.py:115} INFO - [2023-08-13 18:39:30,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:39:30,166] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:39:30,180] {logging_mixin.py:115} INFO - [2023-08-13 18:39:30,180] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:39:30,198] {logging_mixin.py:115} INFO - [2023-08-13 18:39:30,197] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:39:30,214] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.156 seconds
[2023-08-13 18:40:00,286] {processor.py:153} INFO - Started process (PID=1805) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:40:00,287] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:40:00,289] {logging_mixin.py:115} INFO - [2023-08-13 18:40:00,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:40:00,407] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:40:00,424] {logging_mixin.py:115} INFO - [2023-08-13 18:40:00,424] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:40:00,445] {logging_mixin.py:115} INFO - [2023-08-13 18:40:00,445] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:40:00,459] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.180 seconds
[2023-08-13 18:40:30,541] {processor.py:153} INFO - Started process (PID=1810) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:40:30,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:40:30,544] {logging_mixin.py:115} INFO - [2023-08-13 18:40:30,544] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:40:30,680] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:40:30,699] {logging_mixin.py:115} INFO - [2023-08-13 18:40:30,699] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:40:30,720] {logging_mixin.py:115} INFO - [2023-08-13 18:40:30,720] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:40:30,732] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.198 seconds
[2023-08-13 18:41:00,873] {processor.py:153} INFO - Started process (PID=1815) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:41:00,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:41:00,878] {logging_mixin.py:115} INFO - [2023-08-13 18:41:00,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:41:01,081] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:41:01,120] {logging_mixin.py:115} INFO - [2023-08-13 18:41:01,120] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:41:01,190] {logging_mixin.py:115} INFO - [2023-08-13 18:41:01,190] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:41:01,216] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.370 seconds
[2023-08-13 18:41:31,363] {processor.py:153} INFO - Started process (PID=1820) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:41:31,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:41:31,366] {logging_mixin.py:115} INFO - [2023-08-13 18:41:31,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:41:31,474] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:41:31,491] {logging_mixin.py:115} INFO - [2023-08-13 18:41:31,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:41:31,513] {logging_mixin.py:115} INFO - [2023-08-13 18:41:31,513] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:41:31,525] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.166 seconds
[2023-08-13 18:42:01,604] {processor.py:153} INFO - Started process (PID=1825) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:42:01,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:42:01,607] {logging_mixin.py:115} INFO - [2023-08-13 18:42:01,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:42:01,719] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:42:01,736] {logging_mixin.py:115} INFO - [2023-08-13 18:42:01,736] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:42:01,758] {logging_mixin.py:115} INFO - [2023-08-13 18:42:01,758] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:42:01,769] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.172 seconds
[2023-08-13 18:42:31,851] {processor.py:153} INFO - Started process (PID=1830) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:42:31,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:42:31,854] {logging_mixin.py:115} INFO - [2023-08-13 18:42:31,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:42:31,965] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:42:31,982] {logging_mixin.py:115} INFO - [2023-08-13 18:42:31,982] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:42:32,000] {logging_mixin.py:115} INFO - [2023-08-13 18:42:32,000] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:42:32,012] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.165 seconds
[2023-08-13 18:43:02,095] {processor.py:153} INFO - Started process (PID=1835) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:43:02,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:43:02,098] {logging_mixin.py:115} INFO - [2023-08-13 18:43:02,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:43:02,217] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:43:02,237] {logging_mixin.py:115} INFO - [2023-08-13 18:43:02,237] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:43:02,264] {logging_mixin.py:115} INFO - [2023-08-13 18:43:02,263] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:43:02,279] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.190 seconds
[2023-08-13 18:43:32,354] {processor.py:153} INFO - Started process (PID=1840) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:43:32,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:43:32,357] {logging_mixin.py:115} INFO - [2023-08-13 18:43:32,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:43:32,470] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:43:32,490] {logging_mixin.py:115} INFO - [2023-08-13 18:43:32,490] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:43:32,512] {logging_mixin.py:115} INFO - [2023-08-13 18:43:32,511] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:43:32,524] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.174 seconds
[2023-08-13 18:44:02,597] {processor.py:153} INFO - Started process (PID=1845) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:44:02,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:44:02,600] {logging_mixin.py:115} INFO - [2023-08-13 18:44:02,599] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:44:02,712] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:44:02,729] {logging_mixin.py:115} INFO - [2023-08-13 18:44:02,729] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:44:02,747] {logging_mixin.py:115} INFO - [2023-08-13 18:44:02,747] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:44:02,757] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.164 seconds
[2023-08-13 18:44:32,819] {processor.py:153} INFO - Started process (PID=1850) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:44:32,820] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:44:32,822] {logging_mixin.py:115} INFO - [2023-08-13 18:44:32,821] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:44:32,955] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:44:32,977] {logging_mixin.py:115} INFO - [2023-08-13 18:44:32,977] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:44:33,003] {logging_mixin.py:115} INFO - [2023-08-13 18:44:33,003] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:44:33,019] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.205 seconds
[2023-08-13 18:45:03,101] {processor.py:153} INFO - Started process (PID=1855) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:45:03,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:45:03,104] {logging_mixin.py:115} INFO - [2023-08-13 18:45:03,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:45:03,211] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:45:03,235] {logging_mixin.py:115} INFO - [2023-08-13 18:45:03,235] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:45:03,259] {logging_mixin.py:115} INFO - [2023-08-13 18:45:03,259] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:45:03,272] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.176 seconds
[2023-08-13 18:45:33,354] {processor.py:153} INFO - Started process (PID=1860) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:45:33,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:45:33,356] {logging_mixin.py:115} INFO - [2023-08-13 18:45:33,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:45:33,460] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:45:33,477] {logging_mixin.py:115} INFO - [2023-08-13 18:45:33,477] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:45:33,497] {logging_mixin.py:115} INFO - [2023-08-13 18:45:33,497] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:45:33,509] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.161 seconds
[2023-08-13 18:46:03,586] {processor.py:153} INFO - Started process (PID=1865) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:46:03,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:46:03,589] {logging_mixin.py:115} INFO - [2023-08-13 18:46:03,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:46:03,709] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:46:03,727] {logging_mixin.py:115} INFO - [2023-08-13 18:46:03,727] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:46:03,746] {logging_mixin.py:115} INFO - [2023-08-13 18:46:03,746] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:46:03,758] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.179 seconds
[2023-08-13 18:46:33,846] {processor.py:153} INFO - Started process (PID=1870) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:46:33,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:46:33,849] {logging_mixin.py:115} INFO - [2023-08-13 18:46:33,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:46:33,965] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:46:33,984] {logging_mixin.py:115} INFO - [2023-08-13 18:46:33,984] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:46:34,020] {logging_mixin.py:115} INFO - [2023-08-13 18:46:34,020] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:46:34,033] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.193 seconds
[2023-08-13 18:47:04,128] {processor.py:153} INFO - Started process (PID=1875) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:47:04,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:47:04,130] {logging_mixin.py:115} INFO - [2023-08-13 18:47:04,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:47:04,231] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:47:04,248] {logging_mixin.py:115} INFO - [2023-08-13 18:47:04,248] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:47:04,267] {logging_mixin.py:115} INFO - [2023-08-13 18:47:04,266] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:47:04,280] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.158 seconds
[2023-08-13 18:47:34,368] {processor.py:153} INFO - Started process (PID=1880) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:47:34,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:47:34,370] {logging_mixin.py:115} INFO - [2023-08-13 18:47:34,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:47:34,484] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:47:34,502] {logging_mixin.py:115} INFO - [2023-08-13 18:47:34,502] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:47:34,523] {logging_mixin.py:115} INFO - [2023-08-13 18:47:34,522] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:47:34,536] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.173 seconds
[2023-08-13 18:48:04,622] {processor.py:153} INFO - Started process (PID=1885) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:48:04,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:48:04,625] {logging_mixin.py:115} INFO - [2023-08-13 18:48:04,624] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:48:04,727] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:48:04,742] {logging_mixin.py:115} INFO - [2023-08-13 18:48:04,742] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:48:04,759] {logging_mixin.py:115} INFO - [2023-08-13 18:48:04,759] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:48:04,770] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.153 seconds
[2023-08-13 18:48:34,853] {processor.py:153} INFO - Started process (PID=1890) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:48:34,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:48:34,855] {logging_mixin.py:115} INFO - [2023-08-13 18:48:34,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:48:34,956] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:48:34,974] {logging_mixin.py:115} INFO - [2023-08-13 18:48:34,974] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:48:34,992] {logging_mixin.py:115} INFO - [2023-08-13 18:48:34,992] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:48:35,003] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.154 seconds
[2023-08-13 18:49:05,090] {processor.py:153} INFO - Started process (PID=1895) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:49:05,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:49:05,093] {logging_mixin.py:115} INFO - [2023-08-13 18:49:05,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:49:05,203] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:49:05,222] {logging_mixin.py:115} INFO - [2023-08-13 18:49:05,222] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:49:05,245] {logging_mixin.py:115} INFO - [2023-08-13 18:49:05,245] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:49:05,256] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.170 seconds
[2023-08-13 18:49:35,334] {processor.py:153} INFO - Started process (PID=1900) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:49:35,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:49:35,337] {logging_mixin.py:115} INFO - [2023-08-13 18:49:35,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:49:35,454] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:49:35,474] {logging_mixin.py:115} INFO - [2023-08-13 18:49:35,474] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:49:35,494] {logging_mixin.py:115} INFO - [2023-08-13 18:49:35,494] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:49:35,507] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.177 seconds
[2023-08-13 18:50:05,569] {processor.py:153} INFO - Started process (PID=1905) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:50:05,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:50:05,573] {logging_mixin.py:115} INFO - [2023-08-13 18:50:05,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:50:05,685] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:50:05,703] {logging_mixin.py:115} INFO - [2023-08-13 18:50:05,703] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:50:05,722] {logging_mixin.py:115} INFO - [2023-08-13 18:50:05,722] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:50:05,733] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.168 seconds
[2023-08-13 18:50:35,810] {processor.py:153} INFO - Started process (PID=1910) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:50:35,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:50:35,813] {logging_mixin.py:115} INFO - [2023-08-13 18:50:35,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:50:35,919] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:50:35,936] {logging_mixin.py:115} INFO - [2023-08-13 18:50:35,936] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:50:35,956] {logging_mixin.py:115} INFO - [2023-08-13 18:50:35,956] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:50:35,968] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.163 seconds
[2023-08-13 18:51:06,066] {processor.py:153} INFO - Started process (PID=1915) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:51:06,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:51:06,068] {logging_mixin.py:115} INFO - [2023-08-13 18:51:06,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:51:06,183] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:51:06,204] {logging_mixin.py:115} INFO - [2023-08-13 18:51:06,204] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:51:06,231] {logging_mixin.py:115} INFO - [2023-08-13 18:51:06,231] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:51:06,243] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.184 seconds
[2023-08-13 18:51:36,383] {processor.py:153} INFO - Started process (PID=1920) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:51:36,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:51:36,386] {logging_mixin.py:115} INFO - [2023-08-13 18:51:36,386] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:51:36,495] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:51:36,513] {logging_mixin.py:115} INFO - [2023-08-13 18:51:36,513] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:51:36,536] {logging_mixin.py:115} INFO - [2023-08-13 18:51:36,536] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:51:36,548] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.170 seconds
[2023-08-13 18:52:06,648] {processor.py:153} INFO - Started process (PID=1925) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:52:06,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:52:06,651] {logging_mixin.py:115} INFO - [2023-08-13 18:52:06,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:52:06,757] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:52:06,773] {logging_mixin.py:115} INFO - [2023-08-13 18:52:06,773] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:52:06,794] {logging_mixin.py:115} INFO - [2023-08-13 18:52:06,793] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:52:06,807] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.164 seconds
[2023-08-13 18:52:36,908] {processor.py:153} INFO - Started process (PID=1930) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:52:36,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:52:36,911] {logging_mixin.py:115} INFO - [2023-08-13 18:52:36,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:52:37,015] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:52:37,033] {logging_mixin.py:115} INFO - [2023-08-13 18:52:37,033] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:52:37,054] {logging_mixin.py:115} INFO - [2023-08-13 18:52:37,054] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:52:37,066] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.163 seconds
[2023-08-13 18:53:07,132] {processor.py:153} INFO - Started process (PID=1935) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:53:07,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:53:07,134] {logging_mixin.py:115} INFO - [2023-08-13 18:53:07,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:53:07,226] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:53:07,245] {logging_mixin.py:115} INFO - [2023-08-13 18:53:07,244] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:53:07,266] {logging_mixin.py:115} INFO - [2023-08-13 18:53:07,266] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:53:07,292] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.164 seconds
[2023-08-13 18:53:37,364] {processor.py:153} INFO - Started process (PID=1940) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:53:37,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:53:37,367] {logging_mixin.py:115} INFO - [2023-08-13 18:53:37,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:53:37,474] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:53:37,491] {logging_mixin.py:115} INFO - [2023-08-13 18:53:37,491] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:53:37,512] {logging_mixin.py:115} INFO - [2023-08-13 18:53:37,512] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:53:37,526] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.166 seconds
[2023-08-13 18:54:07,604] {processor.py:153} INFO - Started process (PID=1945) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:54:07,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:54:07,607] {logging_mixin.py:115} INFO - [2023-08-13 18:54:07,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:54:07,714] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:54:07,731] {logging_mixin.py:115} INFO - [2023-08-13 18:54:07,731] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:54:07,750] {logging_mixin.py:115} INFO - [2023-08-13 18:54:07,750] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:54:07,762] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.163 seconds
[2023-08-13 18:54:37,847] {processor.py:153} INFO - Started process (PID=1950) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:54:37,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:54:37,849] {logging_mixin.py:115} INFO - [2023-08-13 18:54:37,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:54:37,971] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:54:37,991] {logging_mixin.py:115} INFO - [2023-08-13 18:54:37,991] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:54:38,016] {logging_mixin.py:115} INFO - [2023-08-13 18:54:38,016] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:54:38,035] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.193 seconds
[2023-08-13 18:55:08,103] {processor.py:153} INFO - Started process (PID=1955) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:55:08,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:55:08,106] {logging_mixin.py:115} INFO - [2023-08-13 18:55:08,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:55:08,229] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:55:08,246] {logging_mixin.py:115} INFO - [2023-08-13 18:55:08,246] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:55:08,269] {logging_mixin.py:115} INFO - [2023-08-13 18:55:08,269] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:55:08,287] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.188 seconds
[2023-08-13 18:55:38,381] {processor.py:153} INFO - Started process (PID=1960) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:55:38,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:55:38,385] {logging_mixin.py:115} INFO - [2023-08-13 18:55:38,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:55:38,494] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:55:38,511] {logging_mixin.py:115} INFO - [2023-08-13 18:55:38,511] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:55:38,531] {logging_mixin.py:115} INFO - [2023-08-13 18:55:38,531] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:55:38,543] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.166 seconds
[2023-08-13 18:56:08,622] {processor.py:153} INFO - Started process (PID=1965) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:56:08,625] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:56:08,626] {logging_mixin.py:115} INFO - [2023-08-13 18:56:08,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:56:08,745] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:56:08,764] {logging_mixin.py:115} INFO - [2023-08-13 18:56:08,763] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:56:08,793] {logging_mixin.py:115} INFO - [2023-08-13 18:56:08,793] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:56:08,810] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.192 seconds
[2023-08-13 18:56:38,891] {processor.py:153} INFO - Started process (PID=1970) to work on /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:56:38,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py for tasks to queue
[2023-08-13 18:56:38,895] {logging_mixin.py:115} INFO - [2023-08-13 18:56:38,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:56:39,008] {processor.py:651} INFO - DAG(s) dict_keys(['submit_pyspark_script_to_emr']) retrieved from /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py
[2023-08-13 18:56:39,027] {logging_mixin.py:115} INFO - [2023-08-13 18:56:39,027] {dag.py:2379} INFO - Sync 1 DAGs
[2023-08-13 18:56:39,050] {logging_mixin.py:115} INFO - [2023-08-13 18:56:39,050] {dag.py:2931} INFO - Setting next_dagrun for submit_pyspark_script_to_emr to None, run_after=None
[2023-08-13 18:56:39,062] {processor.py:161} INFO - Processing /opt/airflow/dags/orchestration/submit_spark_job_to_emr.py took 0.176 seconds
